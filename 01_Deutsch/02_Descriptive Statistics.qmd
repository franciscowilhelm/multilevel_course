---
title: "Descriptive Statistics"
format:
  html:
    df-print: kable
editor: source
---

```{r}
if (!require("pacman")) install.packages("pacman")
pacman::p_load(haven, psych,
               sjmisc, sjPlot, writexl,
               tidyverse, multilevelTools)
```

```{r}
load("data_scoring.RData")
```


## ICC und Within-Person Variance

Uns interessiert wie gross der Anteil der Varianz ist, der auf die zwei Ebenen der Daten entfallen (Inner-Person, Zwischen-Person-Ebene). Dies kann uns der ICC angeben. Mittels der Funktion `statsBy()` bekommen wir einige Analysen zu unseren Mehrebenen-Daten geliefert. Die Funktion benötigt zwei Argumente: den Datensatz und und die Gruppierungsvariable. Wir wählen mittels `select()` die Rohvariante der Variablen aus, da nur diese die Informationen über beide Ebenen enthalten. 
Ersetzt entsprechend im `select()` die Variablen mit denen, die euch interessieren, hier sowohl die täglichen als auch Baselinevariablen.

```{r}
mehrebenen_stats <- df_scores |> 
  statsBy(group = "id")
```
Wir bekommen hier Warnungen, weil wir auch eine reine Level-2 Variablen eingeschlossen haben (w). Dies können wir jedoch ignorieren.
Den ICC können wir uns angeben lassen, indem wir aus dem Listenobjekt `mehrebenen_stats` mit dem Dollarzeichen `$` die Untervariable `ICC1` anwählen.

```{r}
icc <- mehrebenen_stats$ICC1 |> 
  round(2) # runden
icc
```
Alle Skalen im Beispiel haben ICCs in einem angemessenen Bereich (<.80). Dies heisst, dass genug tägliche Varianz vorhanden ist, um Mehrebenen-Analysen durchzuführen.

## Vorläufige Analysen

### Reliabilitätsanalyse

Die Reliabilitätsanalyse basiert auf den Items, nicht auf den Skalenwerten.

Bei Skalen aus der Daily Erhebung nehmen wir die `omegaSEM()` Funktion. Als erstes Argument geben wir die Items in einem Character-Vector mittels `c()`, die Items werden mit Anführungszeichen angegeben. Falls ihr die Itemnamen nicht wisst, könnt ihr sie mit `names(df_items)` nachsehen.

```{r}
names(df_example2)
scalea_reliab <- multilevelTools::omegaSEM(c("a1", "a2", "a3", "a4", "a5"), "id", df_example2)
scalea_reliab$Results
```

Hier erscheint meist eine Warnung, weil nicht alle Personen (cluster) Varianz auf den Items haben. Dies koennen wir ignorieren.
In den simulierten Daten, die wir verwenden, ist dies jedoch nicht der Fall.
Dann koennen wir den Output ansehen. Omega_within und Omega_between sollten über .70 liegen für eine gute Reliabilität auf beiden Leveln.

```{r}
scaleb_reliab <- multilevelTools::omegaSEM(c("b1", "b2", "b3", "b4", "b5"), "id", df_example2)
scaleb_reliab$Results
```

```{r}
scalec_reliab <- multilevelTools::omegaSEM(c("c1", "c2", "c3"), "id", df_example2)
scalec_reliab$Results
```

Für eine genauere Auswertung können wir `omegaSEM()` mit dem Parameter `savemodel = TRUE` laufen lassen und uns mittels `summary()` die konfirmatorische Faktoranalyse genauer ansehen.
Zudem können wir uns mit `lavInspect()` die Modellparameter ansehen, um zu verstehen wie die Reliabilitätskoeffizient gebildet wird.

```{r}
scaleb_reliab <- multilevelTools::omegaSEM(c("b1", "b2", "b3", "b4", "b5"), "id", df_example2, savemodel = TRUE)
scaleb_reliab$Fit |> summary(fit = TRUE, stand = TRUE)
lavaan::lavInspect(scaleb_reliab$Fit, "list") # alternatively, parTable()
```

Wie der Output zeigt, ergibt sich die omega Reliabilität aus dem Anteil der durch den Faktor (f_within für den Faktor auf Level-1 bzw. f_between für den Faktor auf Level-2) erklärten Varianz der Items (Summe aller  Item-Ladungen, quadriert für Varianz) geteilt durch die Gesamtvarianz der Items (durch Faktor erklärte Varianz der Items + Residualvarianz, d.h. übrigbleibende Varianz der Items). Diese Formel wird pro Varianzebene (Level-1, also tägliche Schwankungen innerhalb der Person) und Level-2 (Unterschiede zwischen Personen) getrennt berechnet.

### Reliabilitaeten Level-2 Skalen

Für die Baseline-Variablen verwenden wir die Funktion `alpha()` aus dem `psych` Paket. Als Argument nimmt die Funktion hier (a) den Datensatz und (b) die Variablennamen der Items der Skala in einem Vektor `c()`. Revers kodierte Items werden mit einem "-" als Präfix eingetragen (z.B. "-reversitem_1").

Der Datensatz muss hier angepasst werden. Aktuell haben wir eine Zeile pro tägliche Messung. Da die Funktion alpha es nicht berücksichtigt, dass es sich hier um genestete Daten handelt (100 Personen x 10 Tage), müssen wir den Datensatz so transformieren, dass wir nur einen Wert pro Person haben. 
```{r}
# create dataframe that has one row per person
df_w <- df_example2 |> select(id, c("w1", "w2", "w3", "w4", "w5")) |>
  group_by(id) |> 
  summarise(across(everything(), ~mean(.x, na.rm = TRUE))) # we use mean as a shortcut, useful when we have missing data
w_reliab <- psych::alpha(df_w, keys = list(w = c("w1", "w2", "w3", "w4", "w5")))
print(w_reliab)
```
Wir erhalten umfangreiche Angaben zur Reliabilität. Wichtig ist der Alpha-Wert der Gesamtskala (std.alpha). Dieser ist im Beispiel > .70.


## Korrelationstabelle

In psychologischen Artikeln ist (fast) immer die Korrelationstabelle die erste Tabelle des Artikels. Unser nächstes Ziel ist es, die Korrelationstabelle anzufertigen in der wir auch die Mittelwerte und Standardabweichungen integrieren. 


### Mittelwerte

Mittelwerte wurden bereits - pro Person - durch die statsBy() Funktion gebildet. Den allgemeinen Mittelwert bekommen wir  mit der Funktion `summarise()`. Diese erlaubt uns, zusammenfassende Werte zu bilden. Da wir dies gleich für mehrere Variablen machen, benutzen wir zudem `across()` um die Summary gleich für mehrere Variablen zu bilden. Die Funktion benötigt als Argumente (a) die Namen der Variablen mit `c()` als einen Vektor zusammengefasst, (b) die Funktionen, wie sie gebildet werden (hier: `~mean(.x, na.rm = TRUE)` für das arithmetische Mittel unter Ausschluss aller nicht vorhandenen Werte) und (c) optional die Namen der ausgegebenen Variablen mittels ".names". Wir verwenden "m_{.col}". Abschliessend runden wir die Werte.

Ersetzt im folgenden Code in der Klammer von `c()` die Variablennamen  mit denen, die euch interessieren, hier sowohl die täglichen als auch Baselinevariablen.

```{r}
mittelwerte <- mehrebenen_stats$mean |> 
  as_tibble() |> 
  summarise(across(c(w, a, b, c), ~mean(.x, na.rm = TRUE)))

mittelwerte
```
Wir sehen, dass Boredom und bored behavior eher selten sind. Für die Verteilung der Variablen sehen wir uns idealerweise auch Histogramme an (hier nicht aufgezeigt).

#### Standardabweichungen

Ganz ähnlich verfahren wir für die Standardabweichung, nur dass wir hier als Funktion `~sd(.x, na.rm = TRUE)` verwenden.
Ersetzt auch hier im folgenden Code in der Klammer von `c()` die Variablennamen  mit denen, die euch interessieren, hier sowohl die täglichen als auch Baselinevariablen.
Die Baselinevariable "w" zeigt hier keine SD mit dieser Berechnung und muss separat berechnet werden.



```{r}
standardabweichung <- mehrebenen_stats$sd |> 
  as_tibble() |> 
  summarise(across(c(a, b, c), ~mean(.x, na.rm = TRUE)))

standardabweichung_w <- scales_between$scores |> sd()
  
standardabweichung <- bind_cols(tibble(w = standardabweichung_w), standardabweichung)
standardabweichung
```

#### Korrelationen

Wir wollen eine Korrelationstabelle, in der wir auf einen Blick sowohl die Zwischen-Person-Korrelationen als auch die Inner-Person-Korrelationen sehen. Die `statsBy()` Funktion, die wir bereits aufgerufen haben, gibt uns beides separat aus, und wir müssen sie über mehrere Schritte zusammenführen und gemösse APA mit Signifikanzsternchen ergänzen.
Die Details der Vorgehensweise geht über den Rahmen dieses Arbeitsbuchs hinaus. Wir verwenden die `mehrebenen_stats` Liste, die wir weiter oben erstellt haben. 

(Die folgende Syntax muss nicht angepasst werden.)

%todo% - star_assign in lib verschieben oder aus r-collection nehmen

```{r}
cortable_between <- mehrebenen_stats$rbg |> round(2) # Zwischen Person Kor.
cortable_within <- mehrebenen_stats$rwg |> round(2) # Inner Person Kor.

# Signifikanzsternchen
star_assign <- function(x) {
  if(!is.na(x)) {
    if(x < 0.001) "***"
    else if (x < 0.01) "**"
    else if (x < 0.05) "*"
    else ""
  }
  else ""
}
vstar_assign <- Vectorize(star_assign)

for(i in 1:length(cortable_between)) {
  cortable_between[i] <- str_c(cortable_between[i], vstar_assign(mehrebenen_stats$pbg[i]))
  }

for(i in 1:length(cortable_within)) {
  cortable_within[i] <- str_c(cortable_within[i], vstar_assign(mehrebenen_stats$pwg[i]))
  }

cortable <- cortable_between
cortable[lower.tri(cortable)] <- cortable_within[lower.tri(cortable_within)] # Inner-Person Korrelationen im unteren Dreieck einfügen.
cortable <- cortable |>   as_tibble(rownames = "var") # als data frame formatieren (später wichtig)

cortable
```

Wir erhalten im unteren Dreieck die Inner-Person-Korrelationen, und im oberen Dreieck die Zwischen-Person-Korrelationen.


#### Integration in Tabelle

Jetzt gilt es, die Mittelwerte, Standardabweichungen, ICCs, und Korrelationen in einer Tabelle zu integrieren. Mit der `tibble()` Funktion bauen wir einen neue Datensatz-Tabelle, in der wir alle Variablen integrieren.

(Die folgende Syntax muss nicht angepasst werden.)

```{r}
cortable_integriert <- tibble(cortable["var"],
                              m = t(mittelwerte), # t() transponiert die Dimensionen der Variable, damit wir es als spalte (3x1) haben statt als zeile (1x3)
                              sd = t(standardabweichung),
                              icc = icc[2:length(icc)], # 1 überspringen da wir den ICC von "id" nicht brauchen
                              cortable[,2:ncol(cortable)])

cortable_integriert
```


Die vorhergehenden Analysen zeigen wie man die einzelnen Komponenten der Tabelle erstellt und zusammenführt.
Die Funktion cortable_multilevel() aus franzpak führt die einzelnen Funktionen direkt zusammen.
Aufgrund der Inklusion von reinen Level-2 Variablen, die keine Varianz auf Level 1 haben, werden uns auch hier ein paar Warnungen ausgegeben.

```{r}
# devtools::install_github()
library(franzpak)
cortable_integriert2 <- cortable_multilevel(df_scores,
                                            varnames = c("w", "a", "b", "c"),
                                            grp = "id")
cortable_integriert2
```


### Export von Tabellen zu Excel

Wir exportieren die Korrelationstabelle nach Excel mittels `write_xlsx()`.

(Die folgende Syntax muss nicht angepasst werden.)
```{r}
write_xlsx(cortable_integriert2, path = "korrelationstabelle.xlsx")
```

Die Excel-Tabelle lässt sich dann in Word kopieren und weiter verarbeitet werden, z.B. mit den richtigen Variablennamen versehen werden etc. Damit haben wir nun die Datenaufbereitung und deskriptive Datenanalyse abgeschlossen.


## Übung:

Erstellt eine Korrelationstabelle von den Variablen w, x, m, und y mit Mittelwerten, Standardabweichungen, ICC, und Within/Between-Korrelationen wie in Kapitel 1a gezeigt.

```{r}
#| eval: false
library(franzpak)
cortable_multilevel(...)
```
