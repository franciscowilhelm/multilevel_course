---
title: "Kapitel 4: Hypothesentests - Teil 1"
format:
  html:
    df-print: kable
    code_folding: hide
    highlight: haddock
    toc: true
    toc_float: true
editor: source
---

In diesem Kapitel verwenden wir verschiedene Regressionsmodelle die zur Überprüfung von Hypothesen eingesetzt werden.

- Random Intercept Modell / Null-Model
- Random Intercept, fixed slope Modell
- Random intercept, random slope Modell
- Erweiterung um Level-2 Prädiktoren

## Vorbereitung

Install packages

```{r}
if (!require("pacman")) install.packages("pacman")
pacman::p_load(lmerTest, haven, brms, psych,
               sjmisc, sjPlot, sjlabelled, writexl, broom.mixed, qgraph,
               tidyverse, multilevelTools, parameters)
```

## Daten einlesen

```{r}
load("../data/df_example1.RData")
load("../data/df_example1c.RData")

```

Für diese Einheit verwenden wir den folgenden Datensatz (data.frame/tibble):

-   df_example1: Alle Skalenscores im Long Format, mit personen-zentrierten Variablenvarianten ("_dm") und Personen-Mittelwerten der täglich gemessenenen Variablen ("_gm").
Struktur des Datensatzes kann man sich ansehen mit `head()` oder `print()`.

```{r}
head(df_example1)
```


Im Folgenden betrachten wir ein Modell in dem y durch x vorhergesagt wird.

## Random Intercept Modell / Null-Model

Die Funktion lmer() benötigt zwei Argumente, (a) die Formel und (b) den Datensatz. Zum Aufbau und Details der Formeln s. Folien.


Level 1: $y_{ij} = \beta_{0j} + e_{ij}$

Level 2 (random intercept): $\beta_{0j} = \gamma_{00} + u_{0j}$

```{r}
nullmodel <- lmer(y ~ (1 | id), data = df_example1)
```

Zur Ansicht der Ergebnisse haben wir zwei Optionen: Den `summary()` Befehl - die Standardansicht, wie von den Paketautoren implementiert, den `tidy()` Befehl aus dem broom-Package, und den `model_parameters()` Befehl aus dem parameters Package. tidy() und model_parameters() Funktionsoutputs könnten nach Excel/Word exportiert werden mittels der `write_xlsx()` Funktion, oder indem das Notebook als .docx "gerendert" (ausgegeben) wird.


```{r}
summary(nullmodel)
```

```{r}
tidy(nullmodel)
```

```{r}
model_parameters(nullmodel) |> print_html()
```

Im Seminar verwenden wir den Output von model_parameters(), weil er eine recht gut formatierte Übersicht gibt.

### ICC

Aus dem Null-Model wird der ICC bestimmt. Dies haben wir in der  vorhergehenden 

ICC: $\frac{\tau_{00}}{\tau_{00}+\tau_{ij}}$, $\tau$ gibt die Varianz des jewiligen Koeffizienten an.

Wir können dies aus dem Modelloutput nehmen und berechnen:

```{r}
modelsummary <- model_parameters(nullmodel)
tau00 <- modelsummary$Coefficient[modelsummary$Parameter == "SD (Intercept)"]^2
tauij <- modelsummary$Coefficient[modelsummary$Parameter == "SD (Observations)"]^2
tau00 / (tau00+tauij)
# performance::icc(nullmodel) # Alternativfunktion
```

### Visualisierung

Wir können uns die Analysen visualisieren, hier zur reduzierten visuellen Komplexität nur auf Basis der ersten 20 Personen (ID 1-20.)

```{r}
#| echo: false
df_example1 <- df_example1 |> mutate(predicted_ri = predict(nullmodel))

xlabel <- "X"
ylabel <- "Y"

ggplot(data = df_example1 |> filter(id %in% 1:20), aes(
  x = x,
  y = predicted_ri,
  colour = id
)) +
  geom_smooth(method = "lm", fullrange = TRUE, se = F, size = .3) +
  geom_jitter(aes(y = y), alpha = .2) +
  labs(x = xlabel, y = ylabel) +
  ggtitle("Intercept-Only-Modell") +
  scale_colour_discrete() +
  geom_abline(intercept = fixef(nullmodel), slope = 0, size = 1.5) +
  ggthemes::theme_tufte()
```

Oder zwei Personen, um uns die einzelnen Punkte auch anschauen zu können:

```{r}
ggplot(data = df_example1 |> filter(id %in% c(1, 16)), aes(
  x = x,
  y = predicted_ri,
  colour = id
)) +
  geom_smooth(method = "lm", fullrange = TRUE, se = F, size = 1) +
  geom_jitter(aes(y = y), alpha = .5, size = 2.5) +
  labs(x = xlabel, y = ylabel) +
  ggtitle("Intercept-Only-Modell") +
  scale_colour_discrete() +
  geom_abline(intercept = fixef(nullmodel), slope = 0, size = 1.5) +
  ggthemes::theme_tufte()
```


## Random Intercept, fixed slope Modell

Als nächstes bauen wir den Prädiktor x ein. Wir verwenden hier die zentrierte Variable "`_dm`" um Inner-Person Effekte zu berechnen.

Level 1: $y_{ij} = \beta_{0j} + \beta_{1j}*X_{ij} + e_{ij}$

Level 2 (random intercept): $\beta_{0j} = \gamma_{00} + u_{0j}$

Level 2 (fixed effect only): $\beta'_{1j} = \gamma'_{10}$

```{r}
ri.fs_modell <- lmer(y ~ x_dm + (1 | id), data = df_example1)
```

```{r}
model_parameters(ri.fs_modell) |> print_html()
```

### Visualisierung

```{r}
#| echo: false

df_example1 <- df_example1 |> mutate(predicted_rifs = predict(ri.fs_modell))

ggplot(data = df_example1 |> filter(id %in% 1:20), aes(
  x = x,
  y = predicted_rifs,
  colour = id
)) +
  geom_smooth(method = "lm", fullrange = TRUE, se = F, size = .3) +
  geom_jitter(aes(y = y), alpha = .2) +
  labs(x = xlabel, y = ylabel) +
  ggtitle("Random Intercept , Fixed Slope Modell") +
  scale_colour_discrete() +
  geom_abline(
    intercept = fixef(ri.fs_modell)["(Intercept)"],
    slope = fixef(ri.fs_modell)["x_dm"],
    size = 1.5
  ) +
  ggthemes::theme_tufte()
```



## Random intercept, random slope Modell

Als nächstes fügen wir den random slope der Prädiktorvariable x_dm hinzu, in dem wir die random effect Struktur erweitern - "(1 + x_dm | id)".

Level 1: $y_{ij} = \beta_{0j} + \beta_{1j}*(X_{ij}-\overline{X_j}) + e_{ij}$

Level 2 (random intercept): $\beta_{0j} = \gamma_{00} + u_{0j}$

Level 2: $\beta'_{1j} = \gamma'_{10}$

```{r}
ri.rs_modell <- lmer(y ~ x_dm + (1 + x_dm | id), data = df_example1)
model_parameters(ri.rs_modell) |> print_html()
```


### Visualisierung

```{r}
#| echo: false
df_example1 <- df_example1 |> mutate(predicted_rirs = predict(ri.rs_modell))

ggplot(data = df_example1 |> filter(id %in% 1:20), aes(
  x = x,
  y = predicted_rirs,
  colour = id
)) +
  geom_smooth(method = "lm", fullrange = TRUE, se = F, size = .3) +
  geom_jitter(aes(y = y), alpha = .2) +
  labs(x = xlabel, y = ylabel) +
  ggtitle("Random Intercept , Random Slope Modell") +
  scale_colour_discrete() +
  geom_abline(
    intercept = fixef(ri.rs_modell)["(Intercept)"],
    slope = fixef(ri.rs_modell)["x_dm"],
    size = 1.5
  ) +
  ggthemes::theme_tufte()
```




## Level-2 Prädiktoren

Als nächstes fügen wir einen Level-2 Prädiktor hinzu, der pro Person nur einmal gemessen wurde. Dabei handelt es sich für gewöhnlich um (1) Variablen, bei denen wir nicht an täglichen Schwankungen interessiert sind, wie soziodemografischen oder Persönlichkeitsvariablen, oder (2) den Mittelwert der Personen auf einer täglich gemessenen Variable. Im Beispiel verwenden wir (2), "x_gm".

Level 1: $y_{ij} = \beta_{0j} + \beta_{1j}*(X_{ij}-\overline{X_j}) + \beta_{2j}*\overline{X_j} + e_{ij}$

Level 2 (random intercept): $\beta_{0j} = \gamma_{00} + u_{0j}$
Level 2 (random slope for x): $\beta_{1j} = \gamma_{10} + u_{2j}$

```{r}
ri.rs_l2_modell <- lmer(y ~ x_dm + x_gm + (1 + x_dm | id), data = df_example1)
model_parameters(ri.rs_l2_modell) |> print_html()
```

## Übung

Wir arbeiten in der Übung mit einem neuen Datensatz.

Mache dich mit ihm vertraut.
Diesmal benutzen wir einen Datensatz in dem die Variablen "labelled" sind, also Beschriftungen haben. Wir können die Labels mit `get_label()` oder `view_df()` abrufen.

```{r}
load("../data/df_example_cli.RData")

head(df_example_cli)

view_df(df_example_cli)
# alternativ
#get_label(df_example_cli)
```

Berechne Modelle mit denen du die folgenden Hypothesen testest: 

Hypothese 1: Tägliche illegitime Aufgaben hängen positiv mit täglichem negativem Affekt zusammen.

Teste zunächst ein Random intercept, fixed slope Modell, und dann ein Random Intercept, Random Slope Modell.
Urteile, ob die Hypothese angenommen oder verworfen werden sollten.

:::{.callout-tip collapse="true"}
### Lösung

```{r}
ri.fs_modell <- lmer(negativ ~ illtask_dm + (1 | id), data = df_example_cli)
parameters(ri.fs_modell) |> print_html()

ri.rs_modell <- lmer(negativ ~ illtask_dm + (1 + illtask_dm | id), data = df_example_cli)
parameters(ri.rs_modell) |> print_html()

```

Die Hypothese 1 kann angenommen werden, da der Effekt von illegitimen Aufgaben (`illtask_dm`) signifikant positiv ist. Auch im strengeren random Slopes Modell ist der Effekt weiterhin signifikant.

Wir können auch sehen, dass im Random Slopes Modell die Konfidenzintervalle etwas breiter sind und der Standardfehler etwas grösser sind als im Fixed Slopes Modell. 
In Random Slopes Modellen können die Regressionskoeffizienten zwischen den Individuen variieren, was zusätzliche Varianz in die Schätzungen einbringt. Diese zusätzliche Unsicherheit führt dazu, dass sowohl die Standardfehler als auch die Konfidenzintervalle grösser ausfallen als in Fixed Slopes Modellen, bei denen die Steigung als konstant über alle Gruppen angenommen wird. Dadurch reflektieren die größeren Intervalle die höhere Unsicherheit in der Modellierung individueller Unterschiede in den Effekten.

:::
