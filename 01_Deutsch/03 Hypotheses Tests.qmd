---
title: "Kapitel 3: Hypothesentests - Teil 1"
format:
  html:
    df-print: kable
    code_folding: hide
    highlight: haddock
    theme: flatly
    toc: true
    toc_float: true
editor: source
---

In diesem Kapitel verwenden wir verschiedene Regressionsmodelle die zur Überprüfung von Hypothesen eingesetzt werden.


- Random Intercept Modell / Null-Model
- Random Intercept, fixed slope Modell
- Random intercept, random slope Modell
- Erweiterung um Level-2 Prädiktoren
- Cross-level und within-level Interaktionen

## Vorbereitung

Install packages

```{r}
if (!require("pacman")) install.packages("pacman")
pacman::p_load(lmerTest, haven, brms, psych,
               sjmisc, sjPlot, writexl, broom.mixed, qgraph,
               tidyverse, multilevelTools, parameters)
```

## Daten einlesen

```{r}
load("../data/df_example1.RData")
load("../data/df_example1c.RData")

```

Für diese Einheit verwenden wir den folgenden Datensatz (data.frame/tibble):

-   df_example1: Alle Skalenscores im Long Format, mit personen-zentrierten Variablenvarianten ("_dm") und Personen-Mittelwerten der täglich gemessenenen Variablen ("_gm").
Struktur des Datensatzes kann man sich ansehen mit `head()` oder `print()`.

```{r}
head(df_example1)
```


Im Folgenden betrachten wir ein Modell in dem y durch x vorhergesagt wird.

## Random Intercept Modell / Null-Model

Die Funktion lmer() benötigt zwei Argumente, (a) die Formel und (b) den Datensatz. Zum Aufbau und Details der Formeln s. Folien.


Level 1: $y_{ij} = \beta_{0j} + e_{ij}$

Level 2 (random intercept): $\beta_{0j} = \gamma_{00} + u_{0j}$

```{r}
nullmodel <- lmer(y ~ (1 | id), data = df_example1)
```

Zur Ansicht der Ergebnisse haben wir zwei Optionen: Den `summary()` Befehl - die Standardansicht, wie von den Paketautoren implementiert, den `tidy()` Befehl aus dem broom-Package, und den `model_parameters()` Befehl aus dem parameters Package. tidy() und model_parameters() Funktionsoutputs könnten nach Excel/Word exportiert werden mittels der `write_xlsx()` Funktion, oder indem das Notebook als .docx "gerendert" (ausgegeben) wird.


```{r}
summary(nullmodel)
```

```{r}
tidy(nullmodel)
```

```{r}
model_parameters(nullmodel) |> print_html()
```

Ich bevorzuge persönlich den Output von model_parameters(), aber das ist Geschmackssache.

### ICC

Aus dem Null-Model wird der ICC bestimmt. Dies haben wir in der  vorhergehenden 

ICC: $\frac{\tau_{00}}{\tau_{00}+\tau_{ij}}$, $\tau$ gibt die Varianz des jewiligen Koeffizienten an.

Wir können dies aus dem Modelloutput nehmen und berechnen:

```{r}
modelsummary <- model_parameters(nullmodel)
tau00 <- modelsummary$Coefficient[modelsummary$Parameter == "SD (Intercept)"]^2
tauij <- modelsummary$Coefficient[modelsummary$Parameter == "SD (Observations)"]^2
tau00 / (tau00+tauij)
# performance::icc(nullmodel) # Alternativfunktion
```
### Visualisierung

Wir können uns die Analysen visualisieren, hier zur reduzierten visuellen Komplexität nur auf Basis der ersten 20 Personen (ID 1-20.)

```{r}
df_example1 <- df_example1 |> mutate(predicted_ri = predict(nullmodel))

xlabel <- "X"
ylabel <- "Y"

ggplot(data = df_example1 |> filter(id %in% 1:20), aes(
  x = x,
  y = predicted_ri,
  colour = id
)) +
  geom_smooth(method = "lm", fullrange = TRUE, se = F, size = .3) +
  geom_jitter(aes(y = y), alpha = .2) +
  labs(x = xlabel, y = ylabel) +
  ggtitle("Intercept-Only-Modell") +
  scale_colour_discrete() +
  geom_abline(intercept = fixef(nullmodel), slope = 0, size = 1.5) +
  ggthemes::theme_tufte()
```

Oder zwei Personen, um uns die einzelnen Punkte auch anschauen zu können

```{r}
ggplot(data = df_example1 |> filter(id %in% c(1, 16)), aes(
  x = x,
  y = predicted_ri,
  colour = id
)) +
  geom_smooth(method = "lm", fullrange = TRUE, se = F, size = 1) +
  geom_jitter(aes(y = y), alpha = .5, size = 2.5) +
  labs(x = xlabel, y = ylabel) +
  ggtitle("Intercept-Only-Modell") +
  scale_colour_discrete() +
  geom_abline(intercept = fixef(nullmodel), slope = 0, size = 1.5) +
  ggthemes::theme_tufte()
```


## Random Intercept, fixed slope Modell

Als nächstes bauen wir den Prädiktor x ein. Wir verwenden hier die zentrierte Variable "`_dm`" um Inner-Person Effekte zu berechnen.

Level 1: $y_{ij} = \beta_{0j} + \beta_{1j}*X_{ij} + e_{ij}$

Level 2 (random intercept): $\beta_{0j} = \gamma_{00} + u_{0j}$

Level 2 (fixed effect only): $\beta'_{1j} = \gamma'_{10}$

```{r}
ri.fs_modell <- lmer(y ~ x_dm + (1 | id), data = df_example1)
```

```{r}
model_parameters(ri.fs_modell) |> print_html()
```

### Visualisierung

```{r}
df_example1 <- df_example1 |> mutate(predicted_rifs = predict(ri.fs_modell))

ggplot(data = df_example1 |> filter(id %in% 1:20), aes(
  x = x,
  y = predicted_rifs,
  colour = id
)) +
  geom_smooth(method = "lm", fullrange = TRUE, se = F, size = .3) +
  geom_jitter(aes(y = y), alpha = .2) +
  labs(x = xlabel, y = ylabel) +
  ggtitle("Random Intercept , Fixed Slope Modell") +
  scale_colour_discrete() +
  geom_abline(
    intercept = fixef(ri.fs_modell)["(Intercept)"],
    slope = fixef(ri.fs_modell)["x_dm"],
    size = 1.5
  ) +
  ggthemes::theme_tufte()
```


### Random intercept, random slope Modell

Als nächstes fügen wir den random slope der Prädiktorvariable x_dm hinzu, in dem wir die random effect Struktur erweitern - "(1 + x_dm | id)".

Level 1: $y_{ij} = \beta_{0j} + \beta_{1j}*(X_{ij}-\overline{X_j}) + e_{ij}$

Level 2 (random intercept): $\beta_{0j} = \gamma_{00} + u_{0j}$

Level 2: $\beta'_{1j} = \gamma'_{10}$

```{r}
ri.rs_modell <- lmer(y ~ x_dm + (1 + x_dm | id), data = df_example1)
model_parameters(ri.rs_modell) |> print_html()
```


### Visualisierung

```{r}
df_example1 <- df_example1 |> mutate(predicted_rirs = predict(ri.rs_modell))

ggplot(data = df_example1 |> filter(id %in% 1:20), aes(
  x = x,
  y = predicted_rirs,
  colour = id
)) +
  geom_smooth(method = "lm", fullrange = TRUE, se = F, size = .3) +
  geom_jitter(aes(y = y), alpha = .2) +
  labs(x = xlabel, y = ylabel) +
  ggtitle("Random Intercept , Random Slope Modell") +
  scale_colour_discrete() +
  geom_abline(
    intercept = fixef(ri.rs_modell)["(Intercept)"],
    slope = fixef(ri.rs_modell)["x_dm"],
    size = 1.5
  ) +
  ggthemes::theme_tufte()
```


## Level-2 Prädiktoren

Als nächstes fügen wir einen Level-2 Prädiktor hinzu, der pro Person nur einmal gemessen wurde. Dabei handelt es sich für gewöhnlich um (1) Variablen, bei denen wir nicht an täglichen Schwankungen interessiert sind, wie soziodemografischen oder Persönlichkeitsvariablen, oder (2) den Mittelwert der Personen auf einer täglich gemessenen Variable. Im Beispiel verwenden wir (2), "x_gm".

Level 1: $y_{ij} = \beta_{0j} + \beta_{1j}*(X_{ij}-\overline{X_j}) + \beta_{2j}*\overline{X_j} + e_{ij}$

Level 2 (random intercept): $\beta_{0j} = \gamma_{00} + u_{0j}$
Level 2 (random slope for x): $\beta_{1j} = \gamma_{10} + u_{2j}$

```{r}
ri.rs_l2_modell <- lmer(y ~ x_dm + x_gm + (1 + x_dm | id), data = df_example1)
model_parameters(ri.rs_l2_modell) |> print_html()
```

## Cross-Level Interaktion

Erwarten wir dass der Effekt von täglichen Schwankungen in X auf Y abhängig von einer Variablen ist, die auf Level-2 gemessen wird (z.B. relativ stabile Persönlichkeitsmerkmale), können wir dies mit einer Cross-Level Interaktion testen.

Level 1: $y_{ij} = \beta_{0j} + \beta_{1j}*(X_{ij}-\overline{X_j}) + \beta_{2j}*W_{j} + e_{ij}$

Level 2 (random intercept): $\beta_{0j} = \gamma_{00} + u_{0j}$
Level 2 (random slope for x): $\beta_{1j} = \gamma_{10} + u_{2j}$

```{r}
head(df_example1c)
```


```{r}
ri.rs_cli_modell <- lmer(y ~ x_dm + w + w*x_dm + (1 + x_dm | id), data = df_example1c)
model_parameters(ri.rs_cli_modell) |> print_html()
```
Beachtet, dass mit der eingebauten Interaktion die Haupteffekte nicht mehr interpretiert werden.

### Visualisierung

Visualisierung des Interaktionseffekt mittels der `plot_model()` Funktion.
Standardmässig werden die Simple Slopes an den Extremwerten (Minimum, Maximum) des Moderators geschätzt.

```{r}
plot_model(ri.rs_cli_modell, type = "int", terms = c("x_dm", "w"))
ggsave("test.png")
```

Alternativ kann man auch die Werte zum Mittelwerte und bei -1 SD und +1 SD des Moderators anzeigen lassen.

```{r}
plot_model(ri.rs_cli_modell, type = "int", mdrt.values = "meansd")
```
Der Plot zeigt, dass bei höheren Ausprägungen von w der Effekt von x_dm stärker ausfällt.


### Within-level Interaktion

Analog zur Cross-level Interaktion gibt es auch Within-level Interaktionen, bei der die Level-1 Anteile von Prädiktorvariablen miteinander interagieren.

Level 1: $y_{ij} = \beta_{0j} + \beta_{1j}*(X_{ij}-\overline{X_j}) + \beta_{2j}*(M_{ij}-\overline{M_j}) + \beta_{3j}*((M_{ij}-\overline{M_j})*(X_{ij}-\overline{X_j})) + e_{ij}$

Level 2 (random intercept): $\beta_{0j} = \gamma_{00} + u_{0j}$
Level 2 (random slope X): $\beta_{1j} = \gamma_{10} + u_{1j}$
Level 2 (random slope M): $\beta_{2j} = \gamma_{20} + u_{2j}$

```{r}
ri.rs_wli_modell <- lmer(y ~ x_dm + m_dm + x_dm*m_dm + (1 + x_dm + m_dm | id), data = df_example1)
model_parameters(ri.rs_wli_modell) |> print_html()
```

```{r}
plot_model(ri.rs_wli_modell, type = "int", mdrt.values = "meansd")
```

Der Interaktionseffekt ist nicht signifikant. Dies bedeutet, wie der Plot zeigt, dass die Linien bei allen Ausprägungen des Moderators mehr oder wenig parallel sind.
 
 