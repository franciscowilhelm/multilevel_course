---
title: "Kapitel 5: Hypothestentests 2 - Moderation und Mediation"
format:
  html:
    df-print: kable
    code_folding: hide
    highlight: haddock
    theme: cosmos
    toc: true
    toc_float: true
editor: source
---

```{r}
if (!require("pacman")) install.packages("pacman")

pacman::p_load(lmerTest, haven, brms, psych,
               sjmisc, sjlabelled, sjPlot, writexl, broom.mixed, qgraph,
               multilevelmediation,
               tidyverse, multilevelTools, parameters, devtools, reghelper
               )
load("../data/df_example1c.RData")
```

## Cross-Level Interaktion / Moderation


Erwarten wir, dass der Effekt von täglichen Schwankungen in X auf Y abhängig von einer Variable ist, die auf Level-2 gemessen wird (z.B. relativ stabile Persönlichkeitsmerkmale), können wir dies mit einer Cross-Level Interaktion testen.

```{r}
head(df_example1c)
```

Wir zentrieren den Moderator "w" auf dem Grand mean (Gesamtmittelwert) für eine einfachere Interpretation der Modellparameter.

```{r}
df_example1c <- df_example1c |> center(w)
head(df_example1c)
```

Die zentrierte Variable heisst "w_c" und wurde am Ende des Datensatz angehängt.

Zunächst berechnen wir das Modell ohne Interaktion von X und W (X*W), aber mit dem Haupteffekt von X und W.


Level 1: $y_{ij} = \beta_{0j} + \beta_{1j}*(X_{ij}-\overline{X_j}) + \beta_{2j}*W_{j} + e_{ij}$

Level 2 (random intercept): $\beta_{0j} = \gamma_{00} + u_{0j}$
Level 2 (random slope for x): $\beta_{1j} = \gamma_{10} + u_{2j}$

```{r}
ri.rs_w_modell <- lmer(y ~ x_dm + w_c + (1 + x_dm | id), data = df_example1c)
model_parameters(ri.rs_w_modell) |> print_html()
```
Der Moderator W hat einen positiven Haupteffekt auf die abhängige Variable.


Als nächstes fügen wir den Interaktionsterm hinzu.

Level 1: $y_{ij} = \beta_{0j} + \beta_{1j}*(X_{ij}-\overline{X_j}) + \beta_{2j}*W_{j} + e_{ij}$

Level 2 (random intercept): $\beta_{0j} = \gamma_{00} + u_{0j}$

Level 2 (random slope for x): $\beta_{1j} = \gamma_{10} + \gamma_{11}*W_{j} + u_{2j}$



```{r}
ri.rs_cli_modell <- lmer(y ~ x_dm + w_c + w_c*x_dm + (1 + x_dm | id), data = df_example1c)
model_parameters(ri.rs_cli_modell) |> print_html()
```
Beachtet, dass mit der eingebauten Interaktion die Haupteffekte nicht mehr interpretiert werden.

### Visualisierung

Visualisierung des Interaktionseffekt mittels der `plot_model()` Funktion.
Standardmässig werden die Simple Slopes an den Extremwerten (Minimum, Maximum) des Moderators geschätzt.

```{r}
plot_model(ri.rs_cli_modell, type = "int", terms = c("x_dm", "w_c"))
ggsave("test.png")
```

Alternativ kann man auch die Werte zum Mittelwerte und bei -1 SD und +1 SD des Moderators anzeigen lassen.

```{r}
plot_model(ri.rs_cli_modell, type = "int", mdrt.values = "meansd")
```
Der Plot zeigt, dass bei höheren Ausprägungen von w der Effekt von x_dm stärker ausfällt.

### Simple Slopes Analyse

Mit Hilfe der `simple_slopes` Funktion aus dem `reghelper` Paket können wir uns die Regressionskoeffizienten einer Simple-Slope Analyse unterziehen.
Die Simple-Slope-Analyse in Mehrebenen-Modellen dient dazu, den Moderationseffekt einer Variablen zu untersuchen, indem die Beziehung zwischen Prädiktor (hier: "x") und abhängiger Variable (hier: "y") auf verschiedenen Ausprägungsniveaus der Moderatorvariablen (hier: "w_c") betrachtet wird. Nach der Schätzung des Mehrebenen-Modells werden die Steigungen (Slopes) für unterschiedliche Werte des Moderators berechnet (z. B. ±1 Standardabweichung oder spezifische Werte), um zu analysieren, ob und wie sich der Effekt des Prädiktors je nach Moderator ändert. Diese Methode hilft zu verstehen, ob die Stärke oder Richtung eines Effekts in Abhängigkeit der Moderatorvariable variiert.

Wir können die spezifischen Werte der Variable automatisch bestimmen (1. Variante) oder manuell setzen (2. Variante). Uns interessieren die Werte, wenn x_dm um eine Einheit steigt und der Moderator unterdurchschnittlich (-1 SD), durchschnittlich, oder überdurchschnittlich (+1 SD) ist. Entsprechend werden die Werte in Variante 2 manuell gesetzt. Die Werte können wir der Abbildung oben entnehmen.

```{r}
simple_slopes(ri.rs_cli_modell)

simple_slopes(ri.rs_cli_modell,
              levels = list(x_dm = c(1,'sstest') ),
              w_c = c(-0.62,0, 0.62, "sstest"))

```
Die Simple Slope Analyse bestätigt die Visualiserung und zeigt, dass der Effekt von x_dm auf y schwächer ausfällt, aber immer noch signifikant positiv ist, wenn der Moderator w_c unterdurchschnittlich ist (Variante 1, Zeile 4, Variante 2, Zeile 2). Der Effekt fällt stärker aus, wenn der Moderator w_c überdurchschnittlich ist (Variante 1, Zeile 6, Variante 2, Zeile 4).


### Within-level Interaktion

Analog zur Cross-level Interaktion gibt es auch Within-level Interaktionen, bei der die Level-1 Anteile von Prädiktorvariablen miteinander interagieren.

Level 1: $y_{ij} = \beta_{0j} + \beta_{1j}*(X_{ij}-\overline{X_j}) + \beta_{2j}*(M_{ij}-\overline{M_j}) + \beta_{3j}*((M_{ij}-\overline{M_j})*(X_{ij}-\overline{X_j})) + e_{ij}$

Level 2 (random intercept): $\beta_{0j} = \gamma_{00} + u_{0j}$

Level 2 (random slope X): $\beta_{1j} = \gamma_{10} + u_{1j}$

Level 2 (random slope M): $\beta_{2j} = \gamma_{20} + u_{2j}$

```{r}
ri.rs_wli_modell <- lmer(y ~ x_dm + m_dm + x_dm*m_dm + (1 + x_dm + m_dm | id), data = df_example1c)
model_parameters(ri.rs_wli_modell) |> print_html()
```

```{r}
plot_model(ri.rs_wli_modell, type = "int", mdrt.values = "meansd")
```

Der Interaktionseffekt ist nicht signifikant. Dies bedeutet, wie der Plot zeigt, dass die Linien bei allen Ausprägungen des Moderators mehr oder wenig parallel sind.
 
## Übung

Wir arbeiten in der Übung mit dem Übungs-Datensatz aus Kapitel 4.
```{r}
load("../data/df_example_cli.RData")

head(df_example_cli)
get_label(df_example_cli)
# alternativ
view_df(df_example_cli)
```

Berechne Modelle mit denen du die folgenden Hypothesen testest: 

H1: Illegitime Aufgaben hängen positiv mit negativem Affekt zusammen.
H2: Der positive Zusammenhang von illegitime Aufgaben mit negativem Affekt fällt schwächer aus, wenn Unterstützung von Kolleg:innen hoch ausgeprägt ist.

Gehe Schritt für Schritt vor und teste erst in einem Modell H1 (verwende dazu den Random Intercept, Random Slope Modell-Code aus dem letzten Kapitel), dann in einem anderen Modell H2.
Urteile, ob die Hypothesen angenommen oder verworfen werden sollten.

:::{.callout-tip collapse="true"}
### Lösung

```{r}
ri.rs_modell <- lmer(negativ ~ illtask_dm  + support + (1 + illtask_dm | id), data = df_example_cli)
parameters(ri.rs_modell)
```
Der Zusammenhang von täglichen illegitimen Aufgaben (illtask_dm)  mit negativem Affekt (negativ) ist signifikant (b = 0.33, p < .001), was Hypothese 1 unterstützt.

```{r}
ri.rs_cli_modell <- lmer(negativ ~ illtask_dm  + support*illtask_dm + (1 + illtask_dm | id), data = df_example_cli)
parameters(ri.rs_cli_modell)

```
Der Interaktionseffekt von täglichen illegitimen AUfgaben mit sozialer Unterstützung durch Kolleg:innen auf negativen Affekt ist nicht signifikant (b = -0.01, p = .89). Hypothese 2 muss somit verworfen werden.

:::

## 1-1-1 Mediation

Im Folgenden erstellen wir ein Mediationsmodellen und spezifizieren bei den Argumenten x, y, und m die die unabhängige, abhängige, und mediierende Variable. Für die abhängige Variablen wählen wir die Rohvariable, für unabhängige und mediierende Variablen die personen-zentrierten Variablen.

Die 1-1-1 Mediation ist die gängigste Variante, in der alle Variablen (X, M[ediator], und Y) auf Tagesebene gemessen werden.

### Daten einlesen

```{r}
load("../data/df_example1.RData")
head(df_example1)
```

Zum Testen verwenden wir zunächst die Funktion `modmed.mlm()`.
Anders als bei den früheren ANalysen steht uns das `parameters` Paket hier nicht zur Verfügung um die Ergebnisse zusammenzufassen. Stattdessen nehmen wir die `summary()` Funktion.

```{r}
fit_mediation <- modmed.mlm(df_example1, "id", "x_dm", "y", "m_dm",
                                random.int.m = FALSE,
                                na.action = na.omit)

summary(fit_mediation$model)
```
Die ausgegebenen Zeilen/Parameter sind etwas kryptisch beschrieben.

- Sm - fixed Intercept von M
- Sy - fixed Intercept von Y
- SmX - fixed Slope von X auf M (a-Pfad)
- SyX - fixed Slope von Y auf X (c'-Pfad)
- SyM - fixed Slope von Y auf M (b-Pfad)

### Bootstrapped Version

Der indirekte Effekt von X auf Y via M (a-Pfad * b-Pfad) der uns in der Mediation von zentralem Interesse ist, ist in der Regel nicht normalverteilt, da ein Produkt zweier (oder mehrerer) Pfadkoeffizienten nicht wie die Pfadkoeffizienten selber approximativ normalverteilt ist. Aufgrund der fehlenden Normalverteilung verwenden wir die Bootstrap-Schätzung, um eine robustere Aussage über die Signifikanz des indirekten Effekts zu bekommen.

```{r}
#| cache: true
boot.custom.results <- boot.modmed.mlm.custom(
  data = df_example1 |> as.data.frame(),
  L2ID = "id",
  X = "x_dm",
  Y = "y",
  M = "m_dm",
  random.int.m = FALSE,
  control = list(opt = "nlm"),
  na.action = na.omit,
  return.type = "all",
  nrep = 1000,
  parallel.type = "parallel",
  ncores = 4,
  seed = 2299)

```

```{r}
summary(boot.custom.results$model)
extract.modmed.mlm(boot.custom.results, type="all")
extract.modmed.mlm(boot.custom.results, type="indirect")
# manual extract of CI
indirect_boot <- tibble(SyM = boot.custom.results[["t"]][,which(names(boot.custom.results[["t0"]]) == "SyM")], 
                        SmX = boot.custom.results[["t"]][,which(names(boot.custom.results[["t0"]]) == "SmX")]) |> 
  mutate(indirect = SyM * SmX)
quantile(indirect_boot$indirect, c(0.025, 0.975), na.rm = TRUE)

# zusammenfassen
indirect_punktschaetzung <- extract.modmed.mlm(boot.custom.results, type="indirect")
indirekt_ci <- quantile(indirect_boot$indirect, c(0.025, 0.975), na.rm = TRUE)
indirekt_zusammenfassung <-
  tibble(Koeffizient = indirect_punktschaetzung,
         LLCI = indirekt_ci[1],
         ULCI = indirekt_ci[2]) |> 
  mutate(across(where(is.numeric), round, 3))

```

Der indirekte Effekt und sein 95% Konfidenzintervall müssen wir aus den Daten extrahieren. Wenn der 95% Konfidenzintervall die 0 ausschliesst (also sowohl unterer als auch oberes Limit entweder unter Null oder über Null liegen) können wir den indirekten Effekt als signifikant ansehen.

In diesem Beispiel finden wir also einen signifikanten indirekten Effekt mit Koeffizient = 0.30, 95% CI = [0.19, 0.41].

LLCI = Lower Limit of Confidence Interval

ULCI = Upper Limit of Confidence Interval

## Übung

Wir arbeiten in der Übung mit einem neuen Datensatz.

Mache dich mit ihm vertraut.
Wie in der Cross-Level Interaktionsübung benutzen wir einen Datensatz in dem die Variablen "labelled" sind, also Beschriftungen haben. Wir können die Labels mit `get_label()` abrufen.

```{r}
load("../data/df_111_uebung.RData")

head(df_111_uebung)
get_label(df_111_uebung)
# alternativ
view_df(df_111_uebung)
```

Berechne Modelle mit denen du die folgenden Hypothesen testest: 

H1: Tägliche Wertschätzung durch Vorgesetzte und Kolleg:innen hängen positiv mit dem täglichen Selbstwert zusammen.
H2: Täglicher Selbstwert hängt positiv mit täglichem proaktivem Helfen zusammen.
H3: Es gibt einen positiven indirekten Zusammenhang zwischen täglicher Wertschätzung und täglichem proaktiven Helfen, vermittel durch den täglichen Selbstwert.

Teste die Hypothesen in einem Modell mittels der `boot.modmed.mlm.custom()` Funktion. Urteile, ob die Hypothesen angenommen oder verworfen werden sollten.

::: {.callout-tip collapse="true"}
### Lösung

```{r}
# | cache: true
boot.custom.results <- boot.modmed.mlm.custom(
  data = df_111_uebung |> remove_all_labels(),
  L2ID = "id",
  X = "wertschaetz_dm",
  Y = "helfen",
  M = "selbstwert_dm",
  random.int.m = FALSE,
  control = list(opt = "nlm"),
  na.action = na.omit,
  return.type = "all",
  nrep = 1000,
  parallel.type = "parallel",
  ncores = 4,
  seed = 2299)
```


```{r}
summary(boot.custom.results$model)
extract.modmed.mlm(boot.custom.results, type="all")
extract.modmed.mlm(boot.custom.results, type="indirect")
# manual extract of CI
indirect_boot <- tibble(SyM = boot.custom.results[["t"]][,which(names(boot.custom.results[["t0"]]) == "SyM")], 
                        SmX = boot.custom.results[["t"]][,which(names(boot.custom.results[["t0"]]) == "SmX")]) |> 
  mutate(indirect = SyM * SmX)
quantile(indirect_boot$indirect, c(0.025, 0.975), na.rm = TRUE)

# zusammenfassen
indirect_punktschaetzung <- extract.modmed.mlm(boot.custom.results, type="indirect")
indirekt_ci <- quantile(indirect_boot$indirect, c(0.025, 0.975), na.rm = TRUE)
indirekt_zusammenfassung <-
  tibble(Koeffizient = indirect_punktschaetzung,
         LLCI = indirekt_ci[1],
         ULCI = indirekt_ci[2]) |> 
  mutate(across(where(is.numeric), round, 3))
indirekt_zusammenfassung
```
H1 wird unterstützt (SmX: b = 0.40, *p* < .001). 
H2 wird verworfen (SyM: b = 0.14, *p* < .40).
H3: wird entsprechend auch verworfen (95% CI des indirekten Effekt schliesst die 0 ein). Es besteht aber ein direkter Zusammenhang zwischen X und Y (SyX: b = 0.33, *p* < .001), der, anders als angenommen, nicht indirekt über Selbstwert vermittelt wird. 

:::