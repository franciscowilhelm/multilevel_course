[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Tagebuchstudien und Mehrebenenmodelle",
    "section": "",
    "text": "1 Einleitung\nDieses Dokument enthält Anleitungen und Übungen zur Analyse von Daten aus Tagebuchstudien mittels Mehrebenenmodellen. Es ist im Rahmen des Seminars zu Tagebuchstudien in Psychologie an der Uni Bern entstanden.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Kapitel 1: Einleitung</span>"
    ]
  },
  {
    "objectID": "index.html#voraussetzungen",
    "href": "index.html#voraussetzungen",
    "title": "Tagebuchstudien und Mehrebenenmodelle",
    "section": "1.1 Voraussetzungen",
    "text": "1.1 Voraussetzungen\nMaterialien:\n\nRStudio (erstellt RStudio 2024.12.0, Build 467)\nR (erstellt mit R 4.4.2)\nInstallation von Paketen mit dem Code unten.\n\nKenntnisse:\n\nData Wrangling in R, Umgang mit R-Notebooks, s. Anhang: Data Wrangling, sowie https://methodenlehre.github.io/einfuehrung-in-R/\nStatistisches Wissen zu linearen Modellen (Regressionen) und Testkonstruktion (Likert-Skalen, Reliabilitätsanalyse)\n\n\n1.1.1 Installation von R-Paketen, die im Kurs verwendet werden\nDer Code unten installiert, falls noch nicht vorhanden, den “pacman” Paketmanager und danach alle R-Pakete, die für den Kurs benötigt werden.\n\nif (!require(\"pacman\")) install.packages(\"pacman\")\n\npacman::p_load(devtools)\nif (!require(\"multilevelmediation\")) devtools::install_github(\"falkcarl/multilevelmediation\")\nif (!require(\"franzpak\")) devtools::install_github(\"franciscowilhelm/franzpak\")\n\npacman::p_load(lmerTest, haven, brms, psych,\n               sjmisc, sjlabelled, sjPlot, writexl, broom.mixed, qgraph,\n               tidyverse, multilevelTools, parameters, devtools,\n               multilevelmediation, reghelper)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Kapitel 1: Einleitung</span>"
    ]
  },
  {
    "objectID": "01 Data Preparation Item Level.html",
    "href": "01 Data Preparation Item Level.html",
    "title": "2  Kapitel 2: Datenaufbereitung",
    "section": "",
    "text": "2.1 Pakete installieren und laden\nif (!require(\"pacman\")) install.packages(\"pacman\")\n\nLade nötiges Paket: pacman\n\npacman::p_load(haven, psych,\n               sjmisc, sjPlot, writexl,\n               tidyverse, multilevelTools)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Kapitel 2: Datenaufbereitung</span>"
    ]
  },
  {
    "objectID": "01 Data Preparation Item Level.html#daten-einlesen",
    "href": "01 Data Preparation Item Level.html#daten-einlesen",
    "title": "2  Kapitel 2: Datenaufbereitung",
    "section": "2.2 Daten einlesen",
    "text": "2.2 Daten einlesen\nMit load() können wir .RData Dateien einlesen (für weitergehende Infos s. auch Einführung in R, Kapitel 3.2.4.)\n\nload(\"../data/df_cfa_wide.RData\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Kapitel 2: Datenaufbereitung</span>"
    ]
  },
  {
    "objectID": "01 Data Preparation Item Level.html#daten-ansehen",
    "href": "01 Data Preparation Item Level.html#daten-ansehen",
    "title": "2  Kapitel 2: Datenaufbereitung",
    "section": "2.3 Daten ansehen",
    "text": "2.3 Daten ansehen\nDer Datensatz hat 131 Spalten (ncol()) und 100 Zeilen (nrow()) (eine pro Person).\nWie wir mit names() sehen, gibt es die Variablen id für die Personidentifikation (jede Person hat ihre eigene Nummer), a1-a5, b1-b5, und c1-c3. Da jeder Tag (1-10 Tage) von jeder Variable seine eigene Spalte bekommt (t1-t10) gibt es viele Spalten und wir nennen das Datenformat daher breites Datenformat ( wide format).\na,b und c bilden jeweils eine Skala mit 5 bzw. bei c 3 Indikatoren.\nMit head() können wir einen Blick in die Daten werfen.\n\nncol(df_cfa_wide)\n\n[1] 131\n\nnrow(df_cfa_wide)\n\n[1] 100\n\nnames(df_cfa_wide)\n\n  [1] \"id\"     \"a1_t1\"  \"a1_t2\"  \"a1_t3\"  \"a1_t4\"  \"a1_t5\"  \"a1_t6\"  \"a1_t7\" \n  [9] \"a1_t8\"  \"a1_t9\"  \"a1_t10\" \"a2_t1\"  \"a2_t2\"  \"a2_t3\"  \"a2_t4\"  \"a2_t5\" \n [17] \"a2_t6\"  \"a2_t7\"  \"a2_t8\"  \"a2_t9\"  \"a2_t10\" \"a3_t1\"  \"a3_t2\"  \"a3_t3\" \n [25] \"a3_t4\"  \"a3_t5\"  \"a3_t6\"  \"a3_t7\"  \"a3_t8\"  \"a3_t9\"  \"a3_t10\" \"a4_t1\" \n [33] \"a4_t2\"  \"a4_t3\"  \"a4_t4\"  \"a4_t5\"  \"a4_t6\"  \"a4_t7\"  \"a4_t8\"  \"a4_t9\" \n [41] \"a4_t10\" \"a5_t1\"  \"a5_t2\"  \"a5_t3\"  \"a5_t4\"  \"a5_t5\"  \"a5_t6\"  \"a5_t7\" \n [49] \"a5_t8\"  \"a5_t9\"  \"a5_t10\" \"b1_t1\"  \"b1_t2\"  \"b1_t3\"  \"b1_t4\"  \"b1_t5\" \n [57] \"b1_t6\"  \"b1_t7\"  \"b1_t8\"  \"b1_t9\"  \"b1_t10\" \"b2_t1\"  \"b2_t2\"  \"b2_t3\" \n [65] \"b2_t4\"  \"b2_t5\"  \"b2_t6\"  \"b2_t7\"  \"b2_t8\"  \"b2_t9\"  \"b2_t10\" \"b3_t1\" \n [73] \"b3_t2\"  \"b3_t3\"  \"b3_t4\"  \"b3_t5\"  \"b3_t6\"  \"b3_t7\"  \"b3_t8\"  \"b3_t9\" \n [81] \"b3_t10\" \"b4_t1\"  \"b4_t2\"  \"b4_t3\"  \"b4_t4\"  \"b4_t5\"  \"b4_t6\"  \"b4_t7\" \n [89] \"b4_t8\"  \"b4_t9\"  \"b4_t10\" \"b5_t1\"  \"b5_t2\"  \"b5_t3\"  \"b5_t4\"  \"b5_t5\" \n [97] \"b5_t6\"  \"b5_t7\"  \"b5_t8\"  \"b5_t9\"  \"b5_t10\" \"c1_t1\"  \"c1_t2\"  \"c1_t3\" \n[105] \"c1_t4\"  \"c1_t5\"  \"c1_t6\"  \"c1_t7\"  \"c1_t8\"  \"c1_t9\"  \"c1_t10\" \"c2_t1\" \n[113] \"c2_t2\"  \"c2_t3\"  \"c2_t4\"  \"c2_t5\"  \"c2_t6\"  \"c2_t7\"  \"c2_t8\"  \"c2_t9\" \n[121] \"c2_t10\" \"c3_t1\"  \"c3_t2\"  \"c3_t3\"  \"c3_t4\"  \"c3_t5\"  \"c3_t6\"  \"c3_t7\" \n[129] \"c3_t8\"  \"c3_t9\"  \"c3_t10\"\n\nhead(df_cfa_wide)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\na1_t1\na1_t2\na1_t3\na1_t4\na1_t5\na1_t6\na1_t7\na1_t8\na1_t9\na1_t10\na2_t1\na2_t2\na2_t3\na2_t4\na2_t5\na2_t6\na2_t7\na2_t8\na2_t9\na2_t10\na3_t1\na3_t2\na3_t3\na3_t4\na3_t5\na3_t6\na3_t7\na3_t8\na3_t9\na3_t10\na4_t1\na4_t2\na4_t3\na4_t4\na4_t5\na4_t6\na4_t7\na4_t8\na4_t9\na4_t10\na5_t1\na5_t2\na5_t3\na5_t4\na5_t5\na5_t6\na5_t7\na5_t8\na5_t9\na5_t10\nb1_t1\nb1_t2\nb1_t3\nb1_t4\nb1_t5\nb1_t6\nb1_t7\nb1_t8\nb1_t9\nb1_t10\nb2_t1\nb2_t2\nb2_t3\nb2_t4\nb2_t5\nb2_t6\nb2_t7\nb2_t8\nb2_t9\nb2_t10\nb3_t1\nb3_t2\nb3_t3\nb3_t4\nb3_t5\nb3_t6\nb3_t7\nb3_t8\nb3_t9\nb3_t10\nb4_t1\nb4_t2\nb4_t3\nb4_t4\nb4_t5\nb4_t6\nb4_t7\nb4_t8\nb4_t9\nb4_t10\nb5_t1\nb5_t2\nb5_t3\nb5_t4\nb5_t5\nb5_t6\nb5_t7\nb5_t8\nb5_t9\nb5_t10\nc1_t1\nc1_t2\nc1_t3\nc1_t4\nc1_t5\nc1_t6\nc1_t7\nc1_t8\nc1_t9\nc1_t10\nc2_t1\nc2_t2\nc2_t3\nc2_t4\nc2_t5\nc2_t6\nc2_t7\nc2_t8\nc2_t9\nc2_t10\nc3_t1\nc3_t2\nc3_t3\nc3_t4\nc3_t5\nc3_t6\nc3_t7\nc3_t8\nc3_t9\nc3_t10\n\n\n\n\n1\n3.336252\n2.149828\n1.613518\n3.351085\n3.320900\n4.173775\n3.653771\n1.926106\n5.621661\n4.948758\n3.380463\n5.110309\n3.004133\n3.852294\n3.694431\n5.658948\n4.973751\n4.999227\n5.123906\n6.090460\n3.223528\n5.678413\n2.503233\n4.972103\n4.703663\n3.273027\n3.187604\n3.664482\n5.464105\n3.765162\n4.399347\n2.765556\n1.898476\n2.612551\n3.476859\n4.192700\n2.856953\n4.112356\n4.579488\n3.134414\n3.542602\n2.387270\n2.807670\n3.233779\n4.210036\n3.565438\n3.293944\n3.909548\n5.635526\n4.620410\n3.370896\n2.486919\n0.991958\n2.248097\n1.953658\n1.544111\n2.103968\n1.763424\n3.087552\n1.618470\n1.697640\n0.952220\n-0.685685\n0.004118\n0.675750\n-0.373186\n1.938302\n0.447036\n3.860272\n1.211009\n0.584167\n2.101517\n0.003147\n0.711264\n0.921623\n1.303905\n1.201749\n0.899882\n1.797242\n0.734580\n1.576649\n0.331000\n-0.517730\n2.185949\n0.284884\n1.687402\n1.388842\n0.160632\n2.144261\n1.205662\n2.847195\n2.552073\n1.955846\n2.028044\n2.361978\n2.539967\n2.125510\n1.206909\n4.844395\n4.320178\n4.325797\n3.364003\n2.582169\n2.918614\n2.829237\n4.141474\n2.711044\n4.787052\n4.594232\n2.511473\n1.030847\n5.711729\n2.659834\n3.163276\n3.910432\n5.234767\n5.515933\n5.206142\n4.431722\n4.953160\n3.822098\n3.613752\n2.155132\n2.463234\n2.739723\n3.409232\n3.488225\n1.453246\n4.117747\n3.745528\n\n\n2\n3.707018\n2.377418\n1.854018\n4.632683\n2.479164\n2.234632\n4.485121\n4.011457\n2.427658\n2.600831\n3.996684\n3.074568\n3.716554\n3.796472\n3.108752\n2.922636\n4.654462\n4.431057\n3.497468\n4.130753\n0.810690\n2.874266\n3.669414\n2.478778\n2.406462\n2.515853\n3.129976\n3.718570\n2.542158\n2.606330\n3.515638\n4.128262\n3.577047\n4.258751\n4.238509\n3.267878\n4.119021\n2.712250\n2.601381\n5.293957\n2.907960\n2.834590\n3.827659\n5.278379\n3.967381\n4.134327\n5.923659\n4.251589\n3.292468\n3.639972\n2.323243\n2.042416\n2.601619\n0.235322\n1.990456\n3.388960\n0.995331\n3.325457\n2.207927\n0.221311\n2.990608\n1.476811\n2.349784\n3.097647\n2.047705\n2.722032\n3.112804\n1.368452\n2.251611\n1.587188\n1.013232\n2.926646\n2.095343\n2.858416\n3.019904\n1.726097\n3.515165\n1.348090\n1.890474\n2.311975\n1.190393\n2.184150\n1.549624\n0.452129\n1.513757\n1.432716\n1.950500\n2.007023\n0.249291\n-0.504312\n2.010378\n4.018477\n3.410691\n3.063017\n3.897992\n2.469268\n2.906900\n2.914951\n0.608605\n2.239330\n2.576924\n1.208644\n2.606353\n3.886131\n3.856964\n3.332155\n0.597512\n2.731819\n2.110466\n2.687502\n-1.710033\n-0.670529\n-0.330814\n-0.601643\n-0.251286\n0.439045\n0.734464\n0.066167\n-0.849054\n-0.757472\n0.351828\n0.095795\n0.897598\n2.615174\n0.455632\n2.211615\n-0.235576\n0.389909\n-0.160126\n1.833746\n\n\n3\n5.177071\n-0.128053\n2.797632\n0.303081\n4.314881\n2.337009\n3.575595\n1.818855\n-0.306364\n1.614770\n2.958702\n2.735971\n2.978813\n4.107814\n4.661105\n3.033462\n2.912859\n3.754350\n1.986925\n2.453018\n5.346752\n4.501127\n4.825683\n4.908117\n5.724673\n5.153263\n4.766531\n5.198076\n1.471673\n3.829653\n4.772178\n2.755005\n4.204091\n2.631057\n4.744125\n3.983818\n2.875329\n3.684137\n1.252706\n1.649124\n5.782683\n4.648184\n3.675335\n5.918703\n5.729757\n5.027148\n4.950459\n5.555384\n2.874046\n2.074345\n3.034341\n5.163917\n1.010752\n1.666880\n1.295466\n1.477020\n1.009490\n1.175458\n1.284057\n3.434230\n4.263902\n3.116927\n2.598624\n2.281766\n4.053404\n2.417430\n1.154442\n2.357182\n-0.103946\n2.599341\n3.981286\n1.433954\n2.329805\n3.582351\n2.509821\n-0.341738\n1.558373\n2.687843\n1.337345\n3.732375\n3.988386\n2.509786\n2.058585\n3.740040\n3.256067\n3.500106\n0.782067\n3.601466\n0.922850\n4.635307\n3.024556\n1.150083\n3.052157\n3.163149\n2.655710\n0.093386\n-0.073910\n2.227515\n1.712568\n2.898763\n2.820979\n1.664689\n2.688626\n2.657114\n1.381627\n2.417342\n1.443182\n2.776111\n2.248535\n2.684371\n1.748407\n2.869058\n1.052509\n3.174517\n0.118054\n0.789280\n2.679447\n0.740977\n1.135104\n0.980832\n1.537544\n2.950929\n1.429920\n2.534687\n3.792833\n1.161559\n0.105494\n2.915895\n1.714465\n2.815621\n\n\n4\n4.705740\n3.597286\n2.948942\n2.098839\n2.783596\n4.420878\n1.358347\n3.848268\n3.714631\n2.284839\n4.038396\n4.916627\n2.739167\n3.144930\n2.224095\n2.968036\n2.365223\n3.665594\n2.585768\n3.208773\n5.110747\n4.059650\n3.327694\n4.411642\n3.937307\n5.154507\n3.126869\n4.554551\n3.766840\n4.039097\n5.965881\n5.027371\n4.130869\n5.175652\n4.037358\n5.245027\n3.205133\n3.004498\n6.786242\n4.499281\n3.958800\n3.838211\n3.211688\n2.475119\n2.191741\n2.052676\n2.687921\n2.079803\n3.929772\n1.621818\n3.621642\n3.197431\n2.838179\n1.280215\n1.746913\n2.267367\n1.597599\n2.441468\n1.211542\n4.138991\n1.342898\n1.821522\n1.688056\n2.463308\n2.030884\n0.815056\n0.953910\n1.729489\n1.332197\n3.093290\n2.400477\n2.873127\n1.997939\n1.791812\n-0.960833\n0.893946\n0.647417\n1.110916\n1.748169\n2.121472\n1.952886\n2.904973\n0.878772\n1.269630\n0.835469\n-1.070358\n-0.541286\n1.063053\n1.485312\n3.607293\n4.027168\n3.804839\n2.787383\n2.807136\n2.706166\n2.527843\n1.675010\n2.839636\n3.124758\n4.327591\n-0.571315\n2.285224\n1.057377\n1.803651\n0.992669\n1.980404\n3.310448\n1.662047\n2.537811\n1.245361\n1.490392\n0.456182\n1.328019\n1.697168\n0.693560\n0.252673\n2.728439\n1.103803\n1.332902\n0.163830\n0.043749\n0.744745\n0.204956\n-0.370906\n-1.022587\n-0.403501\n1.095947\n0.274934\n1.170815\n-1.658070\n\n\n5\n3.949976\n3.330208\n5.413867\n3.719810\n5.798861\n3.088709\n4.012137\n5.875070\n3.181456\n4.931577\n3.317796\n5.810359\n5.343310\n3.928448\n3.798973\n3.932334\n2.986737\n6.926680\n4.932457\n6.716081\n3.673230\n3.927261\n4.515421\n3.791699\n4.846026\n3.398835\n2.273474\n4.371252\n1.762524\n3.275910\n5.841838\n8.072948\n6.721671\n6.987111\n5.944237\n4.489158\n4.921571\n7.603350\n6.165390\n6.983403\n3.389670\n5.893949\n3.749111\n4.411794\n2.873486\n2.611568\n1.286889\n4.646997\n3.107310\n4.433750\n1.701253\n0.278520\n3.249563\n2.181162\n3.107517\n0.092424\n1.985821\n1.740418\n3.187945\n2.244310\n3.361174\n3.497546\n3.372372\n2.430237\n5.397523\n3.270945\n3.053623\n1.919141\n3.688502\n2.961518\n4.337413\n3.496237\n5.441549\n3.444545\n4.486709\n4.455020\n2.470650\n5.844872\n4.583409\n6.108861\n4.302733\n2.764837\n3.876676\n3.527337\n5.128605\n2.163503\n1.886539\n1.734753\n3.437857\n3.740089\n4.179862\n3.775715\n5.299768\n2.953386\n3.807893\n2.537854\n2.901724\n4.785203\n5.926126\n4.928503\n3.053878\n1.885364\n4.448834\n3.900540\n4.728735\n2.129385\n3.805631\n2.089345\n3.743529\n2.992289\n1.790360\n1.515488\n3.618075\n3.781413\n4.205560\n1.303834\n3.673459\n3.327604\n3.160806\n3.722098\n1.817841\n2.362278\n2.812572\n4.554119\n3.287976\n3.279677\n1.435943\n3.242930\n0.500366\n5.079764\n\n\n6\n2.274255\n2.290222\n1.376191\n2.173916\n2.099371\n3.312339\n2.172030\n2.595873\n2.289308\n1.580778\n2.787734\n2.067549\n2.180852\n3.302369\n1.863362\n3.760236\n2.294264\n2.135892\n1.550506\n2.432511\n3.703579\n2.047107\n3.065654\n1.978181\n2.963593\n2.955959\n3.468359\n4.343268\n3.525407\n3.837417\n4.151001\n0.835873\n1.884775\n2.608722\n3.012065\n2.776904\n2.578840\n3.399579\n3.577152\n3.039595\n1.512579\n0.621510\n1.092427\n1.911605\n1.368582\n2.511084\n0.839038\n3.272104\n1.121144\n1.740897\n2.996994\n-1.267884\n2.586945\n2.184757\n-0.124601\n2.601747\n1.747253\n2.520691\n4.051763\n2.738223\n1.022146\n-1.129770\n1.219736\n-0.032099\n2.843606\n-1.122089\n0.739502\n2.138073\n0.272516\n0.625661\n2.134281\n0.231331\n2.861858\n1.303966\n1.199804\n1.300905\n1.312581\n2.266003\n3.106999\n2.869239\n2.308207\n1.068449\n2.414964\n1.894137\n2.681821\n0.512435\n2.125864\n2.787195\n2.595406\n2.191860\n2.267998\n0.203488\n2.181351\n1.670791\n0.222494\n0.947280\n2.464313\n2.733245\n2.599860\n1.042442\n1.648781\n0.598068\n0.225724\n0.521410\n1.669001\n1.384766\n2.299040\n2.014711\n2.088084\n0.651604\n2.356883\n0.718648\n1.309239\n2.011107\n1.617811\n3.844703\n1.838274\n2.215482\n2.364317\n1.437971\n2.745956\n3.067538\n3.096565\n2.927631\n4.206480\n3.969140\n5.377585\n2.509150\n2.817378\n1.073844",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Kapitel 2: Datenaufbereitung</span>"
    ]
  },
  {
    "objectID": "01 Data Preparation Item Level.html#daten-transformieren-langformat",
    "href": "01 Data Preparation Item Level.html#daten-transformieren-langformat",
    "title": "2  Kapitel 2: Datenaufbereitung",
    "section": "2.4 Daten transformieren: Langformat",
    "text": "2.4 Daten transformieren: Langformat\nAls erstes transformieren wir die Daten vom Breit- ins Langformat, so dass jede Messung (Tag 1-Tag 10) eine eigene Zeile bekommt. Diese Variable nennen wir “time”. Im ersten Schritt machen wir mit pivot_longer() den Datensatz seeehr lang, es bekommt nämlich jede Messung von jeder Variable ihre eigenen Zeile. Wir machen den Datensatz dann im zweiten Schritt mit pivot_wider() wieder etwas breiter mit dem Ziel, eine Zeile pro Person und Tag zu bekommen, und jeweils eine Spalte pro Item.\nDie Funktionsweise von pivot_longer() und pivot_wider() ist in der Einführung zu R, Kapitel 4.3 ausführlicher beschrieben.\n\ndf_cfa_superlong &lt;- df_cfa_wide |&gt; \n  pivot_longer(\n    cols = -id, # All columns except id\n    names_to = c(\"variable\", \"time\"), # Namensgebende Spalten sollen heissen: variable, time\n    names_sep = \"_t\" \n    # Namensgebende Spalten anhand \"_t_ separieren (z.B. \"a1_t1\" --&gt; gespalten in \"a1\" und \"1\", \"_t\" ist der Separator)\n  ) \n\nhead(df_cfa_superlong)\n\n\n\n\n\nid\nvariable\ntime\nvalue\n\n\n\n\n1\na1\n1\n3.336252\n\n\n1\na1\n2\n2.149828\n\n\n1\na1\n3\n1.613518\n\n\n1\na1\n4\n3.351085\n\n\n1\na1\n5\n3.320900\n\n\n1\na1\n6\n4.173775\n\n\n\n\n\n\n\ndf_cfa_long &lt;- df_cfa_superlong |&gt; \n  pivot_wider(names_from = variable, #namen aus variable\n              values_from = value) |&gt;  # werte aus \"value\" (Standardname)\n  mutate(time = as.numeric(time)) # time ist eine Zahl von 1-10, wurde aber zuvor als Character-Vector abgespeichert\n\nhead(df_cfa_long)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\ntime\na1\na2\na3\na4\na5\nb1\nb2\nb3\nb4\nb5\nc1\nc2\nc3\n\n\n\n\n1\n1\n3.336252\n3.380463\n3.223528\n4.399347\n3.542602\n3.370896\n1.697640\n0.584167\n1.576649\n2.847195\n4.325797\n1.030847\n3.822098\n\n\n1\n2\n2.149828\n5.110309\n5.678413\n2.765556\n2.387270\n2.486919\n0.952220\n2.101517\n0.331000\n2.552073\n3.364003\n5.711729\n3.613752\n\n\n1\n3\n1.613518\n3.004133\n2.503233\n1.898476\n2.807670\n0.991958\n-0.685685\n0.003147\n-0.517730\n1.955846\n2.582169\n2.659834\n2.155132\n\n\n1\n4\n3.351085\n3.852294\n4.972103\n2.612551\n3.233779\n2.248097\n0.004118\n0.711264\n2.185949\n2.028044\n2.918614\n3.163276\n2.463234\n\n\n1\n5\n3.320900\n3.694431\n4.703663\n3.476859\n4.210036\n1.953658\n0.675750\n0.921623\n0.284884\n2.361978\n2.829237\n3.910432\n2.739723\n\n\n1\n6\n4.173775\n5.658948\n3.273027\n4.192700\n3.565438\n1.544111\n-0.373186\n1.303905\n1.687402\n2.539967\n4.141474\n5.234767\n3.409232\n\n\n\n\n\n\nDas Ergebnis:\n\neine Zeile pro Person (id) und Messung (time). Die Spalten id und time identifizieren also für jede Zeile, von welcher Person und welchem Tag die Werte in den folgenden Spalten kommen.\neine Spalte pro Variable (a1-a5, b1-b5, c1-c3)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Kapitel 2: Datenaufbereitung</span>"
    ]
  },
  {
    "objectID": "01 Data Preparation Item Level.html#daten-transformieren-skalenscores-erstellen",
    "href": "01 Data Preparation Item Level.html#daten-transformieren-skalenscores-erstellen",
    "title": "2  Kapitel 2: Datenaufbereitung",
    "section": "2.5 Daten transformieren: Skalenscores erstellen",
    "text": "2.5 Daten transformieren: Skalenscores erstellen\nAls nächstes können wir mittels summarise() die Skalenscores erstellen. Wir verwenden eine simple Form der Skalenerstellung bei dem der Mittelwert aller vorhandenen Items einer Skala rowMeans(...) verwendet wird.\n\ndf_cfa_long_scores &lt;- df_cfa_long |&gt; group_by(id, time) |&gt; \n  summarise(\n    a = rowMeans(across(starts_with(\"a\")), na.rm = TRUE),\n    b = rowMeans(across(starts_with(\"b\")), na.rm = TRUE),\n    c = rowMeans(across(starts_with(\"c\")), na.rm = TRUE),\n    .groups = \"drop\" # group_by() wieder aufheben für den finalen Datensatz\n  )\n\n(Best-practice ist es bei fehlenden Daten genau hinzuschauen und nur dann einen Skalenwert zu erstellen, wenn die Personen zu einen gewissen Prozentsatz aller Items eine Antwort geben (etwa 2/3). Eine solche Funktion könnten wir programmieren, lassen es aber für das Beispiel weg.)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Kapitel 2: Datenaufbereitung</span>"
    ]
  },
  {
    "objectID": "01 Data Preparation Item Level.html#daten-transformieren-zentrierung",
    "href": "01 Data Preparation Item Level.html#daten-transformieren-zentrierung",
    "title": "2  Kapitel 2: Datenaufbereitung",
    "section": "2.6 Daten transformieren: Zentrierung",
    "text": "2.6 Daten transformieren: Zentrierung\nFür die spätere Verwendung zerlegen wir die Rohvariablen mittels person-mean Zentrierung. Wir zentrieren wir die Skalenvariablen, die täglich gemessen werden (aber nicht Baseline-Variablen), mittels de_mean(). de_mean() nimmt als Argumente (a) mit Komma getrennte Namen der Variablen, die wir zentrieren wollen (mehrere auf einmal ist möglich), (b) mittels grp = Argument die identifizierende Variable für die Gruppenzugehörigkeit in Anführungszeichen (\"id\".\n\ndf_cfa_long_scores &lt;- df_cfa_long_scores |&gt; \n  de_mean(a,b, c, grp = \"id\")\nhead(df_cfa_long_scores)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\ntime\na\nb\nc\na_dm\nb_dm\nc_dm\na_gm\nb_gm\nc_gm\n\n\n\n\n1\n1\n3.576438\n2.0153094\n3.059581\n-0.2566380\n0.4476044\n-0.5267811\n3.833076\n1.567705\n3.586362\n\n\n1\n2\n3.618275\n1.6847458\n4.229828\n-0.2148012\n0.1170408\n0.6434662\n3.833076\n1.567705\n3.586362\n\n\n1\n3\n2.365406\n0.3495072\n2.465712\n-1.4676704\n-1.2181978\n-1.1206501\n3.833076\n1.567705\n3.586362\n\n\n1\n4\n3.604362\n1.4354944\n2.848375\n-0.2287140\n-0.1322106\n-0.7379871\n3.833076\n1.567705\n3.586362\n\n\n1\n5\n3.881178\n1.2395786\n3.159797\n0.0481014\n-0.3281264\n-0.4265645\n3.833076\n1.567705\n3.586362\n\n\n1\n6\n4.172778\n1.3404398\n4.261824\n0.3397012\n-0.2272652\n0.6754625\n3.833076\n1.567705\n3.586362\n\n\n\n\n\n\nAls Ergebnis erhalten wir die zusätzlichen Variablen a, b, c jeweils mit “_dm” und “_gm”. Was verbirgt sich dahinter? Wir haben einen Datensatz mit den unzentrierten / Rohvariablen der Skalen (ohne Suffix), den zentrierten Variablen (Suffix _dm) und den Mittelwerten der Personen (Suffix _gm), den wir zur weiteren Verwendung auch abspeichern.\nDamit ist die Transformation der Daten abgeschlossen! Wir können die Datensätze - “df_cfa_long” für die Items und “df_cfa_long_scores” für die Skalen nun abspeichern.\n\nsave(df_cfa_long, df_cfa_long_scores, file = \"../data/df_cfa_long.RData\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Kapitel 2: Datenaufbereitung</span>"
    ]
  },
  {
    "objectID": "01 Data Preparation Item Level.html#überprüfe-dein-verständnis",
    "href": "01 Data Preparation Item Level.html#überprüfe-dein-verständnis",
    "title": "2  Kapitel 2: Datenaufbereitung",
    "section": "2.7 Überprüfe dein Verständnis",
    "text": "2.7 Überprüfe dein Verständnis\n\nbeispiel_zentrierung &lt;- df_cfa_long_scores |&gt; \n  filter(id == 1) |&gt; \n  select(id, time, a, a_dm, a_gm)\n\nbeispiel_zentrierung\n\n\n\n\n\nid\ntime\na\na_dm\na_gm\n\n\n\n\n1\n1\n3.576438\n-0.2566380\n3.833076\n\n\n1\n2\n3.618275\n-0.2148012\n3.833076\n\n\n1\n3\n2.365406\n-1.4676704\n3.833076\n\n\n1\n4\n3.604362\n-0.2287140\n3.833076\n\n\n1\n5\n3.881178\n0.0481014\n3.833076\n\n\n1\n6\n4.172778\n0.3397012\n3.833076\n\n\n1\n7\n3.593205\n-0.2398718\n3.833076\n\n\n1\n8\n3.722344\n-0.1107326\n3.833076\n\n\n1\n9\n5.284937\n1.4518608\n3.833076\n\n\n1\n10\n4.511841\n0.6787644\n3.833076\n\n\n\n\n\n\nWarum ist der Wert, den Person 1 in “a_gm” hat, in jeder Zeile gleich, nicht aber bei “a_dm” und “a”? Wie müsste man “a” transformieren, damit man auf “a_gm” und “a_dm” kommt? Denke an die mathematischen Operationen die du in mutate() eingeben müsstest, wie Plus, Minus ( +, -, /, …) und die Funktion für Mittelwert ( mean()).\n\n\n\n\n\n\nLösung\n\n\n\n\n\nDie Variable a ist die Rohvariable, die den gemessenen Wert auf der Skala an jedem Tag angibt. Variablen mit “_gm” und “_dm” werden von sjmisc::de_mean() erstellt. Variablen mit “_gm” stehen für den Mittelwert der Person über alle Tage hinweg. Variablen mit “_dm” stehen für die täglichen Abweichungen vom Mittelwert der Person. “a_dm” ergibt sich aus: \\(a = a - a\\_gm\\). Wir können dies auch in R replizieren mit:\n\nbeispiel_zentrierung |&gt; \n  mutate(a_gm_manuell = mean(a),\n         a_dm_manuell = a - a_gm_manuell)\n\n\n\n\n\nid\ntime\na\na_dm\na_gm\na_gm_manuell\na_dm_manuell\n\n\n\n\n1\n1\n3.576438\n-0.2566380\n3.833076\n3.833076\n-0.2566380\n\n\n1\n2\n3.618275\n-0.2148012\n3.833076\n3.833076\n-0.2148012\n\n\n1\n3\n2.365406\n-1.4676704\n3.833076\n3.833076\n-1.4676704\n\n\n1\n4\n3.604362\n-0.2287140\n3.833076\n3.833076\n-0.2287140\n\n\n1\n5\n3.881178\n0.0481014\n3.833076\n3.833076\n0.0481014\n\n\n1\n6\n4.172778\n0.3397012\n3.833076\n3.833076\n0.3397012\n\n\n1\n7\n3.593205\n-0.2398718\n3.833076\n3.833076\n-0.2398718\n\n\n1\n8\n3.722344\n-0.1107326\n3.833076\n3.833076\n-0.1107326\n\n\n1\n9\n5.284937\n1.4518608\n3.833076\n3.833076\n1.4518608\n\n\n1\n10\n4.511841\n0.6787644\n3.833076\n3.833076\n0.6787644",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Kapitel 2: Datenaufbereitung</span>"
    ]
  },
  {
    "objectID": "01 Data Preparation Item Level.html#übung-datenaufbereitung",
    "href": "01 Data Preparation Item Level.html#übung-datenaufbereitung",
    "title": "2  Kapitel 2: Datenaufbereitung",
    "section": "2.8 Übung Datenaufbereitung",
    "text": "2.8 Übung Datenaufbereitung\nSchau dir den Datensatz df_cfa_exercise an und repliziere die Schritte oben:\n\nDaten in Langformat transformieren und als df_uebung_lang &lt;- zuweisen.\nSkalenscores für x und y erstellen und als df_uebung_lang_scores &lt;- zuweisen.\nSkalenscores für x und y zentrieren (weiterhin in df_uebung_lang_scores).\n\nDu kannst dazu den Code von oben wiederverwenden und auf den hier verwendeten Datensatz und seine Variablen anpassen.\n\nload(\"../data/df_cfa_exercise.RData\")\nhead(df_cfa_exercise)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nx1_t1\nx1_t2\nx1_t3\nx1_t4\nx1_t5\nx1_t6\nx1_t7\nx1_t8\nx1_t9\nx1_t10\nx2_t1\nx2_t2\nx2_t3\nx2_t4\nx2_t5\nx2_t6\nx2_t7\nx2_t8\nx2_t9\nx2_t10\nx3_t1\nx3_t2\nx3_t3\nx3_t4\nx3_t5\nx3_t6\nx3_t7\nx3_t8\nx3_t9\nx3_t10\nx4_t1\nx4_t2\nx4_t3\nx4_t4\nx4_t5\nx4_t6\nx4_t7\nx4_t8\nx4_t9\nx4_t10\nx5_t1\nx5_t2\nx5_t3\nx5_t4\nx5_t5\nx5_t6\nx5_t7\nx5_t8\nx5_t9\nx5_t10\ny1_t1\ny1_t2\ny1_t3\ny1_t4\ny1_t5\ny1_t6\ny1_t7\ny1_t8\ny1_t9\ny1_t10\ny2_t1\ny2_t2\ny2_t3\ny2_t4\ny2_t5\ny2_t6\ny2_t7\ny2_t8\ny2_t9\ny2_t10\ny3_t1\ny3_t2\ny3_t3\ny3_t4\ny3_t5\ny3_t6\ny3_t7\ny3_t8\ny3_t9\ny3_t10\ny4_t1\ny4_t2\ny4_t3\ny4_t4\ny4_t5\ny4_t6\ny4_t7\ny4_t8\ny4_t9\ny4_t10\ny5_t1\ny5_t2\ny5_t3\ny5_t4\ny5_t5\ny5_t6\ny5_t7\ny5_t8\ny5_t9\ny5_t10\n\n\n\n\n1\n4.927017\n3.484359\n5.209319\n3.777327\n2.822955\n2.874990\n4.399279\n3.999338\n2.829229\n4.534257\n3.569244\n3.716360\n4.025572\n2.601702\n4.917407\n4.417907\n5.836183\n2.584864\n2.416726\n3.428733\n3.123268\n2.200183\n2.416466\n2.600930\n2.179303\n3.370835\n5.833981\n3.574207\n2.399534\n1.756436\n5.759150\n4.865658\n5.106690\n4.142291\n4.984553\n4.902819\n7.088255\n6.024145\n4.119966\n4.134776\n4.700258\n3.579269\n5.881804\n4.111085\n4.600078\n4.055922\n4.496880\n4.373719\n4.322336\n3.912015\n4.329297\n3.597471\n3.552542\n3.052100\n2.592308\n3.082656\n4.184377\n4.064089\n3.642032\n2.777390\n4.477198\n4.454955\n4.760682\n3.288172\n5.678996\n4.679951\n4.928690\n5.166207\n3.485148\n3.454632\n2.848577\n5.551165\n3.769263\n3.649328\n2.271035\n5.264214\n3.832915\n3.875455\n2.525079\n1.163129\n4.678402\n4.682683\n3.607138\n4.363976\n3.401883\n5.139966\n5.210060\n4.713772\n3.424733\n2.631818\n3.480544\n3.221823\n3.853132\n3.120772\n3.842651\n2.815425\n3.273848\n3.126467\n3.647887\n3.895862\n\n\n2\n5.024072\n2.470240\n2.259750\n3.383971\n3.405628\n2.925394\n3.722530\n3.104064\n4.068848\n2.923166\n3.661601\n3.732475\n2.084769\n3.978517\n2.855392\n3.381118\n3.865699\n3.911571\n3.102266\n2.858461\n5.186708\n1.540100\n3.453976\n1.671304\n4.397883\n4.996236\n3.609226\n2.266511\n5.332266\n5.041631\n2.577130\n1.182058\n2.648178\n2.580964\n4.378121\n2.015839\n2.477425\n2.718602\n2.512741\n3.104794\n2.425656\n2.302399\n1.261294\n2.294336\n0.776553\n3.169805\n2.850572\n2.683466\n2.756426\n3.199966\n3.488302\n3.348598\n1.567981\n2.689270\n2.093631\n0.946151\n2.760766\n1.974521\n0.788326\n1.546632\n3.613495\n3.002835\n2.618250\n3.474268\n4.107470\n3.950412\n3.461374\n3.162900\n2.504398\n3.957139\n3.269670\n2.924702\n2.951385\n1.403080\n1.747677\n3.671060\n2.755273\n2.860291\n3.582403\n2.855433\n4.296437\n4.459933\n3.877955\n3.542746\n4.623289\n5.768592\n2.820453\n4.347125\n5.008321\n5.628651\n3.446137\n3.354074\n0.216899\n1.984132\n2.551348\n1.010641\n3.200017\n1.600360\n1.541323\n3.561905\n\n\n3\n3.661946\n4.515898\n2.627455\n2.097116\n3.295632\n4.674215\n3.854248\n3.430167\n3.423922\n4.346313\n3.369146\n2.583655\n2.805899\n2.629365\n2.759572\n2.753171\n1.063016\n2.180655\n3.397097\n3.797167\n3.784757\n3.774945\n1.163201\n2.880376\n2.329117\n5.686030\n3.881392\n3.907517\n3.697921\n3.270770\n2.040071\n4.645036\n2.312931\n2.106188\n3.517961\n3.099783\n3.312862\n4.134669\n3.522531\n2.951239\n3.113105\n2.513375\n2.887626\n4.867711\n4.787919\n2.084980\n4.140326\n3.036390\n4.304286\n3.375258\n1.956426\n2.710257\n2.345528\n2.025919\n1.763310\n1.487463\n1.435715\n3.255219\n3.430917\n2.560493\n2.972647\n3.841999\n2.321647\n5.547948\n2.755463\n3.135102\n1.252126\n1.455243\n0.126571\n0.754453\n3.451330\n2.634979\n2.051891\n3.677636\n4.382111\n0.630656\n2.520796\n2.908761\n-0.251480\n1.706827\n4.334217\n3.310795\n3.634877\n3.788040\n3.997747\n3.418240\n1.451858\n5.332129\n3.107325\n2.796257\n3.441736\n1.732713\n4.678564\n3.527282\n4.910696\n3.960887\n2.782757\n3.427556\n4.629581\n4.084214\n\n\n4\n1.933604\n1.835414\n4.246882\n3.229524\n2.456309\n2.818070\n2.602155\n3.215303\n4.200392\n2.272876\n0.706912\n-0.801259\n1.640656\n1.587674\n1.470820\n2.430678\n1.819882\n1.695119\n1.338284\n0.605444\n0.133074\n0.158037\n1.792941\n1.790514\n1.269408\n3.353523\n2.179509\n1.409529\n0.888444\n1.224938\n0.326793\n0.174798\n2.335327\n1.525558\n-0.955707\n3.610542\n1.960530\n-0.865120\n1.385375\n1.430312\n0.685265\n-0.230309\n0.633548\n1.199429\n0.310757\n2.375445\n1.869323\n0.641068\n1.674369\n1.870899\n3.087726\n0.985564\n0.784520\n2.725897\n0.850097\n0.685824\n1.168844\n-0.239602\n2.799497\n2.131838\n1.596182\n1.458913\n3.630159\n2.387079\n0.462230\n0.650202\n2.356301\n0.755215\n2.026497\n2.441231\n2.790539\n2.575200\n3.509842\n3.116568\n3.452843\n3.093494\n1.836035\n2.222184\n2.761235\n4.237117\n3.075454\n1.881486\n2.553940\n1.045851\n3.202694\n4.161503\n2.702880\n0.817310\n2.733675\n1.369864\n0.687845\n2.150121\n1.293763\n0.737558\n0.793559\n1.293628\n1.312178\n-1.925199\n0.168729\n1.409099\n\n\n5\n2.274807\n2.908011\n3.179267\n2.941155\n3.710268\n2.717757\n3.510822\n1.550497\n2.728217\n4.947419\n4.312907\n1.624997\n3.450676\n3.296389\n4.639991\n4.428850\n4.773291\n2.273139\n2.820446\n3.868664\n4.675249\n2.412898\n3.691474\n4.295843\n4.288994\n3.679321\n3.664403\n3.449730\n4.627416\n5.374093\n3.114936\n0.937293\n3.231832\n2.031238\n2.033217\n0.704127\n1.766480\n1.422281\n1.951835\n3.429262\n2.336261\n3.616157\n3.631813\n3.258421\n5.976209\n4.089613\n2.896231\n4.596477\n4.129096\n7.093438\n3.593002\n3.190479\n2.211968\n2.500292\n3.999353\n2.826291\n2.768957\n2.979500\n3.155079\n3.074007\n2.688911\n2.680939\n4.108605\n2.347372\n3.353903\n3.417996\n3.602248\n3.722665\n1.867266\n4.398309\n2.672452\n3.234202\n4.512234\n1.011391\n2.736290\n2.495329\n2.283781\n0.979636\n2.101990\n3.646597\n4.168885\n6.011056\n5.576807\n4.452524\n5.109755\n3.539751\n5.203918\n6.884093\n6.758122\n4.835822\n1.016782\n1.853578\n2.498811\n3.096292\n2.572159\n2.496271\n1.515257\n1.183772\n3.329594\n2.744476\n\n\n6\n3.184660\n4.046734\n3.540150\n4.059281\n2.374465\n2.067087\n3.390182\n3.492470\n3.661657\n1.892471\n2.910669\n2.351059\n0.726541\n1.928325\n-0.062322\n1.306896\n0.272615\n1.463914\n2.076900\n2.569456\n5.019716\n2.328710\n2.837884\n4.043339\n1.947459\n2.449519\n3.065598\n4.321089\n2.036927\n1.389769\n3.537501\n4.318936\n1.631771\n3.685972\n3.609319\n1.645394\n2.917829\n2.317283\n2.267146\n3.963144\n3.536972\n3.295575\n3.075710\n3.460675\n3.224478\n1.660497\n3.093049\n2.421162\n2.188736\n3.557481\n0.309582\n1.857645\n1.819382\n1.085073\n2.427644\n1.988539\n2.246552\n2.295530\n1.075097\n1.388195\n1.656496\n1.752528\n2.418624\n1.340024\n0.824050\n0.698072\n1.970136\n2.064690\n1.795599\n4.439921\n1.967216\n0.477582\n1.303589\n0.223835\n1.302689\n1.254710\n2.383013\n0.978524\n2.745955\n1.923409\n1.194165\n1.793615\n0.785669\n0.374648\n1.989626\n3.421168\n2.360255\n0.441367\n2.033105\n3.299585\n1.283497\n1.845475\n1.331906\n1.425406\n2.937331\n0.823984\n2.306800\n2.113772\n2.127941\n1.507769\n\n\n\n\n\n# 1. Daten in Langformat transformieren - funktionen: pivot_longer(), pivot_wider()\n\n\n# 2. Skalenscores für X und Y erstellen - funktionen: group_by(), summarise()\n\n# 3. Skalenscores für X und Y zentrieren - Funktionen: de_mean()\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nload(\"../data/df_cfa_exercise.RData\")\nhead(df_cfa_exercise)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nx1_t1\nx1_t2\nx1_t3\nx1_t4\nx1_t5\nx1_t6\nx1_t7\nx1_t8\nx1_t9\nx1_t10\nx2_t1\nx2_t2\nx2_t3\nx2_t4\nx2_t5\nx2_t6\nx2_t7\nx2_t8\nx2_t9\nx2_t10\nx3_t1\nx3_t2\nx3_t3\nx3_t4\nx3_t5\nx3_t6\nx3_t7\nx3_t8\nx3_t9\nx3_t10\nx4_t1\nx4_t2\nx4_t3\nx4_t4\nx4_t5\nx4_t6\nx4_t7\nx4_t8\nx4_t9\nx4_t10\nx5_t1\nx5_t2\nx5_t3\nx5_t4\nx5_t5\nx5_t6\nx5_t7\nx5_t8\nx5_t9\nx5_t10\ny1_t1\ny1_t2\ny1_t3\ny1_t4\ny1_t5\ny1_t6\ny1_t7\ny1_t8\ny1_t9\ny1_t10\ny2_t1\ny2_t2\ny2_t3\ny2_t4\ny2_t5\ny2_t6\ny2_t7\ny2_t8\ny2_t9\ny2_t10\ny3_t1\ny3_t2\ny3_t3\ny3_t4\ny3_t5\ny3_t6\ny3_t7\ny3_t8\ny3_t9\ny3_t10\ny4_t1\ny4_t2\ny4_t3\ny4_t4\ny4_t5\ny4_t6\ny4_t7\ny4_t8\ny4_t9\ny4_t10\ny5_t1\ny5_t2\ny5_t3\ny5_t4\ny5_t5\ny5_t6\ny5_t7\ny5_t8\ny5_t9\ny5_t10\n\n\n\n\n1\n4.927017\n3.484359\n5.209319\n3.777327\n2.822955\n2.874990\n4.399279\n3.999338\n2.829229\n4.534257\n3.569244\n3.716360\n4.025572\n2.601702\n4.917407\n4.417907\n5.836183\n2.584864\n2.416726\n3.428733\n3.123268\n2.200183\n2.416466\n2.600930\n2.179303\n3.370835\n5.833981\n3.574207\n2.399534\n1.756436\n5.759150\n4.865658\n5.106690\n4.142291\n4.984553\n4.902819\n7.088255\n6.024145\n4.119966\n4.134776\n4.700258\n3.579269\n5.881804\n4.111085\n4.600078\n4.055922\n4.496880\n4.373719\n4.322336\n3.912015\n4.329297\n3.597471\n3.552542\n3.052100\n2.592308\n3.082656\n4.184377\n4.064089\n3.642032\n2.777390\n4.477198\n4.454955\n4.760682\n3.288172\n5.678996\n4.679951\n4.928690\n5.166207\n3.485148\n3.454632\n2.848577\n5.551165\n3.769263\n3.649328\n2.271035\n5.264214\n3.832915\n3.875455\n2.525079\n1.163129\n4.678402\n4.682683\n3.607138\n4.363976\n3.401883\n5.139966\n5.210060\n4.713772\n3.424733\n2.631818\n3.480544\n3.221823\n3.853132\n3.120772\n3.842651\n2.815425\n3.273848\n3.126467\n3.647887\n3.895862\n\n\n2\n5.024072\n2.470240\n2.259750\n3.383971\n3.405628\n2.925394\n3.722530\n3.104064\n4.068848\n2.923166\n3.661601\n3.732475\n2.084769\n3.978517\n2.855392\n3.381118\n3.865699\n3.911571\n3.102266\n2.858461\n5.186708\n1.540100\n3.453976\n1.671304\n4.397883\n4.996236\n3.609226\n2.266511\n5.332266\n5.041631\n2.577130\n1.182058\n2.648178\n2.580964\n4.378121\n2.015839\n2.477425\n2.718602\n2.512741\n3.104794\n2.425656\n2.302399\n1.261294\n2.294336\n0.776553\n3.169805\n2.850572\n2.683466\n2.756426\n3.199966\n3.488302\n3.348598\n1.567981\n2.689270\n2.093631\n0.946151\n2.760766\n1.974521\n0.788326\n1.546632\n3.613495\n3.002835\n2.618250\n3.474268\n4.107470\n3.950412\n3.461374\n3.162900\n2.504398\n3.957139\n3.269670\n2.924702\n2.951385\n1.403080\n1.747677\n3.671060\n2.755273\n2.860291\n3.582403\n2.855433\n4.296437\n4.459933\n3.877955\n3.542746\n4.623289\n5.768592\n2.820453\n4.347125\n5.008321\n5.628651\n3.446137\n3.354074\n0.216899\n1.984132\n2.551348\n1.010641\n3.200017\n1.600360\n1.541323\n3.561905\n\n\n3\n3.661946\n4.515898\n2.627455\n2.097116\n3.295632\n4.674215\n3.854248\n3.430167\n3.423922\n4.346313\n3.369146\n2.583655\n2.805899\n2.629365\n2.759572\n2.753171\n1.063016\n2.180655\n3.397097\n3.797167\n3.784757\n3.774945\n1.163201\n2.880376\n2.329117\n5.686030\n3.881392\n3.907517\n3.697921\n3.270770\n2.040071\n4.645036\n2.312931\n2.106188\n3.517961\n3.099783\n3.312862\n4.134669\n3.522531\n2.951239\n3.113105\n2.513375\n2.887626\n4.867711\n4.787919\n2.084980\n4.140326\n3.036390\n4.304286\n3.375258\n1.956426\n2.710257\n2.345528\n2.025919\n1.763310\n1.487463\n1.435715\n3.255219\n3.430917\n2.560493\n2.972647\n3.841999\n2.321647\n5.547948\n2.755463\n3.135102\n1.252126\n1.455243\n0.126571\n0.754453\n3.451330\n2.634979\n2.051891\n3.677636\n4.382111\n0.630656\n2.520796\n2.908761\n-0.251480\n1.706827\n4.334217\n3.310795\n3.634877\n3.788040\n3.997747\n3.418240\n1.451858\n5.332129\n3.107325\n2.796257\n3.441736\n1.732713\n4.678564\n3.527282\n4.910696\n3.960887\n2.782757\n3.427556\n4.629581\n4.084214\n\n\n4\n1.933604\n1.835414\n4.246882\n3.229524\n2.456309\n2.818070\n2.602155\n3.215303\n4.200392\n2.272876\n0.706912\n-0.801259\n1.640656\n1.587674\n1.470820\n2.430678\n1.819882\n1.695119\n1.338284\n0.605444\n0.133074\n0.158037\n1.792941\n1.790514\n1.269408\n3.353523\n2.179509\n1.409529\n0.888444\n1.224938\n0.326793\n0.174798\n2.335327\n1.525558\n-0.955707\n3.610542\n1.960530\n-0.865120\n1.385375\n1.430312\n0.685265\n-0.230309\n0.633548\n1.199429\n0.310757\n2.375445\n1.869323\n0.641068\n1.674369\n1.870899\n3.087726\n0.985564\n0.784520\n2.725897\n0.850097\n0.685824\n1.168844\n-0.239602\n2.799497\n2.131838\n1.596182\n1.458913\n3.630159\n2.387079\n0.462230\n0.650202\n2.356301\n0.755215\n2.026497\n2.441231\n2.790539\n2.575200\n3.509842\n3.116568\n3.452843\n3.093494\n1.836035\n2.222184\n2.761235\n4.237117\n3.075454\n1.881486\n2.553940\n1.045851\n3.202694\n4.161503\n2.702880\n0.817310\n2.733675\n1.369864\n0.687845\n2.150121\n1.293763\n0.737558\n0.793559\n1.293628\n1.312178\n-1.925199\n0.168729\n1.409099\n\n\n5\n2.274807\n2.908011\n3.179267\n2.941155\n3.710268\n2.717757\n3.510822\n1.550497\n2.728217\n4.947419\n4.312907\n1.624997\n3.450676\n3.296389\n4.639991\n4.428850\n4.773291\n2.273139\n2.820446\n3.868664\n4.675249\n2.412898\n3.691474\n4.295843\n4.288994\n3.679321\n3.664403\n3.449730\n4.627416\n5.374093\n3.114936\n0.937293\n3.231832\n2.031238\n2.033217\n0.704127\n1.766480\n1.422281\n1.951835\n3.429262\n2.336261\n3.616157\n3.631813\n3.258421\n5.976209\n4.089613\n2.896231\n4.596477\n4.129096\n7.093438\n3.593002\n3.190479\n2.211968\n2.500292\n3.999353\n2.826291\n2.768957\n2.979500\n3.155079\n3.074007\n2.688911\n2.680939\n4.108605\n2.347372\n3.353903\n3.417996\n3.602248\n3.722665\n1.867266\n4.398309\n2.672452\n3.234202\n4.512234\n1.011391\n2.736290\n2.495329\n2.283781\n0.979636\n2.101990\n3.646597\n4.168885\n6.011056\n5.576807\n4.452524\n5.109755\n3.539751\n5.203918\n6.884093\n6.758122\n4.835822\n1.016782\n1.853578\n2.498811\n3.096292\n2.572159\n2.496271\n1.515257\n1.183772\n3.329594\n2.744476\n\n\n6\n3.184660\n4.046734\n3.540150\n4.059281\n2.374465\n2.067087\n3.390182\n3.492470\n3.661657\n1.892471\n2.910669\n2.351059\n0.726541\n1.928325\n-0.062322\n1.306896\n0.272615\n1.463914\n2.076900\n2.569456\n5.019716\n2.328710\n2.837884\n4.043339\n1.947459\n2.449519\n3.065598\n4.321089\n2.036927\n1.389769\n3.537501\n4.318936\n1.631771\n3.685972\n3.609319\n1.645394\n2.917829\n2.317283\n2.267146\n3.963144\n3.536972\n3.295575\n3.075710\n3.460675\n3.224478\n1.660497\n3.093049\n2.421162\n2.188736\n3.557481\n0.309582\n1.857645\n1.819382\n1.085073\n2.427644\n1.988539\n2.246552\n2.295530\n1.075097\n1.388195\n1.656496\n1.752528\n2.418624\n1.340024\n0.824050\n0.698072\n1.970136\n2.064690\n1.795599\n4.439921\n1.967216\n0.477582\n1.303589\n0.223835\n1.302689\n1.254710\n2.383013\n0.978524\n2.745955\n1.923409\n1.194165\n1.793615\n0.785669\n0.374648\n1.989626\n3.421168\n2.360255\n0.441367\n2.033105\n3.299585\n1.283497\n1.845475\n1.331906\n1.425406\n2.937331\n0.823984\n2.306800\n2.113772\n2.127941\n1.507769\n\n\n\n\n\n# 1. Daten in Langformat transformieren - funktionen: pivot_longer(), pivot_wider()\ndf_uebung_superlang &lt;- df_cfa_exercise |&gt; \n  pivot_longer(\n    cols = -id, # All columns except id\n    names_to = c(\"variable\", \"time\"),\n    names_sep = \"_t\"\n  ) \ndf_uebung_lang &lt;- df_uebung_superlang |&gt; \n  pivot_wider(names_from = variable,\n              values_from = value) |&gt; \n  mutate(time = as.numeric(time)) \n\n# 2. Skalenscores für X und Y erstellen - funktionen: group_by(), summarise()\ndf_uebung_lang_scores &lt;- df_uebung_lang |&gt; group_by(id, time) |&gt; \n  summarise(\n    x = rowMeans(across(starts_with(\"x\")), na.rm = TRUE),\n    y = rowMeans(across(starts_with(\"y\")), na.rm = TRUE),\n    .groups = \"drop\" # group_by() wieder aufheben für den finalen Datensatz\n  )\n\n# 3. Skalenscores für X und Y zentrieren - Funktionen: de_mean()\ndf_uebung_lang_scores &lt;- df_uebung_lang_scores |&gt; \n  de_mean(x, y, grp = \"id\")\n\n\nhead(df_uebung_lang_scores)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\ntime\nx\ny\nx_dm\ny_dm\nx_gm\ny_gm\n\n\n\n\n1\n1\n4.415787\n3.962804\n0.3959958\n0.1601657\n4.019792\n3.802638\n\n\n1\n2\n3.569166\n4.301619\n-0.4506258\n0.4989815\n4.019792\n3.802638\n\n\n1\n3\n4.527970\n3.908551\n0.5081786\n0.1059135\n4.019792\n3.802638\n\n\n1\n4\n3.446667\n3.494870\n-0.5731246\n-0.3077683\n4.019792\n3.802638\n\n\n1\n5\n3.900859\n3.557375\n-0.1189324\n-0.2452633\n4.019792\n3.802638\n\n\n1\n6\n3.924495\n4.196442\n-0.0952970\n0.3938045\n4.019792\n3.802638",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Kapitel 2: Datenaufbereitung</span>"
    ]
  },
  {
    "objectID": "01 Data Preparation Item Level.html#abspeichern-der-gebildeten-skalen",
    "href": "01 Data Preparation Item Level.html#abspeichern-der-gebildeten-skalen",
    "title": "2  Kapitel 2: Datenaufbereitung",
    "section": "2.9 Abspeichern der gebildeten Skalen",
    "text": "2.9 Abspeichern der gebildeten Skalen\nZum Schluss speichern wir die Ergebnisse (sowohl die Items als auch die Skalen in Langformat) der Übung ab.\n\nsave(df_uebung_lang, df_uebung_lang_scores, file = \"../data/df_uebung.RData\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Kapitel 2: Datenaufbereitung</span>"
    ]
  },
  {
    "objectID": "02 Descriptive Statistics.html",
    "href": "02 Descriptive Statistics.html",
    "title": "3  Kapitel 3: Deskriptive Analysen und Überprüfung von Voraussetzungen",
    "section": "",
    "text": "3.1 Pakete laden\nif (!require(\"pacman\")) install.packages(\"pacman\")\n\nLade nötiges Paket: pacman\n\npacman::p_load(haven, psych,\n               sjmisc, sjPlot, writexl, lavaan,\n               tidyverse, multilevelTools, franzpak)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Kapitel 3: Deskriptive Analysen und Überprüfung von Voraussetzungen</span>"
    ]
  },
  {
    "objectID": "02 Descriptive Statistics.html#daten-laden",
    "href": "02 Descriptive Statistics.html#daten-laden",
    "title": "3  Kapitel 3: Deskriptive Analysen und Überprüfung von Voraussetzungen",
    "section": "3.2 Daten laden",
    "text": "3.2 Daten laden\n\nload(\"../data/df_cfa_long.RData\")\n\nhead(df_cfa_long_scores)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\ntime\na\nb\nc\na_dm\nb_dm\nc_dm\na_gm\nb_gm\nc_gm\n\n\n\n\n1\n1\n3.576438\n2.0153094\n3.059581\n-0.2566380\n0.4476044\n-0.5267811\n3.833076\n1.567705\n3.586362\n\n\n1\n2\n3.618275\n1.6847458\n4.229828\n-0.2148012\n0.1170408\n0.6434662\n3.833076\n1.567705\n3.586362\n\n\n1\n3\n2.365406\n0.3495072\n2.465712\n-1.4676704\n-1.2181978\n-1.1206501\n3.833076\n1.567705\n3.586362\n\n\n1\n4\n3.604362\n1.4354944\n2.848375\n-0.2287140\n-0.1322106\n-0.7379871\n3.833076\n1.567705\n3.586362\n\n\n1\n5\n3.881178\n1.2395786\n3.159797\n0.0481014\n-0.3281264\n-0.4265645\n3.833076\n1.567705\n3.586362\n\n\n1\n6\n4.172778\n1.3404398\n4.261824\n0.3397012\n-0.2272652\n0.6754625\n3.833076\n1.567705\n3.586362\n\n\n\n\n\n\nSchauen wir uns nochmal die Datenstruktur unserer aufbereiteten Datensätze aus dem vorhergehenden Kapitel an.\nIn df_cfa_long_scores haben wir haben die Variablen mit Fokus auf die Skalenscores:\n\nid: Gruppierungsvariable / Personen-ID, von 1 - 100\ntime: Zeitpunkt / Tag der Messung, von 1-10\na, b, c: Rohvariablen (Skalenscores von a, b, und c. Die Items aus denen a,b,c gebildet sind brauchen wir nur bei bestimmten Abschnitten)\na_dm - c_dm: Personen-zentrierte Variablen\na_gm - c_gm : Personen-Mittelwerte\n\n\nhead(df_cfa_long)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\ntime\na1\na2\na3\na4\na5\nb1\nb2\nb3\nb4\nb5\nc1\nc2\nc3\n\n\n\n\n1\n1\n3.336252\n3.380463\n3.223528\n4.399347\n3.542602\n3.370896\n1.697640\n0.584167\n1.576649\n2.847195\n4.325797\n1.030847\n3.822098\n\n\n1\n2\n2.149828\n5.110309\n5.678413\n2.765556\n2.387270\n2.486919\n0.952220\n2.101517\n0.331000\n2.552073\n3.364003\n5.711729\n3.613752\n\n\n1\n3\n1.613518\n3.004133\n2.503233\n1.898476\n2.807670\n0.991958\n-0.685685\n0.003147\n-0.517730\n1.955846\n2.582169\n2.659834\n2.155132\n\n\n1\n4\n3.351085\n3.852294\n4.972103\n2.612551\n3.233779\n2.248097\n0.004118\n0.711264\n2.185949\n2.028044\n2.918614\n3.163276\n2.463234\n\n\n1\n5\n3.320900\n3.694431\n4.703663\n3.476859\n4.210036\n1.953658\n0.675750\n0.921623\n0.284884\n2.361978\n2.829237\n3.910432\n2.739723\n\n\n1\n6\n4.173775\n5.658948\n3.273027\n4.192700\n3.565438\n1.544111\n-0.373186\n1.303905\n1.687402\n2.539967\n4.141474\n5.234767\n3.409232\n\n\n\n\n\n\nIn df_cfa_long haben wir die einzelnen Item abgespeichert.\n\nid: Gruppierungsvariable / Personen-ID, von 1 - 100\ntime: Zeitpunkt / Tag der Messung, von 1-10\na1-a5: 5 Items aus Skala für “a”\nb1-b5: 5 Items aus Skala für “b”\nc1-c3: 3 Items aus Skala für “c”",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Kapitel 3: Deskriptive Analysen und Überprüfung von Voraussetzungen</span>"
    ]
  },
  {
    "objectID": "02 Descriptive Statistics.html#reliabilitätsanalyse",
    "href": "02 Descriptive Statistics.html#reliabilitätsanalyse",
    "title": "3  Kapitel 3: Deskriptive Analysen und Überprüfung von Voraussetzungen",
    "section": "3.3 Reliabilitätsanalyse",
    "text": "3.3 Reliabilitätsanalyse\nDie Reliabilitätsanalyse basiert auf den Items, nicht auf den Skalenwerten (df_cfa_long). Bei täglich erhobenen Skalen nehmen wir die omegaSEM() Funktion. Als erstes Argument geben wir die Items in einem Character-Vector mittels c(), die Items werden mit Anführungszeichen angegeben. Falls ihr die Itemnamen nicht wisst, könnt ihr sie mit names(df_cfa_long) nachsehen.\n\nscalea_reliab &lt;- omegaSEM(\n  items = c(\"a1\", \"a2\", \"a3\", \"a4\", \"a5\"),\n  id = \"id\",\n  data = df_cfa_long)\nscalea_reliab$Results\n\n\n\n\n\n\nlabel\nest\nci.lower\nci.upper\n\n\n\n\n42\nomega_within\n0.7390195\n0.7120809\n0.7659581\n\n\n50\nomega_between\n0.8480644\n0.7955281\n0.9006008\n\n\n\n\n\n\nHier erscheint teils eine Warnung, weil nicht alle Personen (cluster) Varianz auf den Items haben. Dies können wir ignorieren. In den simulierten Daten, die wir verwenden, ist dies jedoch nicht der Fall. Dann können wir den Output ansehen. Omega_within gibt die Reliabilität für Unterschiede innerhalb der Person an, und Omega_between gibt die Reliabilität für Unterschiede zwischen Personen an. Die Reliabilitäten sollten über .70 liegen für eine gute Reliabilität auf beiden Leveln.\n\nscaleb_reliab &lt;- omegaSEM(\n  items = c(\"b1\", \"b2\", \"b3\", \"b4\", \"b5\"),\n  id = \"id\",\n  data = df_cfa_long)\n\nscaleb_reliab$Results\n\n\n\n\n\n\nlabel\nest\nci.lower\nci.upper\n\n\n\n\n42\nomega_within\n0.7439948\n0.7175652\n0.7704245\n\n\n50\nomega_between\n0.8884161\n0.8502350\n0.9265972\n\n\n\n\n\n\n\nscalec_reliab &lt;- omegaSEM(\n  items = c(\"c1\", \"c2\", \"c3\"),\n  id = \"id\",\n  data = df_cfa_long)\n\nscalec_reliab$Results\n\n\n\n\n\n\nlabel\nest\nci.lower\nci.upper\n\n\n\n\n28\nomega_within\n0.6276604\n0.5854945\n0.6698263\n\n\n34\nomega_between\n0.7638922\n0.6728196\n0.8549647",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Kapitel 3: Deskriptive Analysen und Überprüfung von Voraussetzungen</span>"
    ]
  },
  {
    "objectID": "02 Descriptive Statistics.html#korrelationstabelle",
    "href": "02 Descriptive Statistics.html#korrelationstabelle",
    "title": "3  Kapitel 3: Deskriptive Analysen und Überprüfung von Voraussetzungen",
    "section": "3.4 Korrelationstabelle",
    "text": "3.4 Korrelationstabelle\nIn quantitativ-empirischen psychologischen Artikeln ist (fast) immer die Korrelationstabelle die erste Tabelle des Artikels. Unser nächstes Ziel ist es, eine Korrelationstabelle anzufertigen, in der wir die a) Mittelwerte, b) Standardabweichungen, c) ICC (Anteile der Zwischen-Person Varianz) und Korrelationen Zwischen und Innerhalb von Personen integrieren.\nDie Funktion cortable_multilevel() berechnet und stellt diese Angaben für uns zusammen. Sie nimmt die Argumente varnames mit den Variablennamen als Vektor c(\"a\", \"b\", \"c\") und die Gruppierungsvariable, die angibt zu welcher Level-2 Einheit eine Beobachtung/Zeile gehört (grp = \"id\").\n\ncortable_integriert &lt;- cortable_multilevel(df_cfa_long_scores,\n                                           varnames = c(\"a\", \"b\", \"c\"),\n                                           grp = \"id\")\ncortable_integriert\n\n\n\n\n\nVariable\nM\nSD\nICC\n1.\n2.\n3.\n\n\n\n\n1.a\n3.03\n0.99\n.49\n-\n.32**\n.39***\n\n\n2.b\n1.95\n1.07\n.55\n.22***\n-\n.29**\n\n\n3.c\n1.99\n1.06\n.47\n.25***\n.29***\n-\n\n\n\n\n\n\nBetrachten wir nun die einzelnen Elemente der Korrelationstabelle:\n\nMittelwerte / M: Wir sehen, dass a einen höheren Mittelwert (M = 3.03) als b und c (M = 1.94, M = 1.99) aufweist. Für die Verteilung der Variablen sehen wir uns idealerweise auch Histogramme an.\nStandardabweichungen / SD: Die Streuung der Variablen ist ähnlich und ihre Standardabweichungen liegen zwischen 0.99 und 1.07.\n1.-3. Wir erhalten im unteren Dreieck die Inner-Person-Korrelationen, und im oberen Dreieck die Zwischen-Person-Korrelationen. Alle Korrelationen sind signifikant positiv.\n\n\n3.4.1 Export von Tabellen zu Excel\nWir exportieren die Korrelationstabelle nach Excel mittels write_xlsx().\n\n# eval: false\nwrite_xlsx(cortable_integriert, path = \"korrelationstabelle.xlsx\")\n\nDie Excel-Tabelle lässt sich dann in Word kopieren und weiter verarbeitet werden, z.B. mit den richtigen Variablennamen versehen werden etc. Damit haben wir nun die Datenaufbereitung und deskriptive Datenanalyse abgeschlossen.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Kapitel 3: Deskriptive Analysen und Überprüfung von Voraussetzungen</span>"
    ]
  },
  {
    "objectID": "02 Descriptive Statistics.html#übung",
    "href": "02 Descriptive Statistics.html#übung",
    "title": "3  Kapitel 3: Deskriptive Analysen und Überprüfung von Voraussetzungen",
    "section": "3.5 Übung",
    "text": "3.5 Übung\nWendet diese Schritte nun auf den Datensatz aus der letzten Übung an. Zunächst laden wir die Daten, die in der letzten Übung abgespeichert werden sollten.\nWir haben die beiden Datensätze df_uebung_lang für alle Items (x1-x5, y1-y5) im langen Datenformat und df_uebung_lang_scores für alle Skalenwerte (x,y) im Langformat.\n\nload(\"../data/df_uebung.RData\")\nhead(df_uebung_lang)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\ntime\nx1\nx2\nx3\nx4\nx5\ny1\ny2\ny3\ny4\ny5\n\n\n\n\n1\n1\n4.927017\n3.569244\n3.123268\n5.759150\n4.700258\n4.329297\n4.477198\n2.848577\n4.678402\n3.480544\n\n\n1\n2\n3.484359\n3.716360\n2.200183\n4.865658\n3.579269\n3.597471\n4.454955\n5.551165\n4.682683\n3.221823\n\n\n1\n3\n5.209319\n4.025572\n2.416466\n5.106690\n5.881804\n3.552542\n4.760682\n3.769263\n3.607138\n3.853132\n\n\n1\n4\n3.777327\n2.601702\n2.600930\n4.142291\n4.111085\n3.052100\n3.288172\n3.649328\n4.363976\n3.120772\n\n\n1\n5\n2.822955\n4.917407\n2.179303\n4.984553\n4.600078\n2.592308\n5.678996\n2.271035\n3.401883\n3.842651\n\n\n1\n6\n2.874990\n4.417907\n3.370835\n4.902819\n4.055922\n3.082656\n4.679951\n5.264214\n5.139966\n2.815425\n\n\n\n\n\nhead(df_uebung_lang_scores)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\ntime\nx\ny\nx_dm\ny_dm\nx_gm\ny_gm\n\n\n\n\n1\n1\n4.415787\n3.962804\n0.3959958\n0.1601657\n4.019792\n3.802638\n\n\n1\n2\n3.569166\n4.301619\n-0.4506258\n0.4989815\n4.019792\n3.802638\n\n\n1\n3\n4.527970\n3.908551\n0.5081786\n0.1059135\n4.019792\n3.802638\n\n\n1\n4\n3.446667\n3.494870\n-0.5731246\n-0.3077683\n4.019792\n3.802638\n\n\n1\n5\n3.900859\n3.557375\n-0.1189324\n-0.2452633\n4.019792\n3.802638\n\n\n1\n6\n3.924495\n4.196442\n-0.0952970\n0.3938045\n4.019792\n3.802638\n\n\n\n\n\n\n\nhead(df_uebung_lang_scores)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\ntime\nx\ny\nx_dm\ny_dm\nx_gm\ny_gm\n\n\n\n\n1\n1\n4.415787\n3.962804\n0.3959958\n0.1601657\n4.019792\n3.802638\n\n\n1\n2\n3.569166\n4.301619\n-0.4506258\n0.4989815\n4.019792\n3.802638\n\n\n1\n3\n4.527970\n3.908551\n0.5081786\n0.1059135\n4.019792\n3.802638\n\n\n1\n4\n3.446667\n3.494870\n-0.5731246\n-0.3077683\n4.019792\n3.802638\n\n\n1\n5\n3.900859\n3.557375\n-0.1189324\n-0.2452633\n4.019792\n3.802638\n\n\n1\n6\n3.924495\n4.196442\n-0.0952970\n0.3938045\n4.019792\n3.802638\n\n\n\n\n\n\n\n3.5.1 Reliabilitsätsanalyse\nBerechnet die Omega-Within und Omega-Between Reliabilitäten für X und Y mittels omegaSEM() und analysiert die Angaben. Passt dazu den Code aus dem Abschnitt ‘Reliabilitätsanalyse’ oben auf das Beispiel an.\n\nWeisen die Skalen X und Y hinreichende Omega-Werte auf, um Inner-Person Unterschiede reliabel zu messen? Begründet eure Antworten.\nWeisen die Skalen X und Y hinreichend Omega-Werte auf, um Zwischen-Person Unterschiede reliabel zu messen? Begründet eure Antworten.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nscalex_reliab &lt;- omegaSEM(c(\"x1\", \"x2\", \"x3\", \"x4\", \"x5\"), \"id\", df_uebung_lang)\nscalex_reliab$Results\n\n\n\n\n\n\nlabel\nest\nci.lower\nci.upper\n\n\n\n\n42\nomega_within\n0.7207947\n0.6919655\n0.7496239\n\n\n50\nomega_between\n0.8765616\n0.8338820\n0.9192411\n\n\n\n\n\n\n\nscaley_reliab &lt;- omegaSEM(c(\"y1\", \"y2\", \"y3\", \"y4\", \"y5\"), \"id\", df_uebung_lang)\nscaley_reliab$Results\n\n\n\n\n\n\nlabel\nest\nci.lower\nci.upper\n\n\n\n\n42\nomega_within\n0.3624765\n0.2969411\n0.4280119\n\n\n50\nomega_between\n0.8844400\n0.8452825\n0.9235976\n\n\n\n\n\n\n\n\n\n\n\n3.5.2 ICC und Korrelationstabelle\nBerechnet den ICC für X und Y mittels cortable_multilevel() und analysiert die Angaben. Passt dazu den Code aus dem Abschnitt ‘Korrelationstabelle’ oben auf das Beispiel an.\n\nWeisen die Skalen X und Y hinreichend Varianz auf der Inner-Person-Ebene auf, um sie mittels Mehrebenen-Modelle zu analysieren? Begründet eure Antwort.\nWie fällt die Korrelation zwischen X und Y auf Zwischen-Person Ebene aus? Ist es basierend auf der Prüfungen der Voraussetzungen (ICCs, Reliabilitäten) sinnvoll, diese zu interpretieren?\nWie fällt die Korrelation zwischen X und Y auf Inner-Person Ebene aus? Ist es basierend auf der Prüfungen der Voraussetzungen (ICCs, Reliabilitäten) sinnvoll, diese zu interpretieren?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nmehrebenen_stats &lt;- df_uebung_lang_scores |&gt; \n    cortable_multilevel(varnames = c(\"x\", \"y\"), grp = \"id\")\n\nprint(mehrebenen_stats)\n\n# A tibble: 2 × 6\n  Variable M     SD    ICC   `1.`  `2.` \n  &lt;chr&gt;    &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n1 1.x      3.04  0.99  .53   -     .28**\n2 2.y      2.05  0.93  .69   .02   -    \n\n\nBeide Variablen haben einen ICC unter .80, unserer Faustregel, d.h. 20% oder mehr Varianz liegt auf der Inner-Person Ebene. Somit weisen sie genügend Varianz auf Inner-Person-Ebene aus und eine Mehrebenen-Analyse ist möglich. X scheint mehr Varianz auf Inner-Person zu haben (ICC: .53; Varianz auf Inner-Person-Ebene ist 1-ICC, also .47 oder 47%) als Y (31%).\n\n3.5.2.1 Zwischen-Person Ebene\nDie Korrelation zwischen X und Y beträgt r = .28 und ist signifikant. Die Reliabilität auf Level-2/ Zwischen-Person Ebene, durch omega_between angegeben, ist für X und Y gut (&gt; .80). Die ICCs weisen auf ausreichend Varianz auf Zwischen-Person Ebene hin (53%-69%). Daher ist sie sinnvoll zu interpretieren. DIe Variablen sind moderat positiv miteinander assoziiert.\n\n\n3.5.2.2 Inner-Person Ebene\nFür Y, auch wenn es durchaus Varianz auf Inner-Person Ebene gibt (ICC = .69, damit sind 31% der Varianz auf Inner-Person Ebene), ist auf Inner-Person Ebene ist die Reliabilität sehr niedrig (Omega-within = .32). Das heisst, dass die Varianz innerhalb der Personen über die Tage auf Variable Y nicht reliabel gemessen werden. Die Inner-Person Varianz auf Y ist somit nicht sinnvoll zu interpretieren und stellt vermutlich nur “Rauschen” dar. Die Korrelation mit X ist nicht sinnvoll zu interpretieren (und fällt auch nicht signifikant aus), auch wenn X sowohl ausreichend Level-1 Varianz hat als auch reliabel gemessen ist.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Kapitel 3: Deskriptive Analysen und Überprüfung von Voraussetzungen</span>"
    ]
  },
  {
    "objectID": "02 Descriptive Statistics.html#zusatz",
    "href": "02 Descriptive Statistics.html#zusatz",
    "title": "3  Kapitel 3: Deskriptive Analysen und Überprüfung von Voraussetzungen",
    "section": "3.6 Zusatz",
    "text": "3.6 Zusatz\nDie folgenden Analysen sind optional, geben aber ein tieferes Verständnis des Materials.\n\n3.6.1 Blick hinter die Kulissen: Berechnung von Omega mittels einer Mehrebenen konfirmatorischen Faktorenanalysen\nFür eine genauere Auswertung können wir omegaSEM() mit dem Parameter savemodel = TRUE laufen lassen und uns mittels summary() die konfirmatorische Faktoranalyse (CFA) genauer ansehen.\nWie CFAs funktionieren, kann hier repetiert werden: Statistik IV - Methodenlehre\nZudem können wir uns mit lavInspect() die Modellparameter ansehen, um zu verstehen wie die Reliabilitätskoeffizient gebildet wird.\n\nscalec_reliab &lt;- omegaSEM(c(\"c1\", \"c2\", \"c3\"), \"id\", df_cfa_long, savemodel = TRUE)\nscalec_reliab$Fit |&gt; summary(fit = TRUE, stand = TRUE)\n\nlavaan 0.6-18 ended normally after 32 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        15\n  Number of inequality constraints                   6\n\n  Number of observations                          1000\n  Number of clusters [id]                          100\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nModel Test Baseline Model:\n\n  Test statistic                               383.809\n  Degrees of freedom                                 6\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    1.000\n  Tucker-Lewis Index (TLI)                       1.000\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -4446.130\n  Loglikelihood unrestricted model (H1)      -4446.130\n                                                      \n  Akaike (AIC)                                8922.260\n  Bayesian (BIC)                              8995.876\n  Sample-size adjusted Bayesian (SABIC)       8948.235\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.000\n  90 Percent confidence interval - lower         0.000\n  90 Percent confidence interval - upper         0.000\n  P-value H_0: RMSEA &lt;= 0.050                       NA\n  P-value H_0: RMSEA &gt;= 0.080                       NA\n\nStandardized Root Mean Square Residual (corr metric):\n\n  SRMR (within covariance matrix)                0.000\n  SRMR (between covariance matrix)               0.000\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Observed\n  Observed information based on                Hessian\n\n\nLevel 1 [within]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  f_within =~                                                           \n    c1       (wl1)    0.596    0.043   13.816    0.000    0.596    0.595\n    c2       (wl2)    0.653    0.046   14.176    0.000    0.653    0.622\n    c3       (wl3)    0.587    0.043   13.605    0.000    0.587    0.580\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n    f_within          1.000                               1.000    1.000\n   .c1       (wr1)    0.648    0.048   13.565    0.000    0.648    0.645\n   .c2       (wr2)    0.675    0.054   12.435    0.000    0.675    0.613\n   .c3       (wr3)    0.677    0.048   14.183    0.000    0.677    0.663\n\n\nLevel 2 [id]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  f_between =~                                                          \n    c1       (bl1)    0.529    0.095    5.570    0.000    0.529    0.660\n    c2       (bl2)    0.704    0.106    6.614    0.000    0.704    0.803\n    c3       (bl3)    0.680    0.115    5.905    0.000    0.680    0.694\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .c1                2.003    0.086   23.252    0.000    2.003    2.500\n   .c2                1.948    0.094   20.798    0.000    1.948    2.224\n   .c3                2.021    0.103   19.615    0.000    2.021    2.063\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n    f_betwen          1.000                               1.000    1.000\n   .c1       (br1)    0.362    0.081    4.446    0.000    0.362    0.564\n   .c2       (br2)    0.272    0.107    2.536    0.011    0.272    0.355\n   .c3       (br3)    0.497    0.120    4.132    0.000    0.497    0.518\n\nDefined Parameters:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n    num_within        3.371    0.262   12.875    0.000    3.371    3.233\n    denom_within      5.370    0.253   21.213    0.000    5.370    5.155\n    omega_within      0.628    0.022   29.175    0.000    0.628    0.627\n    num_between       3.659    0.764    4.787    0.000    3.659    4.657\n    denom_between     4.789    0.754    6.354    0.000    4.789    6.094\n    omega_between     0.764    0.046   16.440    0.000    0.764    0.764\n\nConstraints:\n                                               |Slack|\n    wr1 - 0                                      0.648\n    wr2 - 0                                      0.675\n    wr3 - 0                                      0.677\n    br1 - 0                                      0.362\n    br2 - 0                                      0.272\n    br3 - 0                                      0.497\n\nlavInspect(scalec_reliab$Fit, \"list\") |&gt; \n  select(lhs, op, rhs, free, level, free, label, est, se) |&gt; \n  mutate(across(where(is.numeric), round, 2)) # alternatively, parTable()\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `across(where(is.numeric), round, 2)`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlhs\nop\nrhs\nfree\nlevel\nlabel\nest\nse\n\n\n\n\nf_within\n=~\nc1\n1\n1\nwl1\n0.60\n0.04\n\n\nf_within\n=~\nc2\n2\n1\nwl2\n0.65\n0.05\n\n\nf_within\n=~\nc3\n3\n1\nwl3\n0.59\n0.04\n\n\nf_within\n~~\nf_within\n0\n1\n\n1.00\n0.00\n\n\nc1\n~~\nc1\n4\n1\nwr1\n0.65\n0.05\n\n\nc2\n~~\nc2\n5\n1\nwr2\n0.68\n0.05\n\n\nc3\n~~\nc3\n6\n1\nwr3\n0.68\n0.05\n\n\nc1\n~1\n\n0\n1\n\n0.00\n0.00\n\n\nc2\n~1\n\n0\n1\n\n0.00\n0.00\n\n\nc3\n~1\n\n0\n1\n\n0.00\n0.00\n\n\nf_within\n~1\n\n0\n1\n\n0.00\n0.00\n\n\nf_between\n=~\nc1\n7\n2\nbl1\n0.53\n0.10\n\n\nf_between\n=~\nc2\n8\n2\nbl2\n0.70\n0.11\n\n\nf_between\n=~\nc3\n9\n2\nbl3\n0.68\n0.12\n\n\nf_between\n~~\nf_between\n0\n2\n\n1.00\n0.00\n\n\nc1\n~~\nc1\n10\n2\nbr1\n0.36\n0.08\n\n\nc2\n~~\nc2\n11\n2\nbr2\n0.27\n0.11\n\n\nc3\n~~\nc3\n12\n2\nbr3\n0.50\n0.12\n\n\nc1\n~1\n\n13\n2\n\n2.00\n0.09\n\n\nc2\n~1\n\n14\n2\n\n1.95\n0.09\n\n\nc3\n~1\n\n15\n2\n\n2.02\n0.10\n\n\nf_between\n~1\n\n0\n2\n\n0.00\n0.00\n\n\nwr1\n&gt;\n0\n0\n0\n\n0.65\n0.00\n\n\nwr2\n&gt;\n0\n0\n0\n\n0.68\n0.00\n\n\nwr3\n&gt;\n0\n0\n0\n\n0.68\n0.00\n\n\nnum_within\n:=\n(wl1+wl2+wl3)^2\n0\n0\nnum_within\n3.37\n0.26\n\n\ndenom_within\n:=\n(wl1+wl2+wl3)^2+(wr1+wr2+wr3)\n0\n0\ndenom_within\n5.37\n0.25\n\n\nomega_within\n:=\nnum_within/denom_within\n0\n0\nomega_within\n0.63\n0.02\n\n\nbr1\n&gt;\n0\n0\n0\n\n0.36\n0.00\n\n\nbr2\n&gt;\n0\n0\n0\n\n0.27\n0.00\n\n\nbr3\n&gt;\n0\n0\n0\n\n0.50\n0.00\n\n\nnum_between\n:=\n(bl1+bl2+bl3)^2\n0\n0\nnum_between\n3.66\n0.76\n\n\ndenom_between\n:=\n(bl1+bl2+bl3)^2+(br1+br2+br3)\n0\n0\ndenom_between\n4.79\n0.75\n\n\nomega_between\n:=\nnum_between/denom_between\n0\n0\nomega_between\n0.76\n0.05\n\n\n\n\n\n\nWie der Output zeigt, ergibt sich die Omega-Reliabilität aus dem Anteil der durch den Faktor (f_within für den Faktor auf Level-1 bzw. f_between für den Faktor auf Level-2) erklärten Varianz der Items (Summe aller Item-Ladungen, quadriert für Varianz) geteilt durch die Gesamtvarianz der Items (durch Faktor erklärte Varianz der Items + Residualvarianz, d.h. übrigbleibende Varianz der Items). Diese Formel wird pro Varianzebene (Level-1, also tägliche Schwankungen innerhalb der Person) und Level-2 (Unterschiede zwischen Personen) getrennt berechnet.\n\n\n3.6.2 Berechnung der einzelnen Kenngrössen der Korrelationstabelle\n\n3.6.2.1 ICC und Within-Person Variance\nUns interessiert wie gross der Anteil der Varianz ist, der jeweils auf die zwei Ebenen der Daten entfallen (Inner-Person, Zwischen-Person-Ebene). Dies kann uns der ICC angeben. Mittels der Funktion statsBy() bekommen wir einige Analysen zu unseren Mehrebenen-Daten geliefert. Die Funktion benötigt zwei Argumente: den Datensatz und und die Gruppierungsvariable. Wir wählen entsprechend in select() die Variablen, die uns interessieren. Dies sind die Gruppierungsvariable “id” und die Rohvarianten der Variablen aus, da nur diese die Informationen über beide Ebenen enthalten (personen-zentrierte Variablen beinhalten nur Varianz auf Inner-Person-Ebene, Personen-Mittelwerte nur Varianz auf Zwischen-Person-Ebene). Die zerlegten Variablen mit den Kürzeln _dm und _gm brauchen wir erst später.\n\nmehrebenen_stats &lt;- df_cfa_long_scores |&gt; \n  select(id, a, b, c) |&gt; \n    statsBy(group = \"id\")\n\nWir bekommen hier manchmal Warnungen, wenn wir auch reine Level-2 Variablen eingeschlossen haben. Dies können wir jedoch ignorieren. Mit print() bekommen wir eine Übersicht über die Ergebnisse der Resultate der statsBy() Funktion.\n\nprint(mehrebenen_stats)\n\nStatistics within and between groups  \nCall: statsBy(data = select(df_cfa_long_scores, id, a, b, c), group = \"id\")\nIntraclass Correlation 1 (Percentage of variance due to groups) \n  id    a    b    c \n1.00 0.49 0.55 0.47 \nIntraclass Correlation 2 (Reliability of group differences) \n  id    a    b    c \n1.00 0.91 0.92 0.90 \neta^2 between groups  \na.bg b.bg c.bg \n0.54 0.59 0.52 \n\nTo see the correlations between and within groups, use the short=FALSE option in your print statement.\nMany results are not shown directly. To see specific objects select from the following list:\n mean sd n F ICC1 ICC2 ci1 ci2 raw rbg ci.bg pbg rwg nw ci.wg pwg etabg etawg nwg nG Call\n\n\nUns interessiert nur die Intraclass Correlation 1. Intraclass Correlation (2) und Eta-Quadrat interessieren uns nicht.\nDen ICC können wir uns auch direkt angeben lassen, indem wir aus dem Listenobjekt mehrebenen_stats mit dem Dollarzeichen $ die Untervariable ICC1 anwählen.\n\nicc &lt;- mehrebenen_stats$ICC1 |&gt; \n  round(2) # runden\nicc\n\n  id    a    b    c \n1.00 0.49 0.55 0.47 \n\n\nAlle Skalen im Beispiel haben ICCs in einem angemessenen Bereich (&lt;.80). Dies heisst, dass genug tägliche Varianz vorhanden ist, um Mehrebenen-Analysen durchzuführen.\n\n\n3.6.2.2 Mittelwerte\nMittelwerte wurden bereits - pro Person - durch die statsBy() Funktion gebildet. Den allgemeinen Mittelwert bekommen wir mit der Funktion summarise(). Diese erlaubt uns, zusammenfassende Werte zu bilden. Da wir dies gleich für mehrere Variablen machen, benutzen wir zudem across(), um die Summary gleich für mehrere Variablen zu bilden. Die Funktion benötigt als Argumente (a) die Namen der Variablen mit c() als einen Vektor zusammengefasst, (b) die Funktionen, wie sie gebildet werden (hier: ~mean(.x, na.rm = TRUE) für das arithmetische Mittel unter Ausschluss aller nicht vorhandenen Werte) und (c) optional die Namen der ausgegebenen Variablen mittels “.names”. Wir verwenden “m_{.col}”. Abschliessend runden wir die Werte.\nErsetzt im folgenden Code in der Klammer von c() die Variablennamen mit denen, die euch interessieren, hier sowohl die täglichen als auch Baselinevariablen.\n\nmittelwerte &lt;- mehrebenen_stats$mean |&gt; \n  as_tibble() |&gt; \n  summarise(across(c(a,b,c), ~mean(.x, na.rm = TRUE)))\n\nmittelwerte\n\n\n\n\n\na\nb\nc\n\n\n\n\n3.034273\n1.949319\n1.990651\n\n\n\n\n\n\nWir sehen, dass a einen höheren Mittelwert (M = 3.03) als b und c (M = 1.94, M = 1.99) aufweist. Für die Verteilung der Variablen sehen wir uns idealerweise auch Histogramme an.\n\nhist(mehrebenen_stats$mean[,\"a\"])\n\n\n\n\n\n\n\nhist(mehrebenen_stats$mean[,\"b\"])\n\n\n\n\n\n\n\nhist(mehrebenen_stats$mean[,\"c\"])\n\n\n\n\n\n\n\n\nAlle Variablen scheinen vom Histogram her hinreichend normalverteilt.\n\n\n3.6.2.3 Standardabweichungen\nGanz ähnlich wie mit Mittelwerten verfahren wir für die Standardabweichung, nur dass wir hier als Funktion ~sd(.x, na.rm = TRUE) verwenden. Ersetzt auch hier im folgenden Code in der Klammer von c() die Variablennamen mit denen, die euch interessieren, hier sowohl die täglichen als auch Baselinevariablen. Die Baselinevariable “w” zeigt hier keine SD mit dieser Berechnung und muss separat berechnet werden.\n\nstandardabweichung &lt;- mehrebenen_stats$sd |&gt; \n  as_tibble() |&gt; \n  summarise(across(c(a, b, c), ~mean(.x, na.rm = TRUE)))\nstandardabweichung\n\n\n\n\n\na\nb\nc\n\n\n\n\n0.6875217\n0.6956185\n0.7549543\n\n\n\n\n\n\n\n\n3.6.2.4 Korrelationen\nWir wollen eine Korrelationstabelle, in der wir auf einen Blick sowohl die Zwischen-Person-Korrelationen als auch die Inner-Person-Korrelationen sehen. Die statsBy() Funktion, die wir bereits aufgerufen haben, gibt uns beides separat aus. und\n\nmehrebenen_stats$rbg |&gt; round(2) # Zwischen Person Kor.\n\n     a.bg b.bg c.bg\na.bg 1.00 0.32 0.39\nb.bg 0.32 1.00 0.29\nc.bg 0.39 0.29 1.00\n\nmehrebenen_stats$rwg |&gt; round(2) # Inner Person Kor.\n\n     a.wg b.wg c.wg\na.wg 1.00 0.22 0.25\nb.wg 0.22 1.00 0.29\nc.wg 0.25 0.29 1.00\n\n\nWir erhalten im unteren Dreieck die Inner-Person-Korrelationen, und im oberen Dreieck die Zwischen-Person-Korrelationen.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Kapitel 3: Deskriptive Analysen und Überprüfung von Voraussetzungen</span>"
    ]
  },
  {
    "objectID": "03 Hypotheses Tests.html",
    "href": "03 Hypotheses Tests.html",
    "title": "4  Kapitel 4: Hypothesentests - Teil 1",
    "section": "",
    "text": "4.1 Vorbereitung\nIn diesem Kapitel verwenden wir verschiedene Regressionsmodelle die zur Überprüfung von Hypothesen eingesetzt werden.\nInstall packages\nif (!require(\"pacman\")) install.packages(\"pacman\")\n\nLade nötiges Paket: pacman\n\npacman::p_load(lmerTest, haven, brms, psych,\n               sjmisc, sjPlot, writexl, broom.mixed, qgraph,\n               tidyverse, multilevelTools, parameters)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Kapitel 4: Hypothesentests - Teil 1</span>"
    ]
  },
  {
    "objectID": "03 Hypotheses Tests.html#daten-einlesen",
    "href": "03 Hypotheses Tests.html#daten-einlesen",
    "title": "4  Kapitel 4: Hypothesentests - Teil 1",
    "section": "4.2 Daten einlesen",
    "text": "4.2 Daten einlesen\n\nload(\"../data/df_example1.RData\")\nload(\"../data/df_example1c.RData\")\n\nFür diese Einheit verwenden wir den folgenden Datensatz (data.frame/tibble):\n\ndf_example1: Alle Skalenscores im Long Format, mit personen-zentrierten Variablenvarianten (“_dm”) und Personen-Mittelwerten der täglich gemessenenen Variablen (“_gm”). Struktur des Datensatzes kann man sich ansehen mit head() oder print().\n\n\nhead(df_example1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\ny\nm\nx\ny_dm\nm_dm\nx_dm\ny_gm\nm_gm\nx_gm\n\n\n\n\n1\n4.003538\n4.769391\n2.365486\n-0.3020232\n0.8945291\n0.6845636\n4.305561\n3.874862\n1.680922\n\n\n1\n4.925174\n2.510943\n0.748855\n0.6196128\n-1.3639189\n-0.9320674\n4.305561\n3.874862\n1.680922\n\n\n1\n4.598564\n3.098112\n1.395041\n0.2930028\n-0.7767499\n-0.2858814\n4.305561\n3.874862\n1.680922\n\n\n1\n4.286179\n4.610746\n1.860026\n-0.0193822\n0.7358841\n0.1791036\n4.305561\n3.874862\n1.680922\n\n\n1\n4.183494\n4.549044\n2.288019\n-0.1220672\n0.6741821\n0.6070966\n4.305561\n3.874862\n1.680922\n\n\n1\n3.631716\n3.590049\n1.696510\n-0.6738452\n-0.2848129\n0.0155876\n4.305561\n3.874862\n1.680922\n\n\n\n\n\n\nIm Folgenden betrachten wir ein Modell in dem y durch x vorhergesagt wird.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Kapitel 4: Hypothesentests - Teil 1</span>"
    ]
  },
  {
    "objectID": "03 Hypotheses Tests.html#random-intercept-modell-null-model",
    "href": "03 Hypotheses Tests.html#random-intercept-modell-null-model",
    "title": "4  Kapitel 4: Hypothesentests - Teil 1",
    "section": "4.3 Random Intercept Modell / Null-Model",
    "text": "4.3 Random Intercept Modell / Null-Model\nDie Funktion lmer() benötigt zwei Argumente, (a) die Formel und (b) den Datensatz. Zum Aufbau und Details der Formeln s. Folien.\nLevel 1: \\(y_{ij} = \\beta_{0j} + e_{ij}\\)\nLevel 2 (random intercept): \\(\\beta_{0j} = \\gamma_{00} + u_{0j}\\)\n\nnullmodel &lt;- lmer(y ~ (1 | id), data = df_example1)\n\nZur Ansicht der Ergebnisse haben wir zwei Optionen: Den summary() Befehl - die Standardansicht, wie von den Paketautoren implementiert, den tidy() Befehl aus dem broom-Package, und den model_parameters() Befehl aus dem parameters Package. tidy() und model_parameters() Funktionsoutputs könnten nach Excel/Word exportiert werden mittels der write_xlsx() Funktion, oder indem das Notebook als .docx “gerendert” (ausgegeben) wird.\n\nsummary(nullmodel)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: y ~ (1 | id)\n   Data: df_example1\n\nREML criterion at convergence: 2742.9\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-6.1492 -0.5420 -0.0369  0.5543  4.6493 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 0.6902   0.8308  \n Residual             0.7164   0.8464  \nNumber of obs: 1000, groups:  id, 100\n\nFixed effects:\n            Estimate Std. Error       df t value Pr(&gt;|t|)    \n(Intercept)  5.36755    0.08728 99.00000    61.5   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\ntidy(nullmodel)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\neffect\ngroup\nterm\nestimate\nstd.error\nstatistic\ndf\np.value\n\n\n\n\nfixed\nNA\n(Intercept)\n5.3675530\n0.0872832\n61.49586\n99\n0\n\n\nran_pars\nid\nsd__(Intercept)\n0.8307776\nNA\nNA\nNA\nNA\n\n\nran_pars\nResidual\nsd__Observation\n0.8464254\nNA\nNA\nNA\nNA\n\n\n\n\n\n\n\nmodel_parameters(nullmodel) |&gt; print_html()\n\n\n\n\n\n\n\nModel Summary\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(997)\np\n\n\n\n\nFixed Effects\n\n\n(Intercept)\n5.37\n0.09\n(5.20, 5.54)\n61.50\n&lt; .001\n\n\nRandom Effects\n\n\nSD (Intercept: id)\n0.83\n\n\n\n\n\n\nSD (Residual)\n0.85\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIm Seminar verwenden wir den Output von model_parameters(), weil er eine recht gut formatierte Übersicht gibt.\n\n4.3.1 ICC\nAus dem Null-Model wird der ICC bestimmt. Dies haben wir in der vorhergehenden\nICC: \\(\\frac{\\tau_{00}}{\\tau_{00}+\\tau_{ij}}\\), \\(\\tau\\) gibt die Varianz des jewiligen Koeffizienten an.\nWir können dies aus dem Modelloutput nehmen und berechnen:\n\nmodelsummary &lt;- model_parameters(nullmodel)\ntau00 &lt;- modelsummary$Coefficient[modelsummary$Parameter == \"SD (Intercept)\"]^2\ntauij &lt;- modelsummary$Coefficient[modelsummary$Parameter == \"SD (Observations)\"]^2\ntau00 / (tau00+tauij)\n\n[1] 0.4906711\n\n# performance::icc(nullmodel) # Alternativfunktion\n\n\n\n4.3.2 Visualisierung\nWir können uns die Analysen visualisieren, hier zur reduzierten visuellen Komplexität nur auf Basis der ersten 20 Personen (ID 1-20.)\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nOder zwei Personen, um uns die einzelnen Punkte auch anschauen zu können:\n\nggplot(data = df_example1 |&gt; filter(id %in% c(1, 16)), aes(\n  x = x,\n  y = predicted_ri,\n  colour = id\n)) +\n  geom_smooth(method = \"lm\", fullrange = TRUE, se = F, size = 1) +\n  geom_jitter(aes(y = y), alpha = .5, size = 2.5) +\n  labs(x = xlabel, y = ylabel) +\n  ggtitle(\"Intercept-Only-Modell\") +\n  scale_colour_discrete() +\n  geom_abline(intercept = fixef(nullmodel), slope = 0, size = 1.5) +\n  ggthemes::theme_tufte()\n\n`geom_smooth()` using formula = 'y ~ x'",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Kapitel 4: Hypothesentests - Teil 1</span>"
    ]
  },
  {
    "objectID": "03 Hypotheses Tests.html#random-intercept-fixed-slope-modell",
    "href": "03 Hypotheses Tests.html#random-intercept-fixed-slope-modell",
    "title": "4  Kapitel 4: Hypothesentests - Teil 1",
    "section": "4.4 Random Intercept, fixed slope Modell",
    "text": "4.4 Random Intercept, fixed slope Modell\nAls nächstes bauen wir den Prädiktor x ein. Wir verwenden hier die zentrierte Variable “_dm” um Inner-Person Effekte zu berechnen.\nLevel 1: \\(y_{ij} = \\beta_{0j} + \\beta_{1j}*X_{ij} + e_{ij}\\)\nLevel 2 (random intercept): \\(\\beta_{0j} = \\gamma_{00} + u_{0j}\\)\nLevel 2 (fixed effect only): \\(\\beta'_{1j} = \\gamma'_{10}\\)\n\nri.fs_modell &lt;- lmer(y ~ x_dm + (1 | id), data = df_example1)\n\n\nmodel_parameters(ri.fs_modell) |&gt; print_html()\n\n\n\n\n\n\n\nModel Summary\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(996)\np\n\n\n\n\nFixed Effects\n\n\n(Intercept)\n5.37\n0.09\n(5.20, 5.54)\n61.50\n&lt; .001\n\n\nx dm\n0.44\n0.04\n(0.36, 0.51)\n11.63\n&lt; .001\n\n\nRandom Effects\n\n\nSD (Intercept: id)\n0.84\n\n\n\n\n\n\nSD (Residual)\n0.79\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.4.1 Visualisierung\n\n\n`geom_smooth()` using formula = 'y ~ x'",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Kapitel 4: Hypothesentests - Teil 1</span>"
    ]
  },
  {
    "objectID": "03 Hypotheses Tests.html#random-intercept-random-slope-modell",
    "href": "03 Hypotheses Tests.html#random-intercept-random-slope-modell",
    "title": "4  Kapitel 4: Hypothesentests - Teil 1",
    "section": "4.5 Random intercept, random slope Modell",
    "text": "4.5 Random intercept, random slope Modell\nAls nächstes fügen wir den random slope der Prädiktorvariable x_dm hinzu, in dem wir die random effect Struktur erweitern - “(1 + x_dm | id)”.\nLevel 1: \\(y_{ij} = \\beta_{0j} + \\beta_{1j}*(X_{ij}-\\overline{X_j}) + e_{ij}\\)\nLevel 2 (random intercept): \\(\\beta_{0j} = \\gamma_{00} + u_{0j}\\)\nLevel 2: \\(\\beta'_{1j} = \\gamma'_{10}\\)\n\nri.rs_modell &lt;- lmer(y ~ x_dm + (1 + x_dm | id), data = df_example1)\nmodel_parameters(ri.rs_modell) |&gt; print_html()\n\n\n\n\n\n\n\nModel Summary\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(994)\np\n\n\n\n\nFixed Effects\n\n\n(Intercept)\n5.37\n0.09\n(5.20, 5.54)\n61.50\n&lt; .001\n\n\nx dm\n0.42\n0.07\n(0.28, 0.56)\n5.88\n&lt; .001\n\n\nRandom Effects\n\n\nSD (Intercept: id)\n0.85\n\n\n\n\n\n\nSD (x_dm: id)\n0.63\n\n\n\n\n\n\nCor (Intercept~x_dm: id)\n0.20\n\n\n\n\n\n\nSD (Residual)\n0.65\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.5.1 Visualisierung\n\n\n`geom_smooth()` using formula = 'y ~ x'",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Kapitel 4: Hypothesentests - Teil 1</span>"
    ]
  },
  {
    "objectID": "03 Hypotheses Tests.html#level-2-prädiktoren",
    "href": "03 Hypotheses Tests.html#level-2-prädiktoren",
    "title": "4  Kapitel 4: Hypothesentests - Teil 1",
    "section": "4.6 Level-2 Prädiktoren",
    "text": "4.6 Level-2 Prädiktoren\nAls nächstes fügen wir einen Level-2 Prädiktor hinzu, der pro Person nur einmal gemessen wurde. Dabei handelt es sich für gewöhnlich um (1) Variablen, bei denen wir nicht an täglichen Schwankungen interessiert sind, wie soziodemografischen oder Persönlichkeitsvariablen, oder (2) den Mittelwert der Personen auf einer täglich gemessenen Variable. Im Beispiel verwenden wir (2), “x_gm”.\nLevel 1: \\(y_{ij} = \\beta_{0j} + \\beta_{1j}*(X_{ij}-\\overline{X_j}) + \\beta_{2j}*\\overline{X_j} + e_{ij}\\)\nLevel 2 (random intercept): \\(\\beta_{0j} = \\gamma_{00} + u_{0j}\\) Level 2 (random slope for x): \\(\\beta_{1j} = \\gamma_{10} + u_{2j}\\)\n\nri.rs_l2_modell &lt;- lmer(y ~ x_dm + x_gm + (1 + x_dm | id), data = df_example1)\nmodel_parameters(ri.rs_l2_modell) |&gt; print_html()\n\n\n\n\n\n\n\nModel Summary\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(993)\np\n\n\n\n\nFixed Effects\n\n\n(Intercept)\n4.47\n0.19\n(4.09, 4.84)\n23.30\n&lt; .001\n\n\nx dm\n0.42\n0.07\n(0.28, 0.56)\n5.85\n&lt; .001\n\n\nx gm\n0.43\n0.08\n(0.26, 0.59)\n5.13\n&lt; .001\n\n\nRandom Effects\n\n\nSD (Intercept: id)\n0.75\n\n\n\n\n\n\nSD (x_dm: id)\n0.63\n\n\n\n\n\n\nCor (Intercept~x_dm: id)\n0.17\n\n\n\n\n\n\nSD (Residual)\n0.65",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Kapitel 4: Hypothesentests - Teil 1</span>"
    ]
  },
  {
    "objectID": "04 Hypotheses Tests_Erweiterungen.html",
    "href": "04 Hypotheses Tests_Erweiterungen.html",
    "title": "5  Kapitel 5: Hypothestentests 2 - Moderation und Mediation",
    "section": "",
    "text": "5.1 Cross-Level Interaktion / Moderation\nErwarten wir, dass der Effekt von täglichen Schwankungen in X auf Y abhängig von einer Variable ist, die auf Level-2 gemessen wird (z.B. relativ stabile Persönlichkeitsmerkmale), können wir dies mit einer Cross-Level Interaktion testen.\nhead(df_example1c)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nw\ny\nm\nx\ny_dm\nm_dm\nx_dm\ny_gm\nm_gm\nx_gm\n\n\n\n\n1\n3.847053\n4.064028\n8.492899\n4.136489\n-1.1414789\n1.4106789\n0.803986\n5.205507\n7.08222\n3.332503\n\n\n1\n3.847053\n3.599397\n9.073630\n3.728720\n-1.6061099\n1.9914099\n0.396217\n5.205507\n7.08222\n3.332503\n\n\n1\n3.847053\n7.704277\n4.082619\n2.638451\n2.4987701\n-2.9996011\n-0.694052\n5.205507\n7.08222\n3.332503\n\n\n1\n3.847053\n6.796018\n5.516980\n2.761167\n1.5905111\n-1.5652401\n-0.571336\n5.205507\n7.08222\n3.332503\n\n\n1\n3.847053\n4.723777\n6.875090\n3.152261\n-0.4817299\n-0.2071301\n-0.180242\n5.205507\n7.08222\n3.332503\n\n\n1\n3.847053\n3.592594\n9.817786\n4.168687\n-1.6129129\n2.7355659\n0.836184\n5.205507\n7.08222\n3.332503\nWir zentrieren den Moderator “w” auf dem Grand mean (Gesamtmittelwert) für eine einfachere Interpretation der Modellparameter.\ndf_example1c &lt;- df_example1c |&gt; center(w)\nhead(df_example1c)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nw\ny\nm\nx\ny_dm\nm_dm\nx_dm\ny_gm\nm_gm\nx_gm\nw_c\n\n\n\n\n1\n3.847053\n4.064028\n8.492899\n4.136489\n-1.1414789\n1.4106789\n0.803986\n5.205507\n7.08222\n3.332503\n0.81076\n\n\n1\n3.847053\n3.599397\n9.073630\n3.728720\n-1.6061099\n1.9914099\n0.396217\n5.205507\n7.08222\n3.332503\n0.81076\n\n\n1\n3.847053\n7.704277\n4.082619\n2.638451\n2.4987701\n-2.9996011\n-0.694052\n5.205507\n7.08222\n3.332503\n0.81076\n\n\n1\n3.847053\n6.796018\n5.516980\n2.761167\n1.5905111\n-1.5652401\n-0.571336\n5.205507\n7.08222\n3.332503\n0.81076\n\n\n1\n3.847053\n4.723777\n6.875090\n3.152261\n-0.4817299\n-0.2071301\n-0.180242\n5.205507\n7.08222\n3.332503\n0.81076\n\n\n1\n3.847053\n3.592594\n9.817786\n4.168687\n-1.6129129\n2.7355659\n0.836184\n5.205507\n7.08222\n3.332503\n0.81076\nDie zentrierte Variable heisst “w_c” und wurde am Ende des Datensatz angehängt.\nZunächst berechnen wir das Modell ohne Interaktion von X und W (X*W), aber mit dem Haupteffekt von X und W.\nLevel 1: \\(y_{ij} = \\beta_{0j} + \\beta_{1j}*(X_{ij}-\\overline{X_j}) + \\beta_{2j}*W_{j} + e_{ij}\\)\nLevel 2 (random intercept): \\(\\beta_{0j} = \\gamma_{00} + u_{0j}\\) Level 2 (random slope for x): \\(\\beta_{1j} = \\gamma_{10} + u_{2j}\\)\nri.rs_w_modell &lt;- lmer(y ~ x_dm + w_c + (1 + x_dm | id), data = df_example1c)\nmodel_parameters(ri.rs_w_modell) |&gt; print_html()\n\n\n\n\n\n\n\nModel Summary\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(993)\np\n\n\n\n\nFixed Effects\n\n\n(Intercept)\n5.52\n0.10\n(5.33, 5.70)\n57.83\n&lt; .001\n\n\nx dm\n1.20\n0.11\n(0.98, 1.42)\n10.68\n&lt; .001\n\n\nw c\n0.44\n0.15\n(0.14, 0.74)\n2.91\n0.004\n\n\nRandom Effects\n\n\nSD (Intercept: id)\n0.93\n\n\n\n\n\n\nSD (x_dm: id)\n1.07\n\n\n\n\n\n\nCor (Intercept~x_dm: id)\n0.15\n\n\n\n\n\n\nSD (Residual)\n0.66\nDer Moderator W hat einen positiven Haupteffekt auf die abhängige Variable.\nAls nächstes fügen wir den Interaktionsterm hinzu.\nLevel 1: \\(y_{ij} = \\beta_{0j} + \\beta_{1j}*(X_{ij}-\\overline{X_j}) + \\beta_{2j}*W_{j} + e_{ij}\\)\nLevel 2 (random intercept): \\(\\beta_{0j} = \\gamma_{00} + u_{0j}\\)\nLevel 2 (random slope for x): \\(\\beta_{1j} = \\gamma_{10} + \\gamma_{11}*W_{j} + u_{2j}\\)\nri.rs_cli_modell &lt;- lmer(y ~ x_dm + w_c + w_c*x_dm + (1 + x_dm | id), data = df_example1c)\nmodel_parameters(ri.rs_cli_modell) |&gt; print_html()\n\n\n\n\n\n\n\nModel Summary\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(992)\np\n\n\n\n\nFixed Effects\n\n\n(Intercept)\n5.52\n0.10\n(5.33, 5.70)\n57.85\n&lt; .001\n\n\nx dm\n1.20\n0.11\n(0.98, 1.41)\n10.89\n&lt; .001\n\n\nw c\n0.49\n0.15\n(0.19, 0.79)\n3.19\n0.001\n\n\nx dm × w c\n0.39\n0.18\n(0.05, 0.74)\n2.23\n0.026\n\n\nRandom Effects\n\n\nSD (Intercept: id)\n0.93\n\n\n\n\n\n\nSD (x_dm: id)\n1.04\n\n\n\n\n\n\nCor (Intercept~x_dm: id)\n0.14\n\n\n\n\n\n\nSD (Residual)\n0.66\nBeachtet, dass mit der eingebauten Interaktion die Haupteffekte nicht mehr interpretiert werden.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Kapitel 5: Hypothestentests 2 - Moderation und Mediation</span>"
    ]
  },
  {
    "objectID": "04 Hypotheses Tests_Erweiterungen.html#cross-level-interaktion-moderation",
    "href": "04 Hypotheses Tests_Erweiterungen.html#cross-level-interaktion-moderation",
    "title": "5  Kapitel 5: Hypothestentests 2 - Moderation und Mediation",
    "section": "",
    "text": "5.1.1 Visualisierung\nVisualisierung des Interaktionseffekt mittels der plot_model() Funktion. Standardmässig werden die Simple Slopes an den Extremwerten (Minimum, Maximum) des Moderators geschätzt.\n\nplot_model(ri.rs_cli_modell, type = \"int\", terms = c(\"x_dm\", \"w_c\"))\n\n\n\n\n\n\n\nggsave(\"test.png\")\n\nSaving 7 x 5 in image\n\n\nAlternativ kann man auch die Werte zum Mittelwerte und bei -1 SD und +1 SD des Moderators anzeigen lassen.\n\nplot_model(ri.rs_cli_modell, type = \"int\", mdrt.values = \"meansd\")\n\n\n\n\n\n\n\n\nDer Plot zeigt, dass bei höheren Ausprägungen von w der Effekt von x_dm stärker ausfällt.\n\n\n5.1.2 Simple Slopes Analyse\nMit Hilfe der simple_slopes Funktion aus dem reghelper Paket können wir uns die Regressionskoeffizienten einer Simple-Slope Analyse unterziehen. Die Simple-Slope-Analyse in Mehrebenen-Modellen dient dazu, den Moderationseffekt einer Variablen zu untersuchen, indem die Beziehung zwischen Prädiktor (hier: “x”) und abhängiger Variable (hier: “y”) auf verschiedenen Ausprägungsniveaus der Moderatorvariablen (hier: “w_c”) betrachtet wird. Nach der Schätzung des Mehrebenen-Modells werden die Steigungen (Slopes) für unterschiedliche Werte des Moderators berechnet (z. B. ±1 Standardabweichung oder spezifische Werte), um zu analysieren, ob und wie sich der Effekt des Prädiktors je nach Moderator ändert. Diese Methode hilft zu verstehen, ob die Stärke oder Richtung eines Effekts in Abhängigkeit der Moderatorvariable variiert.\nWir können die spezifischen Werte der Variable automatisch bestimmen (1. Variante) oder manuell setzen (2. Variante). Uns interessieren die Werte, wenn x_dm um eine Einheit steigt und der Moderator unterdurchschnittlich (-1 SD), durchschnittlich, oder überdurchschnittlich (+1 SD) ist. Entsprechend werden die Werte in Variante 2 manuell gesetzt. Die Werte können wir der Abbildung oben entnehmen.\n\nsimple_slopes(ri.rs_cli_modell)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx_dm\nw_c\nTest Estimate\nStd. Error\ndf\nt value\nPr(&gt;|t|)\n\n\n\n\n-0.663149\nsstest\n0.2286100\n0.1800277\n96.65133\n1.269861\n0.2071831\n\n\n0\nsstest\n0.4892460\n0.1535760\n97.99976\n3.185694\n0.0019372\n\n\n0.663149\nsstest\n0.7498820\n0.2048973\n97.16437\n3.659794\n0.0004104\n\n\nsstest\n-0.621309\n0.9540629\n0.1553862\n95.45208\n6.139946\n0.0000000\n\n\nsstest\n0\n1.1982546\n0.1099985\n95.83814\n10.893368\n0.0000000\n\n\nsstest\n0.621309\n1.4424463\n0.1547564\n94.09284\n9.320752\n0.0000000\n\n\n\n\n\nsimple_slopes(ri.rs_cli_modell,\n              levels = list(x_dm = c(1,'sstest') ),\n              w_c = c(-0.62,0, 0.62, \"sstest\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx_dm\nw_c\nTest Estimate\nStd. Error\ndf\nt value\nPr(&gt;|t|)\n\n\n\n\n1\nsstest\n0.8822738\n0.2485026\n96.49868\n3.550360\n0.0005966\n\n\nsstest\n-0.621309\n0.9540629\n0.1553862\n95.45208\n6.139946\n0.0000000\n\n\nsstest\n0\n1.1982546\n0.1099985\n95.83814\n10.893368\n0.0000000\n\n\nsstest\n0.621309\n1.4424463\n0.1547564\n94.09284\n9.320752\n0.0000000\n\n\n\n\n\n\nDie Simple Slope Analyse bestätigt die Visualiserung und zeigt, dass der Effekt von x_dm auf y schwächer ausfällt, aber immer noch signifikant positiv ist, wenn der Moderator w_c unterdurchschnittlich ist (Variante 1, Zeile 4, Variante 2, Zeile 2). Der Effekt fällt stärker aus, wenn der Moderator w_c überdurchschnittlich ist (Variante 1, Zeile 6, Variante 2, Zeile 4).\n\n\n5.1.3 Within-level Interaktion\nAnalog zur Cross-level Interaktion gibt es auch Within-level Interaktionen, bei der die Level-1 Anteile von Prädiktorvariablen miteinander interagieren.\nLevel 1: \\(y_{ij} = \\beta_{0j} + \\beta_{1j}*(X_{ij}-\\overline{X_j}) + \\beta_{2j}*(M_{ij}-\\overline{M_j}) + \\beta_{3j}*((M_{ij}-\\overline{M_j})*(X_{ij}-\\overline{X_j})) + e_{ij}\\)\nLevel 2 (random intercept): \\(\\beta_{0j} = \\gamma_{00} + u_{0j}\\)\nLevel 2 (random slope X): \\(\\beta_{1j} = \\gamma_{10} + u_{1j}\\)\nLevel 2 (random slope M): \\(\\beta_{2j} = \\gamma_{20} + u_{2j}\\)\n\nri.rs_wli_modell &lt;- lmer(y ~ x_dm + m_dm + x_dm*m_dm + (1 + x_dm + m_dm | id), data = df_example1c)\nmodel_parameters(ri.rs_wli_modell) |&gt; print_html()\n\n\n\n\n\n\n\nModel Summary\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(989)\np\n\n\n\n\nFixed Effects\n\n\n(Intercept)\n5.52\n0.10\n(5.32, 5.72)\n54.89\n&lt; .001\n\n\nx dm\n0.17\n0.08\n(9.53e-03, 0.33)\n2.08\n0.038\n\n\nm dm\n0.53\n0.06\n(0.41, 0.66)\n8.46\n&lt; .001\n\n\nx dm × m dm\n-5.19e-03\n0.02\n(-0.04, 0.02)\n-0.34\n0.735\n\n\nRandom Effects\n\n\nSD (Intercept: id)\n0.98\n\n\n\n\n\n\nSD (x_dm: id)\n0.47\n\n\n\n\n\n\nSD (m_dm: id)\n0.53\n\n\n\n\n\n\nCor (Intercept~x_dm: id)\n-0.08\n\n\n\n\n\n\nCor (Intercept~m_dm: id)\n0.04\n\n\n\n\n\n\nCor (x_dm~m_dm: id)\n-0.26\n\n\n\n\n\n\nSD (Residual)\n0.52\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplot_model(ri.rs_wli_modell, type = \"int\", mdrt.values = \"meansd\")\n\n\n\n\n\n\n\n\nDer Interaktionseffekt ist nicht signifikant. Dies bedeutet, wie der Plot zeigt, dass die Linien bei allen Ausprägungen des Moderators mehr oder wenig parallel sind.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Kapitel 5: Hypothestentests 2 - Moderation und Mediation</span>"
    ]
  },
  {
    "objectID": "04 Hypotheses Tests_Erweiterungen.html#übung",
    "href": "04 Hypotheses Tests_Erweiterungen.html#übung",
    "title": "5  Kapitel 5: Hypothestentests 2 - Moderation und Mediation",
    "section": "5.2 Übung",
    "text": "5.2 Übung\nWir arbeiten in der Übung mit einem neuen Datensatz.\nMache dich mit ihm vertraut. Diesmal benutzen wir einen Datensatz in dem die Variablen “labelled” sind, also Beschriftungen haben. Wir können die Labels mit get_label() abrufen.\n\nload(\"../data/df_example_cli.RData\")\n\nhead(df_example_cli)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nilltask\nnegativ\nsupport\nilltask_dm\nnegativ_dm\nilltask_gm\nnegativ_gm\nnegativ_dm_l1\nday\n\n\n\n\n1\n1.188858\n1.825857\n3.454777\n-1.2994333\n-0.0153842\n2.488291\n1.841241\nNA\n1\n\n\n1\n1.719163\n1.633681\n3.454777\n-0.7691283\n-0.2075602\n2.488291\n1.841241\nNA\n4\n\n\n1\n3.149280\n1.250429\n3.454777\n0.6609887\n-0.5908122\n2.488291\n1.841241\nNA\n7\n\n\n1\n2.372508\n1.583838\n3.454777\n-0.1157833\n-0.2574032\n2.488291\n1.841241\n-0.5908122\n8\n\n\n1\n2.558448\n2.912401\n3.454777\n0.0701567\n1.0711598\n2.488291\n1.841241\n-0.2574032\n9\n\n\n2\n1.336438\n2.111289\n2.109855\n0.2807496\n-0.4911521\n1.055688\n2.602441\nNA\n1\n\n\n\n\n\nget_label(df_example_cli)\n\n                                         id \n                              \"Personen-ID\" \n                                    illtask \n                 \"Daily Illegitimate Tasks\" \n                                    negativ \n                    \"Daily Negative Affect\" \n                                    support \n                         \"Coworker support\" \n                                 illtask_dm \n\"Illegitimate Tasks (person-mean centered)\" \n                                 negativ_dm \n       \"Neg. Affect (person-mean centered)\" \n                                 illtask_gm \n      \"Illegitimate Tasks (person average)\" \n                                 negativ_gm \n             \"Neg. Affect (person average)\" \n                              negativ_dm_l1 \n                 \"Previous-day Neg. Affect\" \n                                        day \n                               \"Tag (1-10)\" \n\n# alternativ\nview_df(df_example_cli)\n\n\nData frame: df_example_cli\n\n\nID\nName\nLabel\nValues\nValue Labels\n\n\n1\nid\nPersonen-ID\nrange: 1-100\n\n\n2\nilltask\nDaily Illegitimate Tasks\nrange: -1.9-5.6\n\n\n3\nnegativ\nDaily Negative Affect\nrange: -0.2-7.7\n\n\n4\nsupport\nCoworker support\nrange: 1.4-4.5\n\n\n5\nilltask_dm\nIllegitimate Tasks (person-mean centered)\nrange: -2.1-2.3\n\n\n6\nnegativ_dm\nNeg. Affect (person-mean centered)\nrange: -2.0-2.7\n\n\n7\nilltask_gm\nIllegitimate Tasks (person average)\nrange: -0.7-4.7\n\n\n8\nnegativ_gm\nNeg. Affect (person average)\nrange: 0.8-5.0\n\n\n9\nnegativ_dm_l1\nPrevious-day Neg. Affect\nrange: -2.0-2.7\n\n\n10\nday\nTag (1-10)\nrange: 1-10\n\n\n\n\n\nBerechne Modelle mit denen du die folgenden Hypothesen testest:\nH1: Illegitime Aufgaben hängen positiv mit negativem Affekt zusammen. H2: Der positive Zusammenhang von illegitime Aufgaben mit negativem Affekt fällt schwächer aus, wenn Unterstützung von Kolleg:innen hoch ausgeprägt ist.\nGehe Schritt für Schritt vor und teste erst in einem Modell H1, dann in einem anderen Modell H2. Urteile, ob die Hypothesen angenommen oder verworfen werden sollten.\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nri.rs_modell &lt;- lmer(negativ ~ illtask_dm  + support + (1 + illtask_dm | id), data = df_example_cli)\nparameters(ri.rs_modell)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\nCI\nCI_low\nCI_high\nt\ndf_error\np\nEffects\nGroup\n\n\n\n\n(Intercept)\n3.4515583\n0.3038234\n0.95\n2.8551451\n4.0479715\n11.360409\n776\n0.0000000\nfixed\n\n\n\nilltask_dm\n0.3256395\n0.0513930\n0.95\n0.2247537\n0.4265253\n6.336261\n776\n0.0000000\nfixed\n\n\n\nsupport\n-0.2468958\n0.1012860\n0.95\n-0.4457228\n-0.0480687\n-2.437610\n776\n0.0150083\nfixed\n\n\n\nSD (Intercept)\n0.6661075\nNA\n0.95\nNA\nNA\nNA\nNA\nNA\nrandom\nid\n\n\nSD (illtask_dm)\n0.3534636\nNA\n0.95\nNA\nNA\nNA\nNA\nNA\nrandom\nid\n\n\nCor (Intercept~illtask_dm)\n0.6940618\nNA\n0.95\nNA\nNA\nNA\nNA\nNA\nrandom\nid\n\n\nSD (Observations)\n0.6775572\nNA\n0.95\nNA\nNA\nNA\nNA\nNA\nrandom\nResidual\n\n\n\n\n\n\nDer Zusammenhang von täglichen illegitimen Aufgaben (illtask_dm) mit negativem Affekt (negativ) ist signifikant (b = 0.33, p &lt; .001), was Hypothese 1 unterstützt.\n\nri.rs_cli_modell &lt;- lmer(negativ ~ illtask_dm  + support*illtask_dm + (1 + illtask_dm | id), data = df_example_cli)\nparameters(ri.rs_cli_modell)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\nCI\nCI_low\nCI_high\nt\ndf_error\np\nEffects\nGroup\n\n\n\n\n(Intercept)\n3.4723696\n0.3361052\n0.95\n2.8125852\n4.1321541\n10.3311992\n775\n0.0000000\nfixed\n\n\n\nilltask_dm\n0.3598764\n0.2459646\n0.95\n-0.1229594\n0.8427122\n1.4631228\n775\n0.1438392\nfixed\n\n\n\nsupport\n-0.2540133\n0.1126112\n0.95\n-0.4750724\n-0.0329541\n-2.2556656\n775\n0.0243697\nfixed\n\n\n\nilltask_dm:support\n-0.0116576\n0.0823355\n0.95\n-0.1732847\n0.1499694\n-0.1415871\n775\n0.8874429\nfixed\n\n\n\nSD (Intercept)\n0.6668935\nNA\n0.95\nNA\nNA\nNA\nNA\nNA\nrandom\nid\n\n\nSD (illtask_dm)\n0.3567497\nNA\n0.95\nNA\nNA\nNA\nNA\nNA\nrandom\nid\n\n\nCor (Intercept~illtask_dm)\n0.6950819\nNA\n0.95\nNA\nNA\nNA\nNA\nNA\nrandom\nid\n\n\nSD (Observations)\n0.6776777\nNA\n0.95\nNA\nNA\nNA\nNA\nNA\nrandom\nResidual\n\n\n\n\n\n\nDer Interaktionseffekt von täglichen illegitimen AUfgaben mit sozialer Unterstützung durch Kolleg:innen auf negativen Affekt ist nicht signifikant (b = -0.01, p = .89). Hypothese 2 muss somit verworfen werden.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Kapitel 5: Hypothestentests 2 - Moderation und Mediation</span>"
    ]
  },
  {
    "objectID": "04 Hypotheses Tests_Erweiterungen.html#mediation",
    "href": "04 Hypotheses Tests_Erweiterungen.html#mediation",
    "title": "5  Kapitel 5: Hypothestentests 2 - Moderation und Mediation",
    "section": "5.3 1-1-1 Mediation",
    "text": "5.3 1-1-1 Mediation\nIm Folgenden erstellen wir ein Mediationsmodellen und spezifizieren bei den Argumenten x, y, und m die die unabhängige, abhängige, und mediierende Variable. Für die abhängige Variablen wählen wir die Rohvariable, für unabhängige und mediierende Variablen die personen-zentrierten Variablen.\nDie 1-1-1 Mediation ist die gängigste Variante, in der alle Variablen (X, M[ediator], und Y) auf Tagesebene gemessen werden.\n\n5.3.1 Daten einlesen\n\nload(\"../data/df_example1.RData\")\nhead(df_example1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\ny\nm\nx\ny_dm\nm_dm\nx_dm\ny_gm\nm_gm\nx_gm\n\n\n\n\n1\n4.003538\n4.769391\n2.365486\n-0.3020232\n0.8945291\n0.6845636\n4.305561\n3.874862\n1.680922\n\n\n1\n4.925174\n2.510943\n0.748855\n0.6196128\n-1.3639189\n-0.9320674\n4.305561\n3.874862\n1.680922\n\n\n1\n4.598564\n3.098112\n1.395041\n0.2930028\n-0.7767499\n-0.2858814\n4.305561\n3.874862\n1.680922\n\n\n1\n4.286179\n4.610746\n1.860026\n-0.0193822\n0.7358841\n0.1791036\n4.305561\n3.874862\n1.680922\n\n\n1\n4.183494\n4.549044\n2.288019\n-0.1220672\n0.6741821\n0.6070966\n4.305561\n3.874862\n1.680922\n\n\n1\n3.631716\n3.590049\n1.696510\n-0.6738452\n-0.2848129\n0.0155876\n4.305561\n3.874862\n1.680922\n\n\n\n\n\n\nZum Testen verwenden wir zunächst die Funktion modmed.mlm(). Anders als bei den früheren ANalysen steht uns das parameters Paket hier nicht zur Verfügung um die Ergebnisse zusammenzufassen. Stattdessen nehmen wir die summary() Funktion.\n\nfit_mediation &lt;- modmed.mlm(df_example1, \"id\", \"x_dm\", \"y\", \"m_dm\",\n                                random.int.m = FALSE,\n                                na.action = na.omit)\n\nsummary(fit_mediation$model)\n\nLinear mixed-effects model fit by REML\n  Data: tmp \n       AIC      BIC    logLik\n  4255.191 4299.979 -2119.596\n\nRandom effects:\n Formula: ~0 + Sy | L2id\n               Sy  Residual\nStdDev: 0.8445188 0.6973181\n\nVariance function:\n Structure: Different standard deviations per stratum\n Formula: ~1 | Sm \n Parameter estimates:\n        0         1 \n1.0000000 0.8655498 \nFixed effects:  as.formula(fixed.formula) \n       Value  Std.Error   DF  t-value p-value\nSm  0.000000 0.01908636 1896  0.00000   1e+00\nSy  5.367553 0.08728329 1896 61.49577   0e+00\nSmX 0.514122 0.02887261 1896 17.80656   0e+00\nSyX 0.139023 0.03829162 1896  3.63064   3e-04\nSyM 0.583714 0.03657147 1896 15.96090   0e+00\n Correlation: \n    Sm     Sy     SmX    SyX   \nSy   0.000                     \nSmX  0.000  0.000              \nSyX  0.000  0.000  0.000       \nSyM  0.000  0.000  0.000 -0.491\n\nStandardized Within-Group Residuals:\n         Min           Q1          Med           Q3          Max \n-5.950445926 -0.596749015 -0.007671515  0.623219431  4.479879774 \n\nNumber of Observations: 2000\nNumber of Groups: 100 \n\n\nDie ausgegebenen Zeilen/Parameter sind etwas kryptisch beschrieben.\n\nSm - fixed Intercept von M\nSy - fixed Intercept von Y\nSmX - fixed Slope von X auf M (a-Pfad)\nSyX - fixed Slope von Y auf X (c’-Pfad)\nSyM - fixed Slope von Y auf M (b-Pfad)\n\n\n\n5.3.2 Bootstrapped Version\nDer indirekte Effekt von X auf Y via M (a-Pfad * b-Pfad) der uns in der Mediation von zentralem Interesse ist, ist in der Regel nicht normalverteilt, da ein Produkt zweier (oder mehrerer) Pfadkoeffizienten nicht wie die Pfadkoeffizienten selber approximativ normalverteilt ist. Aufgrund der fehlenden Normalverteilung verwenden wir die Bootstrap-Schätzung, um eine robustere Aussage über die Signifikanz des indirekten Effekts zu bekommen.\n\nboot.custom.results &lt;- boot.modmed.mlm.custom(\n  data = df_example1 |&gt; as.data.frame(),\n  L2ID = \"id\",\n  X = \"x_dm\",\n  Y = \"y\",\n  M = \"m_dm\",\n  random.int.m = FALSE,\n  control = list(opt = \"nlm\"),\n  na.action = na.omit,\n  return.type = \"all\",\n  nrep = 1000,\n  parallel.type = \"parallel\",\n  ncores = 4,\n  seed = 2299)\n\n\nsummary(boot.custom.results$model)\n\nLinear mixed-effects model fit by REML\n  Data: tmp \n       AIC      BIC    logLik\n  4255.191 4299.979 -2119.596\n\nRandom effects:\n Formula: ~0 + Sy | L2id\n               Sy  Residual\nStdDev: 0.8445016 0.6973198\n\nVariance function:\n Structure: Different standard deviations per stratum\n Formula: ~1 | Sm \n Parameter estimates:\n        0         1 \n1.0000000 0.8655476 \nFixed effects:  as.formula(fixed.formula) \n       Value  Std.Error   DF  t-value p-value\nSm  0.000000 0.01908635 1896  0.00000   1e+00\nSy  5.367553 0.08728164 1896 61.49693   0e+00\nSmX 0.514122 0.02887260 1896 17.80657   0e+00\nSyX 0.139023 0.03829171 1896  3.63063   3e-04\nSyM 0.583714 0.03657156 1896 15.96086   0e+00\n Correlation: \n    Sm     Sy     SmX    SyX   \nSy   0.000                     \nSmX  0.000  0.000              \nSyX  0.000  0.000  0.000       \nSyM  0.000  0.000  0.000 -0.491\n\nStandardized Within-Group Residuals:\n         Min           Q1          Med           Q3          Max \n-5.950427733 -0.596748613 -0.007673935  0.623218790  4.479873395 \n\nNumber of Observations: 2000\nNumber of Groups: 100 \n\nextract.modmed.mlm(boot.custom.results, type=\"all\")\n\n           Sm            Sy           SmX           SyX           SyM \n-7.971267e-17  5.367553e+00  5.141219e-01  1.390232e-01  5.837135e-01 \n      re.SySy \n 7.131830e-01 \n\nextract.modmed.mlm(boot.custom.results, type=\"indirect\")\n\n[1] 0.3000999\n\n# manual extract of CI\nindirect_boot &lt;- tibble(SyM = boot.custom.results[[\"t\"]][,which(names(boot.custom.results[[\"t0\"]]) == \"SyM\")], \n                        SmX = boot.custom.results[[\"t\"]][,which(names(boot.custom.results[[\"t0\"]]) == \"SmX\")]) |&gt; \n  mutate(indirect = SyM * SmX)\nquantile(indirect_boot$indirect, c(0.025, 0.975), na.rm = TRUE)\n\n     2.5%     97.5% \n0.1979216 0.4113055 \n\n# zusammenfassen\nindirect_punktschaetzung &lt;- extract.modmed.mlm(boot.custom.results, type=\"indirect\")\nindirekt_ci &lt;- quantile(indirect_boot$indirect, c(0.025, 0.975), na.rm = TRUE)\nindirekt_zusammenfassung &lt;-\n  tibble(Koeffizient = indirect_punktschaetzung,\n         LLCI = indirekt_ci[1],\n         ULCI = indirekt_ci[2]) |&gt; \n  mutate(across(where(is.numeric), round, 3))\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `across(where(is.numeric), round, 3)`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))\n\n\nDer indirekte Effekt und sein 95% Konfidenzintervall müssen wir aus den Daten extrahieren. Wenn der 95% Konfidenzintervall die 0 ausschliesst (also sowohl unterer als auch oberes Limit entweder unter Null oder über Null liegen) können wir den indirekten Effekt als signifikant ansehen.\nIn diesem Beispiel finden wir also einen signifikanten indirekten Effekt mit Koeffizient = 0.30, 95% CI = [0.19, 0.41].\nLLCI = Lower Limit of Confidence Interval\nULCI = Upper Limit of Confidence Interval",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Kapitel 5: Hypothestentests 2 - Moderation und Mediation</span>"
    ]
  },
  {
    "objectID": "04 Hypotheses Tests_Erweiterungen.html#übung-1",
    "href": "04 Hypotheses Tests_Erweiterungen.html#übung-1",
    "title": "5  Kapitel 5: Hypothestentests 2 - Moderation und Mediation",
    "section": "5.4 Übung",
    "text": "5.4 Übung\nWir arbeiten in der Übung mit einem neuen Datensatz.\nMache dich mit ihm vertraut. Wie in der Cross-Level Interaktionsübung benutzen wir einen Datensatz in dem die Variablen “labelled” sind, also Beschriftungen haben. Wir können die Labels mit get_label() abrufen.\n\nload(\"../data/df_111_uebung.RData\")\n\nhead(df_111_uebung)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nhelfen\nwertschaetz\nselbstwert\nwertschaetz_dm\nselbstwert_dm\nwertschaetz_gm\nselbstwert_gm\n\n\n\n\n1\n4.714438\n1.371902\n4.441296\n-0.0437649\n-0.7058638\n1.415667\n5.14716\n\n\n1\n3.622743\n0.574266\n5.981966\n-0.8414009\n0.8348062\n1.415667\n5.14716\n\n\n1\n5.337310\n1.472314\n5.407452\n0.0566471\n0.2602922\n1.415667\n5.14716\n\n\n1\n4.938451\n2.790352\n5.428928\n1.3746851\n0.2817682\n1.415667\n5.14716\n\n\n1\n3.742165\n1.204333\n5.369987\n-0.2113339\n0.2228272\n1.415667\n5.14716\n\n\n1\n4.607774\n1.744993\n4.644467\n0.3293261\n-0.5026928\n1.415667\n5.14716\n\n\n\n\n\nget_label(df_111_uebung)\n\n                                               id \n                                    \"Personen-ID\" \n                                           helfen \n                              \"Proaktives Helfen\" \n                                      wertschaetz \n                       \"erfahrene Wertschaetzung\" \n                                       selbstwert \n                                     \"Selbstwert\" \n                                   wertschaetz_dm \n\"erfahrene Wertschaetzung (person-mean centered)\" \n                                    selbstwert_dm \n              \"Selbstwert (person-mean centered)\" \n                                   wertschaetz_gm \n      \"erfahrene Wertschaetzung (person average)\" \n                                    selbstwert_gm \n                    \"Selbstwert (person average)\" \n\n# alternativ\nview_df(df_111_uebung)\n\n\nData frame: df_111_uebung\n\n\n\n\n\n\n\n\n\nID\nName\nLabel\nValues\nValue Labels\n\n\n1\nid\nPersonen-ID\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n&lt;... truncated&gt;\n\n\n2\nhelfen\nProaktives Helfen\nrange: 0.1-9.1\n\n\n3\nwertschaetz\nerfahrene Wertschaetzung\nrange: -2.4-5.5\n\n\n4\nselbstwert\nSelbstwert\nrange: 0.9-8.0\n\n\n5\nwertschaetz_dm\nerfahrene Wertschaetzung (person-mean centered)\nrange: -2.0-2.4\n\n\n6\nselbstwert_dm\nSelbstwert (person-mean centered)\nrange: -2.7-2.5\n\n\n7\nwertschaetz_gm\nerfahrene Wertschaetzung (person average)\nrange: -1.0-4.6\n\n\n8\nselbstwert_gm\nSelbstwert (person average)\nrange: 2.7-6.4\n\n\n\n\n\nBerechne Modelle mit denen du die folgenden Hypothesen testest:\nH1: Tägliche Wertschätzung durch Vorgesetzte und Kolleg:innen hängen positiv mit dem täglichen Selbstwert zusammen. H2: Täglicher Selbstwert hängt positiv mit täglichem proaktivem Helfen zusammen. H3: Es gibt einen positiven indirekten Zusammenhang zwischen täglicher Wertschätzung und täglichem proaktiven Helfen, vermittel durch den täglichen Selbstwert.\nTeste die Hypothesen in einem Modell mittels der boot.modmed.mlm.custom() Funktion. Urteile, ob die Hypothesen angenommen oder verworfen werden sollten.\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n# | cache: true\nboot.custom.results &lt;- boot.modmed.mlm.custom(\n  data = df_111_uebung |&gt; remove_all_labels(),\n  L2ID = \"id\",\n  X = \"wertschaetz_dm\",\n  Y = \"helfen\",\n  M = \"selbstwert_dm\",\n  random.int.m = FALSE,\n  control = list(opt = \"nlm\"),\n  na.action = na.omit,\n  return.type = \"all\",\n  nrep = 1000,\n  parallel.type = \"parallel\",\n  ncores = 4,\n  seed = 2299)\n\n\nsummary(boot.custom.results$model)\n\nLinear mixed-effects model fit by REML\n  Data: tmp \n       AIC      BIC    logLik\n  4461.098 4505.886 -2222.549\n\nRandom effects:\n Formula: ~0 + Sy | L2id\n               Sy  Residual\nStdDev: 0.9352867 0.7376009\n\nVariance function:\n Structure: Different standard deviations per stratum\n Formula: ~1 | Sm \n Parameter estimates:\n       0        1 \n1.000000 0.853954 \nFixed effects:  as.formula(fixed.formula) \n       Value  Std.Error   DF  t-value p-value\nSm  0.000000 0.01991847 1896  0.00000   1e+00\nSy  4.760590 0.09639329 1896 49.38715   0e+00\nSmX 0.403544 0.02922104 1896 13.81007   0e+00\nSyX 0.333455 0.03734523 1896  8.92898   0e+00\nSyM 0.142299 0.03706805 1896  3.83887   1e-04\n Correlation: \n    Sm     Sy     SmX    SyX   \nSy   0.000                     \nSmX  0.000  0.000              \nSyX  0.000  0.000  0.000       \nSyM  0.000  0.000  0.000 -0.401\n\nStandardized Within-Group Residuals:\n       Min         Q1        Med         Q3        Max \n-3.7071940 -0.6329247  0.0197032  0.6318337  3.6275758 \n\nNumber of Observations: 2000\nNumber of Groups: 100 \n\nextract.modmed.mlm(boot.custom.results, type=\"all\")\n\n           Sm            Sy           SmX           SyX           SyM \n-1.163247e-16  4.760590e+00  4.035445e-01  3.334548e-01  1.422995e-01 \n      re.SySy \n 8.747611e-01 \n\nextract.modmed.mlm(boot.custom.results, type=\"indirect\")\n\n[1] 0.05742417\n\n# manual extract of CI\nindirect_boot &lt;- tibble(SyM = boot.custom.results[[\"t\"]][,which(names(boot.custom.results[[\"t0\"]]) == \"SyM\")], \n                        SmX = boot.custom.results[[\"t\"]][,which(names(boot.custom.results[[\"t0\"]]) == \"SmX\")]) |&gt; \n  mutate(indirect = SyM * SmX)\nquantile(indirect_boot$indirect, c(0.025, 0.975), na.rm = TRUE)\n\n        2.5%        97.5% \n-0.005407806  0.137634291 \n\n# zusammenfassen\nindirect_punktschaetzung &lt;- extract.modmed.mlm(boot.custom.results, type=\"indirect\")\nindirekt_ci &lt;- quantile(indirect_boot$indirect, c(0.025, 0.975), na.rm = TRUE)\nindirekt_zusammenfassung &lt;-\n  tibble(Koeffizient = indirect_punktschaetzung,\n         LLCI = indirekt_ci[1],\n         ULCI = indirekt_ci[2]) |&gt; \n  mutate(across(where(is.numeric), round, 3))\nindirekt_zusammenfassung\n\n\n\n\n\nKoeffizient\nLLCI\nULCI\n\n\n\n\n0.057\n-0.005\n0.138\n\n\n\n\n\n\nH1 wird unterstützt (SmX: b = 0.40, p &lt; .001). H2 wird verworfen (SyM: b = 0.14, p &lt; .40). H3: wird entsprechend auch verworfen (95% CI des indirekten Effekt schliesst die 0 ein). Es besteht aber ein direkter Zusammenhang zwischen X und Y (SyX: b = 0.33, p &lt; .001), der, anders als angenommen, nicht indirekt über Selbstwert vermittelt wird.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Kapitel 5: Hypothestentests 2 - Moderation und Mediation</span>"
    ]
  },
  {
    "objectID": "00 Data Wrangling Basics.html",
    "href": "00 Data Wrangling Basics.html",
    "title": "6  Anhang: Data Wrangling",
    "section": "",
    "text": "6.1 Notebooks\nData Wrangling bezeichnet im Kontext der psychologischen Datenanalyse mit R den systematischen Prozess der Aufbereitung, Bereinigung und Umstrukturierung von Rohdaten, damit sie für statistische Auswertungen und Interpretationen nutzbar werden. Ziel ist es, aus unübersichtlichen Rohdaten ein strukturiertes und hochwertiges Daten-Set zu erzeugen, das sich zuverlässig und nachvollziehbar für weiterführende statistische Analysen, Modellierungen und Visualisierungen in R nutzen lässt.\nIm Folgenden werden dazu verschiedene Funktionen und Techniken dargestellt.\nIn diesem Kurs arbeiten wir mit R- bzw. Quarto-Notebooks. Diese enthalten sowohl normalen Text als auch “Chunks” von R-Code. Chunks sind Abschnitte von R-Code. Diese Chunks lassen sich mit einem Klick auf Code –&gt; Insert Chunk (oder der Tastenkombination Alt + Ctrl + I / unter Mac: Alt + Cmd + I) einfügen. Diese Chunks lassen sich mit einem Klick auf den grünen Play-Button ganz rechts ausführen. Der Pfeil nach unten Button (zweiter von Rechts) führt alle Chunks, die vor dem gewählten Chunk gelagert sind, aus.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Anhang: Data Wrangling</span>"
    ]
  },
  {
    "objectID": "00 Data Wrangling Basics.html#pakete-laden",
    "href": "00 Data Wrangling Basics.html#pakete-laden",
    "title": "6  Anhang: Data Wrangling",
    "section": "6.2 Pakete laden",
    "text": "6.2 Pakete laden\nZunächst laden wir die Pakete, die wir für die Sitzung brauchen.\n\nif (!require(\"pacman\")) install.packages(\"pacman\")\n\nLade nötiges Paket: pacman\n\npacman::p_load(psych, tidyverse)\ndata(sat.act)\ndf_beispiel &lt;-as_tibble(sat.act)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Anhang: Data Wrangling</span>"
    ]
  },
  {
    "objectID": "00 Data Wrangling Basics.html#hilfe-menü-und-dokumentation",
    "href": "00 Data Wrangling Basics.html#hilfe-menü-und-dokumentation",
    "title": "6  Anhang: Data Wrangling",
    "section": "6.3 Hilfe-Menü und Dokumentation",
    "text": "6.3 Hilfe-Menü und Dokumentation\nFür jede Funktion in einem geladenen Paket können Sie einfach ? vor den Funktionsnamen schreiben, um das Hilfemenü bzw. ihre Dokumentation aufzurufen. Dies hilft Ihnen, den Zweck der Funktion, ihre Argumente und Ausgaben zu verstehen. Sie können auch auf den Namen der Funktion klicken (an beliebiger Stelle im Namen) und “F1” drücken.\n\n?head\nhead(df_beispiel)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Anhang: Data Wrangling</span>"
    ]
  },
  {
    "objectID": "00 Data Wrangling Basics.html#struktur-von-funktionen",
    "href": "00 Data Wrangling Basics.html#struktur-von-funktionen",
    "title": "6  Anhang: Data Wrangling",
    "section": "6.4 Struktur von Funktionen",
    "text": "6.4 Struktur von Funktionen\nFast alles in R geschieht mittels Funktionen. Funktionen nehmen Inputs und transformieren sie nach den Regeln der Funktion in Outputs. Die Funktion kann mittels Argumenten gesteuert werden.\n\nFunktionen sind i.d.R. benannt (hier head, mean) und mit Klammern () gekennzeichet. In der Klammer befinden sich die Argumente der Funktion, mit einem Komma getrennt. Argumente können benannt oder unbenannt sein. Werden Sie nicht benannt, folgt R der Reihenfolge der erwarteten Argumente, wie sie in der Funktionsdokumentation beschrieben sind.\nUnbenannt hier: 10 bei head()\nBenannt hier: na.rm = TRUE bei mean(), wobei na.rm der Name und TRUE der Inhalt des Argument sind.\n\n\nhead(df_beispiel, 10)\n\n# A tibble: 10 × 6\n   gender education   age   ACT  SATV  SATQ\n    &lt;int&gt;     &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;\n 1      2         3    19    24   500   500\n 2      2         3    23    35   600   500\n 3      2         3    20    21   480   470\n 4      1         4    27    26   550   520\n 5      1         2    33    31   600   550\n 6      1         5    26    28   640   640\n 7      2         5    30    36   610   500\n 8      1         3    19    22   520   560\n 9      2         4    23    22   400   600\n10      2         5    40    35   730   800\n\nmean(df_beispiel$age, na.rm = TRUE)\n\n[1] 25.59429",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Anhang: Data Wrangling</span>"
    ]
  },
  {
    "objectID": "00 Data Wrangling Basics.html#zuweisung-assignment-mittels--",
    "href": "00 Data Wrangling Basics.html#zuweisung-assignment-mittels--",
    "title": "6  Anhang: Data Wrangling",
    "section": "6.5 Zuweisung / Assignment mittels <-",
    "text": "6.5 Zuweisung / Assignment mittels &lt;-\n\n&lt;- führt die Zuweisung (assignment) von Inhalten der rechten Seite unter dem Namen auf der linken Seite aus. Wir nennen die zugewiesenen Inhalte, etwas verkürzt gesagt, Objekte oder Variablen.\n\n\ndurchschnitt_von_SATV &lt;- mean(df_beispiel$SATV, na.rm = TRUE)\n\nIn diesem Beispiel ist durchschnitt_von_SATV der Name des Objekts/Variable.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Anhang: Data Wrangling</span>"
    ]
  },
  {
    "objectID": "00 Data Wrangling Basics.html#typen-von-objekten",
    "href": "00 Data Wrangling Basics.html#typen-von-objekten",
    "title": "6  Anhang: Data Wrangling",
    "section": "6.6 Typen von Objekten",
    "text": "6.6 Typen von Objekten\nDie häufigsten Typen von Objekten/Variablen sind:\n\nVektor, numerisch\nVektor, Character (Buchstaben)\ndata frame (Datenframe, Tabelle)\ntibble - eine verbesserte Variante eines data frame\nlist (Liste)\n\nEinen Vektor erstellt man mit der c() Funktionen\n\nvektor_numerisch &lt;- c(1,2,3,4,5)\nvektor_character &lt;- c(\"Zytglogge\", \"Hirschengraben\", \"Bahnhof\", \"Bundesplatz\", \"Viktoriaplatz\")\ndatenframe &lt;- data.frame(Nummer = vektor_numerisch, Ort = vektor_character)\ndatenframe\n\n  Nummer            Ort\n1      1      Zytglogge\n2      2 Hirschengraben\n3      3        Bahnhof\n4      4    Bundesplatz\n5      5  Viktoriaplatz\n\ntibble_beispiel &lt;- tibble(Nummer = vektor_numerisch, Ort = vektor_character)\ntibble_beispiel\n\n# A tibble: 5 × 2\n  Nummer Ort           \n   &lt;dbl&gt; &lt;chr&gt;         \n1      1 Zytglogge     \n2      2 Hirschengraben\n3      3 Bahnhof       \n4      4 Bundesplatz   \n5      5 Viktoriaplatz \n\n\nWie wir sehen, sind Datenframes i.d.R. aus Vektoren der gleichen Länge, aber oft unterschiedlichen Typs, aufgebaut.\n\nbeispielliste &lt;- list(x1 = vektor_numerisch, x2 = vektor_character, c(6,7,8), x3 = tibble_beispiel, \"test\")\nbeispielliste\n\n$x1\n[1] 1 2 3 4 5\n\n$x2\n[1] \"Zytglogge\"      \"Hirschengraben\" \"Bahnhof\"        \"Bundesplatz\"   \n[5] \"Viktoriaplatz\" \n\n[[3]]\n[1] 6 7 8\n\n$x3\n# A tibble: 5 × 2\n  Nummer Ort           \n   &lt;dbl&gt; &lt;chr&gt;         \n1      1 Zytglogge     \n2      2 Hirschengraben\n3      3 Bahnhof       \n4      4 Bundesplatz   \n5      5 Viktoriaplatz \n\n[[5]]\n[1] \"test\"\n\n\nListen sind extrem flexibel, was ihre Anhalte angeht - wir können quasi alles reinpacken. Das macht sie teils aber auch schwer zu durchschauen. Wenn möglich empfiehlt es sich, mit tibble/data.frame zu arbeiten; dies spart kognitive Ressourcen.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Anhang: Data Wrangling</span>"
    ]
  },
  {
    "objectID": "00 Data Wrangling Basics.html#die-pipe-oder",
    "href": "00 Data Wrangling Basics.html#die-pipe-oder",
    "title": "6  Anhang: Data Wrangling",
    "section": "6.7 Die “Pipe” (%>% oder |>)",
    "text": "6.7 Die “Pipe” (%&gt;% oder |&gt;)\n%&gt;% ist der ursprüngliche Pipe-Operator, der für das Paket {magrittr} entwickelt wurde und in den gesamten tidyverse-Paketen verwendet wird. Er ist etwas langsamer, aber auch flexibler. |&gt; ist eine neuere Version des Pipe-Operators, die in Base-R integriert wurde. Sie ist etwas schneller, aber weniger flexibel.\nDie Ausgabe des linken Teils der Pipe wird als Eingabe für den rechten Teil der Pipe verwendet, in der Regel als erstes Argument oder als Datenargument. Effektiv transportiert die Pipe den Inhalt von links nach rechts weiter. Schreiben lässt sich die Pipe mit den Tasten Ctrl + Shift + M (unter Windows; unter Mac Cmd + Shift + M?).\n\n# use a function without the pipe\nexample_without_pipe &lt;- select(df_beispiel, gender, ACT)\n\n# use a function with the pipe. \nexample_with_pipe &lt;- df_beispiel |&gt; \n  select(gender, ACT)\n\n\nexample_without_pipe\n\n# A tibble: 700 × 2\n   gender   ACT\n    &lt;int&gt; &lt;int&gt;\n 1      2    24\n 2      2    35\n 3      2    21\n 4      1    26\n 5      1    31\n 6      1    28\n 7      2    36\n 8      1    22\n 9      2    22\n10      2    35\n# ℹ 690 more rows\n\nexample_with_pipe\n\n# A tibble: 700 × 2\n   gender   ACT\n    &lt;int&gt; &lt;int&gt;\n 1      2    24\n 2      2    35\n 3      2    21\n 4      1    26\n 5      1    31\n 6      1    28\n 7      2    36\n 8      1    22\n 9      2    22\n10      2    35\n# ℹ 690 more rows\n\n# check they produce identical results\nidentical(example_without_pipe, example_with_pipe)\n\n[1] TRUE\n\n\n\n6.7.1 Warum lohnt es sich, die Pipe zu nutzen?\nDer Pipe-Operator ermöglicht es uns, Code zu schreiben, der von oben nach unten gelesen wird und einer Abfolge von Schritten folgt – so, wie Menschen Schritte organisieren und beschreiben. Ohne den Pipe-Operator wird der Code von innen nach aussen geschrieben, auf eine Weise, die der Computer versteht, aber für Menschen weniger intuitiv ist. Die Unterscheide in der Lesbarkeit zeigen sich vor allem bei komplexeren, verketteten Funktionen.\nWir verwenden im Folgenden einen Datenframe, wählen mit select() Spalten aus, und erstellen ihre Mittelwerte mit colMeans(). Ohne Pipe lesen wir von innen nach aussen: select(…), dann colMeans(…); mit Pipe lesen und schreiben wir: Objekt - select() - colMeans(), was einfacher nachzuvollziehen ist. Jede Funktion macht etwas, die Pipe gibt jeweils den transformierten Inhalt weiter an die nächste Funktion.\n\n# use a function without the pipe\nexample_without_pipe &lt;- colMeans(select(df_beispiel, SATV, SATQ), na.rm = TRUE)\n\nexample_without_pipe\n\n    SATV     SATQ \n612.2343 610.2169 \n\n# use a function with the pipe. \nexample_with_pipe &lt;- df_beispiel |&gt; \n  select(SATV, SATQ) |&gt; \n  colMeans(na.rm = TRUE)\n\n# check they produce identical results\nidentical(example_without_pipe, example_with_pipe)\n\n[1] TRUE",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Anhang: Data Wrangling</span>"
    ]
  },
  {
    "objectID": "00 Data Wrangling Basics.html#spaltennamen-anzeigen",
    "href": "00 Data Wrangling Basics.html#spaltennamen-anzeigen",
    "title": "6  Anhang: Data Wrangling",
    "section": "6.8 Spaltennamen anzeigen",
    "text": "6.8 Spaltennamen anzeigen\nDie meiste Zeit verbringen wir mit Data Frames - effektiv Tabellen. Wie können wir herausfinden, welche Variablen sich in einem Data Frame befinden? Wir können den Data Frame anzeigen, aber es kann auch hilfreich sein, ihn auszugeben. Zu wissen, welche Variablen vorhanden sind, ist einer der ersten Schritte, um mit den Daten zu arbeiten.\n\n# print all column names\ncolnames(df_beispiel)\n\n[1] \"gender\"    \"education\" \"age\"       \"ACT\"       \"SATV\"      \"SATQ\"     \n\n# print all column names as a vector using the pipe\ndf_beispiel |&gt; \n  colnames()\n\n[1] \"gender\"    \"education\" \"age\"       \"ACT\"       \"SATV\"      \"SATQ\"",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Anhang: Data Wrangling</span>"
    ]
  },
  {
    "objectID": "00 Data Wrangling Basics.html#spalten-umbenennen---rename",
    "href": "00 Data Wrangling Basics.html#spalten-umbenennen---rename",
    "title": "6  Anhang: Data Wrangling",
    "section": "6.9 Spalten umbenennen - rename()",
    "text": "6.9 Spalten umbenennen - rename()\nOft sind die Variablennamen nicht intuitiv. Ein früher Schritt bei jeder Datenaufbereitung ist es, sie mithilfe der Funktion rename() intuitiver zu gestalten. Als Argumente schreiben wir jeweils neuer_name = alter_name.\n\ndf_beispiel_renamed &lt;- df_beispiel |&gt; \n  rename(Alter = age,\n         Bildung = education)",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Anhang: Data Wrangling</span>"
    ]
  },
  {
    "objectID": "00 Data Wrangling Basics.html#auswahl-und-extraktion",
    "href": "00 Data Wrangling Basics.html#auswahl-und-extraktion",
    "title": "6  Anhang: Data Wrangling",
    "section": "6.10 Auswahl und Extraktion",
    "text": "6.10 Auswahl und Extraktion\nEs gibt verschieden Möglichkeiten, Inhalte aus Variablen auszuwählen und zu extrahieren:\n\nselect() / |&gt; slice() / pluck()\n[]\n$\n\nIm ersten Beispiel wollen wir die Variable x aus unserem Dataframe df_beispiel auswählen.\n\ndf_beispiel |&gt; select(ACT) # select mit pipe\n\n# A tibble: 700 × 1\n     ACT\n   &lt;int&gt;\n 1    24\n 2    35\n 3    21\n 4    26\n 5    31\n 6    28\n 7    36\n 8    22\n 9    22\n10    35\n# ℹ 690 more rows\n\ndf_beispiel[,\"ACT\"] # []\n\n# A tibble: 700 × 1\n     ACT\n   &lt;int&gt;\n 1    24\n 2    35\n 3    21\n 4    26\n 5    31\n 6    28\n 7    36\n 8    22\n 9    22\n10    35\n# ℹ 690 more rows\n\ndf_beispiel$ACT # $ \n\n  [1] 24 35 21 26 31 28 36 22 22 35 32 29 21 35 27 27 33 32 28 32 28 30 31 30 31\n [26] 30 30 21 28 33 28 24 27 31 33 29 28 24 27 31 28 29 30 36 36 26 33 27 23 33\n [51] 35 28 28 33 34 26 36 28 18 34 34 32 36 34 21 31 22 29 29 24 26 29 28 32 32\n [76] 27 28 32 15 21 26 25 31 26 28 33 24 32 31 30 32 36 32 30 27 35 29 33 30 32\n[101] 26 36 36 27 26 29 23 23 29 32 32 30 28 23 36 26 36 34 23 28 23 28 32 16 29\n[126] 29 29 32 26 23 35 28 25 23 36 30 30 33 31 28 35 32 26 34 34 32 24 32 23 35\n[151] 24 30 26 26 30 34 19 23 31 28 32 25 26 31 34 31 30 36 32 33 29 25 30 34 32\n[176] 29 25 32 33 35 26 24 23 35 27 28 27 28 32 34 27 31 17 25 36 29 30 29 28 28\n[201] 30 30 31 29 28 26 31 25 21 24 36 34 32 23 36 34 28 19 31 21 19 22 30 18 36\n[226] 28 24 28 23 30 22 23 25 25 24 30 30 24 22 22 27 27 35 16 28 25 23 32 25 28\n[251] 35 28 24 27 30 34 35 33 19 25 35 26 24 20 30 32 30 29 28 23 36 25 29 20 32\n[276] 24 30 33 21 20 32 30 31 25 18 25 26 29 33 31 25 27 36 32 32 26 23 34 27 30\n[301] 30 28 25 20 26 33 23 33 25 27 26 28 28 35 21 28 29 32 30 18 32 32 27 17 28\n[326] 21 30 25 32 35 32 16 27 27 20 31 30 24 26 19 24 27 35 27 32 26 25 29 36 30\n[351] 25 22 27 23 34 31 33 31 26 35 33 29 28 27 27 31 31 32 22 35 25 25 23 26 27\n[376] 27 34 30 32 26 25 29 22 28 35 24 27 32 17 18 20 35 32 24 32 29 28 27 27 20\n[401] 22 33 30 34 28 32 30 23 34 26 32 22 29 23 35 32 31 27 29 29 33 35 21 24 29\n[426] 30 30 32 28 28 25 28 33 32 20 21 28 35 26  3 21 21 32 31 27 35 32 24 34 32\n[451] 31 36 23 28 35 22 26 29 29 21 31 36 25 27 17 32 32 22 26 30 25 25 34 24 20\n[476] 32 25 21 22 35 20 23 23 29 21 28 35 34 36 15 34 28 24 23 22 32 21 35 26 15\n[501] 32 28 28 25 30 28 20 22 20 18 32 35 30 25 26 21 24 16 30 28 34 35 25 34 27\n[526] 31 27 34 31 27 27 36 30 15 23 26 35 33 34 35 27 31 33 29 21 19 25 30 21 23\n[551] 32 21 25 27 29 20 32 28 32 32 35 18 32 31 20 32 33 34 31 30 34 32 28 34 31\n[576] 29 34 32 31 32 32 27 33 30 27 31 33 31 33 30 32 31 33 35 32 32 33 36 26 34\n[601] 36 31 30 24 34 34 29 30 31 31 26 32 30 28 32 32 25 32 36 25 29 28 32 28 33\n[626] 35 27 32 35 29 26 31 34 26 35 35 28 27 20 31 34 22 35 22 22 35 34 32 31 25\n[651] 32 31 29 32 27 27 34 22 36 36 34 33 34 21 28 29 25 31 29 31 22 23 33 36 30\n[676] 30 36 32 33 28 31 32 34 33 36 30 30 27 33 32 33 25 26 27 26 30 27 31 32 25\n\n\nWie wir sehen, behalten |&gt; und [] die Struktur des Inputs (ein Datenframe) standardmässig bei (ihr Output ist identisch), während $ die Struktur “fallen lässt” und eine simplere Struktur wählt (Vektor statt Datenframe). Entsprechend ist der Output auch anders.\nIm zweiten Beispiel wollen wir die Variablen x und y und die ersten zwei Zeilen aus unserem Dataframe df_beispiel auswählen. Nach dem “tidy” Verfahren wählen wir dafür Datenframe |&gt; select() |&gt; slice(). Nach dem “klassischen” Verfahren wählen wir in [] zuerst die Zeilen, dann die Spalten aus. Die Spalten müssen wir hier als richtigen Vektor eingeben, d.h. mittels c() “x”und “y” (in Anführungszeichen) angeben.\n\ndf_beispiel |&gt; select(SATV, SATQ) |&gt; slice(1:2)\n\n# A tibble: 2 × 2\n   SATV  SATQ\n  &lt;int&gt; &lt;int&gt;\n1   500   500\n2   600   500\n\ndf_beispiel[1:2,c(\"SATV\", \"SATQ\")]\n\n# A tibble: 2 × 2\n   SATV  SATQ\n  &lt;int&gt; &lt;int&gt;\n1   500   500\n2   600   500\n\nc(df_beispiel$SATV[1:2], df_beispiel$SATQ[1:2])\n\n[1] 500 600 500 500\n\n\nListen sind etwas komplizierter. Hier wird analog zu select() pluck() verwendet.\n\nbeispielliste &lt;- list(x1 = vektor_numerisch, x2 = vektor_character, c(6,7,8), x3 = tibble_beispiel, \"test\")\n# tidy\nbeispielliste |&gt; pluck(2)\n\n[1] \"Zytglogge\"      \"Hirschengraben\" \"Bahnhof\"        \"Bundesplatz\"   \n[5] \"Viktoriaplatz\" \n\nbeispielliste |&gt; pluck(\"x2\")\n\n[1] \"Zytglogge\"      \"Hirschengraben\" \"Bahnhof\"        \"Bundesplatz\"   \n[5] \"Viktoriaplatz\" \n\n# [] und [[]]\nbeispielliste[2]\n\n$x2\n[1] \"Zytglogge\"      \"Hirschengraben\" \"Bahnhof\"        \"Bundesplatz\"   \n[5] \"Viktoriaplatz\" \n\nbeispielliste[[2]]\n\n[1] \"Zytglogge\"      \"Hirschengraben\" \"Bahnhof\"        \"Bundesplatz\"   \n[5] \"Viktoriaplatz\" \n\n# $ - geht nur mit benannten Listenelementen\nbeispielliste$x2\n\n[1] \"Zytglogge\"      \"Hirschengraben\" \"Bahnhof\"        \"Bundesplatz\"   \n[5] \"Viktoriaplatz\" \n\n\n\n6.10.1 Auswahl von Spalten / Variablen mittels Helfern\nBeim Data Wrangling bearbeiten wir häufig Gruppen von Variablen / Spalten. Damit wir nicht immer jede einzelne Variable ausschreiben müssen, gibt es verschiedene Methoden. Hilfreich sind vor allem die sogenannten “tidyselect” Helferfunktionen. Diese können wir in select(), aber auch vielen anderen Funktionen verwenden, bei der wir Spalten aus einem Datensatz ansteuern.\nDie häufigsten Helfer sind :, c(), starts_with(), ends_with(), contains(), all_of(), num_range().\n\nnames(df_beispiel)\n\n[1] \"gender\"    \"education\" \"age\"       \"ACT\"       \"SATV\"      \"SATQ\"     \n\ndf_beispiel |&gt; select(age:gender)\n\n# A tibble: 700 × 3\n     age education gender\n   &lt;int&gt;     &lt;int&gt;  &lt;int&gt;\n 1    19         3      2\n 2    23         3      2\n 3    20         3      2\n 4    27         4      1\n 5    33         2      1\n 6    26         5      1\n 7    30         5      2\n 8    19         3      1\n 9    23         4      2\n10    40         5      2\n# ℹ 690 more rows\n\ndf_beispiel |&gt; select(c(age,gender))\n\n# A tibble: 700 × 2\n     age gender\n   &lt;int&gt;  &lt;int&gt;\n 1    19      2\n 2    23      2\n 3    20      2\n 4    27      1\n 5    33      1\n 6    26      1\n 7    30      2\n 8    19      1\n 9    23      2\n10    40      2\n# ℹ 690 more rows\n\ndf_beispiel |&gt; select(starts_with(\"S\"))\n\n# A tibble: 700 × 2\n    SATV  SATQ\n   &lt;int&gt; &lt;int&gt;\n 1   500   500\n 2   600   500\n 3   480   470\n 4   550   520\n 5   600   550\n 6   640   640\n 7   610   500\n 8   520   560\n 9   400   600\n10   730   800\n# ℹ 690 more rows\n\ndf_beispiel |&gt; select(ends_with(\"V\"))\n\n# A tibble: 700 × 1\n    SATV\n   &lt;int&gt;\n 1   500\n 2   600\n 3   480\n 4   550\n 5   600\n 6   640\n 7   610\n 8   520\n 9   400\n10   730\n# ℹ 690 more rows\n\ndf_beispiel |&gt; select(contains(\"SAT\"))\n\n# A tibble: 700 × 2\n    SATV  SATQ\n   &lt;int&gt; &lt;int&gt;\n 1   500   500\n 2   600   500\n 3   480   470\n 4   550   520\n 5   600   550\n 6   640   640\n 7   610   500\n 8   520   560\n 9   400   600\n10   730   800\n# ℹ 690 more rows\n\nmeine_variablen &lt;- c(\"SATV\", \"SATQ\", \"gender\")\ndf_beispiel |&gt; select(all_of(meine_variablen))\n\n# A tibble: 700 × 3\n    SATV  SATQ gender\n   &lt;int&gt; &lt;int&gt;  &lt;int&gt;\n 1   500   500      2\n 2   600   500      2\n 3   480   470      2\n 4   550   520      1\n 5   600   550      1\n 6   640   640      1\n 7   610   500      2\n 8   520   560      1\n 9   400   600      2\n10   730   800      2\n# ℹ 690 more rows\n\n\nWir können auch mit logischen Operatoren arbeiten und diese verketten. Zu logischen Operatoren siehe auch: Einführung in R, Kapitel 2.1.2.\n\ndata(bfi)  \nnames(bfi) #Big Five Items, OCEAN mit je 5 Items sowie gender, education und age\n\n [1] \"A1\"        \"A2\"        \"A3\"        \"A4\"        \"A5\"        \"C1\"       \n [7] \"C2\"        \"C3\"        \"C4\"        \"C5\"        \"E1\"        \"E2\"       \n[13] \"E3\"        \"E4\"        \"E5\"        \"N1\"        \"N2\"        \"N3\"       \n[19] \"N4\"        \"N5\"        \"O1\"        \"O2\"        \"O3\"        \"O4\"       \n[25] \"O5\"        \"gender\"    \"education\" \"age\"      \n\n# bfi von normalen data.frame zu tibble upgraden\nbfi &lt;- as_tibble(bfi)\n\nbfi |&gt; select(starts_with(\"E\")) |&gt; head() # auch education dabei\n\n# A tibble: 6 × 6\n     E1    E2    E3    E4    E5 education\n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;     &lt;int&gt;\n1     3     3     3     4     4        NA\n2     1     1     6     4     3        NA\n3     2     4     4     4     5        NA\n4     5     3     4     4     4        NA\n5     2     2     5     4     5        NA\n6     2     1     6     5     6         3\n\nbfi |&gt; select(starts_with(\"E\") & !all_of(\"education\")) |&gt; head() # nur die Extraversion Items, kein education\n\n# A tibble: 6 × 5\n     E1    E2    E3    E4    E5\n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     3     3     3     4     4\n2     1     1     6     4     3\n3     2     4     4     4     5\n4     5     3     4     4     4\n5     2     2     5     4     5\n6     2     1     6     5     6\n\n# oder eleganter mit num_range()\nbfi |&gt; select(num_range(\"E\", 1:5)) |&gt; head() # nur die Extraversion Items\n\n# A tibble: 6 × 5\n     E1    E2    E3    E4    E5\n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     3     3     3     4     4\n2     1     1     6     4     3\n3     2     4     4     4     5\n4     5     3     4     4     4\n5     2     2     5     4     5\n6     2     1     6     5     6\n\nbfi |&gt; select(starts_with(\"E\"), starts_with(\"C\")) |&gt; head() # \",\" wird als einschliessendes oder (OR) gelesen\n\n# A tibble: 6 × 11\n     E1    E2    E3    E4    E5 education    C1    C2    C3    C4    C5\n  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;     &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;\n1     3     3     3     4     4        NA     2     3     3     4     4\n2     1     1     6     4     3        NA     5     4     4     3     4\n3     2     4     4     4     5        NA     4     5     4     2     5\n4     5     3     4     4     4        NA     4     4     3     5     5\n5     2     2     5     4     5        NA     4     4     5     3     2\n6     2     1     6     5     6         3     6     6     6     1     3",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Anhang: Data Wrangling</span>"
    ]
  },
  {
    "objectID": "00 Data Wrangling Basics.html#spalten-ändern-und-neue-anlegen---mutate",
    "href": "00 Data Wrangling Basics.html#spalten-ändern-und-neue-anlegen---mutate",
    "title": "6  Anhang: Data Wrangling",
    "section": "6.11 Spalten ändern und neue Anlegen - mutate()",
    "text": "6.11 Spalten ändern und neue Anlegen - mutate()\nmutate() wird genutzt, um neue Spalten anzulegen oder die Inhalte bestehender Spalten zu ändern. is used to create new columns or to change the contents of existing ones. Oft verändern wir Variablen bei einer Analyse. Typisch ist etwa die Zentrierung von Variablen auf den Mittelwert der Stichprobe (grand mean; damit bekommen die Variablen einen Mittelwert von 0) oder die z-Standardisierung (Variablen bekommen einen Mittelwert von 0 und eine Standardabweichung von 1).\n\ndf_beispiel &lt;- df_beispiel |&gt; mutate(ACT_c = scale(ACT, center = TRUE, scale = FALSE),\n                                     ACT_z = scale(ACT, center = TRUE, scale = TRUE))\ndf_beispiel\n\n# A tibble: 700 × 8\n   gender education   age   ACT  SATV  SATQ ACT_c[,1] ACT_z[,1]\n    &lt;int&gt;     &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n 1      2         3    19    24   500   500    -4.55     -0.943\n 2      2         3    23    35   600   500     6.45      1.34 \n 3      2         3    20    21   480   470    -7.55     -1.56 \n 4      1         4    27    26   550   520    -2.55     -0.528\n 5      1         2    33    31   600   550     2.45      0.509\n 6      1         5    26    28   640   640    -0.547    -0.113\n 7      2         5    30    36   610   500     7.45      1.55 \n 8      1         3    19    22   520   560    -6.55     -1.36 \n 9      2         4    23    22   400   600    -6.55     -1.36 \n10      2         5    40    35   730   800     6.45      1.34 \n# ℹ 690 more rows",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Anhang: Data Wrangling</span>"
    ]
  },
  {
    "objectID": "00 Data Wrangling Basics.html#zeilen-filtern",
    "href": "00 Data Wrangling Basics.html#zeilen-filtern",
    "title": "6  Anhang: Data Wrangling",
    "section": "6.12 Zeilen filtern",
    "text": "6.12 Zeilen filtern\nNeben der Mutation/Transformation von Spalten ist das Filtern von Zeilen ein typisches Anliegen bei der Datenaufbereitung. Dies geht mittels filter(). Du kannst den logischen Test für das Filtern auf verschiedene Arten angeben, einschließlich Gleichheit (==), Negation (!=) oder Zugehörigkeit (%in%). Es ist oft besser zu definieren, was du möchtest (mithilfe von Gleichheit oder Zugehörigkeit), anstatt zu definieren, was du nicht möchtest (Negation), da Negationen weniger robust gegenüber neuen Daten mit ungewöhnlichen Werten sind, die du beim Schreiben des Codes nicht bedacht hast. Zum Beispiel könntest du gender != 2 angeben, aber das würde non binary nicht erfassen.\n\ndf_beispiel_w &lt;- df_beispiel |&gt; filter(gender == 2)\n\nDu kannst auch mehrere Kriterien in deinem Filteraufruf verwenden, bei denen beide erfüllt sein müssen (x & y) oder bei denen eines von beiden erfüllt sein muss (x | y).\n\ndf_beispiel_w_and_edu &lt;- df_beispiel |&gt; filter(gender == 2 & education &gt; 2)\ndf_beispiel_w_or_edu &lt;- df_beispiel |&gt; filter(gender == 2 | education &gt; 2)\n\n\n# note that these provide different results - make sure you understand why\nidentical(df_beispiel_w_and_edu, df_beispiel_w_or_edu)\n\n[1] FALSE",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Anhang: Data Wrangling</span>"
    ]
  },
  {
    "objectID": "00 Data Wrangling Basics.html#übung-data-wrangling",
    "href": "00 Data Wrangling Basics.html#übung-data-wrangling",
    "title": "6  Anhang: Data Wrangling",
    "section": "6.13 Übung Data Wrangling",
    "text": "6.13 Übung Data Wrangling\n\nWähle zunächst die folgenden Variablen aus: education, SATQ.\nErstelle eine neue Variable, in der die SATQ zentriert wird und nenne sie “SATQ_c”. Transformiere education in einen Faktor (as.factor()).\nWähle alle Personen mit High School-Abschluss (Faktor-Level 1) aus.\n\nFühre zunächst jeden Schritt separat und sequentiell aus. Verknüpfe dann alle Funktionen/Schritte mittels mehrerer Pipes. Das führt dazu, dass weniger Objekte in deiner Umgebung existieren und somit weniger Verwirrung oder Fehlerpotenzial entsteht. Genereller Tipp: Wir lösen Programmierprobleme leichter, indem wir sie in kleinere Aufgaben und Probleme zerlegen, diese jeweils einzeln zum Laufen bringen und sie dann wieder zusammenfügen. Wenn man nur das Endprodukt sieht, könnte man leicht denken, der/die Autor:in hätte den Code genau so geschrieben, wie er aussieht. Dabei hat er/sie oft viel ausführlichere Codeabschnitte geschrieben und diese anschließend zusammengeführt.\n\n# auswählen\n df_auswahl &lt;- df_beispiel\n# neue variable erstellen\ndf_neuevariable &lt;- df_auswahl\n# filtern\ndf_filter &lt;- df_neuevariable \n\n# jetzt alles zusammen\ndf_kombiniert &lt;- df_beispiel \n\n\n\n\n\n\n\nLösung: Übung Data Wrangling\n\n\n\n\n\n\n# auswählen\ndf_auswahl &lt;- df_beispiel |&gt; select(education, SATQ)\n# neue variable erstellen\ndf_neuevariable &lt;- df_auswahl |&gt; mutate(\n  education = as.factor(education),\n  SATQ_c = scale(SATQ, center = TRUE, scale = FALSE))\n# filtern\ndf_filter &lt;- df_neuevariable |&gt; filter(education == 1)\n\n# jetzt alles zusammen\ndf_kombiniert &lt;- df_beispiel |&gt; \n  select(education, SATQ) |&gt; \n  mutate(\n  education = as.factor(education),\n  SATQ_c = scale(SATQ, center = TRUE, scale = FALSE)) |&gt; \n  filter(education == 1)\n\n# identical(df_filter, df_kombiniert) # check",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Anhang: Data Wrangling</span>"
    ]
  },
  {
    "objectID": "00 Data Wrangling Basics.html#zusammenfassung-über-zeilen",
    "href": "00 Data Wrangling Basics.html#zusammenfassung-über-zeilen",
    "title": "6  Anhang: Data Wrangling",
    "section": "6.14 Zusammenfassung über Zeilen",
    "text": "6.14 Zusammenfassung über Zeilen\nEs ist sehr häufig, dass wir Zusammenfassungen über Zeilen hinweg erstellen müssen. Zum Beispiel, um den Mittelwert und die Standardabweichung einer Spalte wie age zu berechnen. Das kann mit summarize() erledigt werden. Denk daran: mutate() erstellt neue Spalten oder ändert den Inhalt bestehender Spalten, ohne die Anzahl der Zeilen zu verändern. summarize() hingegen reduziert einen Datensatz auf eine einzelne Zeile.\n\n# mean\ndf_beispiel |&gt; summarize(mean_age = mean(age, na.rm = TRUE))\n\n# A tibble: 1 × 1\n  mean_age\n     &lt;dbl&gt;\n1     25.6\n\n# SD\ndf_beispiel |&gt; \n  summarize(sd_age = sd(age, na.rm = TRUE))\n\n# A tibble: 1 × 1\n  sd_age\n   &lt;dbl&gt;\n1   9.50\n\n# mean and SD with rounding, illustrating how multiple summarizes can be done in one function call\ndf_beispiel |&gt; \n  summarize(mean_age = mean(age, na.rm = TRUE),\n            mean_age = round(mean_age, digits = 2),\n            sd_age = sd(age, na.rm = TRUE),\n            sd_age = round(sd_age, digits = 2))\n\n# A tibble: 1 × 2\n  mean_age sd_age\n     &lt;dbl&gt;  &lt;dbl&gt;\n1     25.6    9.5\n\n\n\n6.14.1 group_by()\nOft wollen wir einen Datensatz jedoch nicht auf eine einzelne Zeile reduzieren bzw. den gesamten Datensatz zusammenfassen, sondern eine Zusammenfassung für jede (Unter-)Gruppe erstellen. Dies ist hilfreich, insbesondere da wir im Seminar mit Tagen verschachtelt in Personen arbeiten werden.\n\n# illustrate use of group_by() and summarize()\ndf_beispiel |&gt; \n  group_by(education) |&gt; \n  summarize(ACT_c = mean(ACT_z, na.rm = TRUE))\n\n# A tibble: 6 × 2\n  education   ACT_c\n      &lt;int&gt;   &lt;dbl&gt;\n1         0 -0.223 \n2         1 -0.219 \n3         2 -0.325 \n4         3 -0.0524\n5         4  0.148 \n6         5  0.219 \n\n\n\n\n6.14.2 Komplexere Zusammenfassungen\nÄhnlich wie bei mutate() kann auch die Operation für summarize() komplexer sein, z. B. das Finden des Mittelwerts einer logischen Operation (d.h., logische Operatoren nutzend, wie &, &lt;, &gt;, | etc.) , um einen Anteil zu berechnen. Im Folgenden berechnen wir den Anteil von niedrigen SAT Verbal Scores (hier definiert als -1 Standardabweichungen oder niedriger) gruppiert nach Bildung.\n\ndf_beispiel |&gt; \n  mutate(SATV_z = scale(SATV)) |&gt; \n  group_by(education) |&gt;\n  summarize(SATV_unterdurchschnitt = mean(SATV_z &lt; -1, na.rm = TRUE))\n\n# A tibble: 6 × 2\n  education SATV_unterdurchschnitt\n      &lt;int&gt;                  &lt;dbl&gt;\n1         0                 0.193 \n2         1                 0.2   \n3         2                 0.25  \n4         3                 0.135 \n5         4                 0.0942\n6         5                 0.0851\n\n\nMit across() kannst du Zusammenfassungen (oder auch Änderungen mit mutate()) über mehrere Spalten hinweg auf dieselbe Weise durchführen. Wir werden hier nicht alle Möglichkeiten oder Details zu across() behandeln, aber es ist wichtig zu wissen, dass es möglich ist. Zum Beispiel:\n\ndf_beispiel |&gt; \n  # ... calculate the mean of every numeric column in the dataset ...\n  summarise(across(where(is.numeric), mean, na.rm = TRUE)) |&gt; \n  # ... and then round every column to one decimal place\n  mutate(across(everything(), round, digits = 2))\n\nWarning: There was 1 warning in `summarise()`.\nℹ In argument: `across(where(is.numeric), mean, na.rm = TRUE)`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))\n\n\n# A tibble: 1 × 8\n  gender education   age   ACT  SATV  SATQ ACT_c ACT_z\n   &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1   1.65      3.16  25.6  28.6  612.  610.     0     0",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Anhang: Data Wrangling</span>"
    ]
  },
  {
    "objectID": "00 Data Wrangling Basics.html#übung-summarize",
    "href": "00 Data Wrangling Basics.html#übung-summarize",
    "title": "6  Anhang: Data Wrangling",
    "section": "6.15 Übung summarize()",
    "text": "6.15 Übung summarize()\nBerechne min, max, mean, und SD aller Antworten auf dem selbstberichteten SAT Verbal Score (SATV).\n\n# data_selfreport_tidy\n\ndf_beispiel |&gt; \n  summarize()\n\n# A tibble: 1 × 0\n\n\nFür die zweiten Übung arbeiten wir mit dem Datensatz BFI, der Big Five Items beinhaltet (s. Dokumentation des Datensatzes). Berechne, getrennt nach Gender, Mittelwert un SD von C1 (ein Gewissenhaftigkeit-Item).\n\ndata(bfi)\nhead(bfi)\n\n      A1 A2 A3 A4 A5 C1 C2 C3 C4 C5 E1 E2 E3 E4 E5 N1 N2 N3 N4 N5 O1 O2 O3 O4\n61617  2  4  3  4  4  2  3  3  4  4  3  3  3  4  4  3  4  2  2  3  3  6  3  4\n61618  2  4  5  2  5  5  4  4  3  4  1  1  6  4  3  3  3  3  5  5  4  2  4  3\n61620  5  4  5  4  4  4  5  4  2  5  2  4  4  4  5  4  5  4  2  3  4  2  5  5\n61621  4  4  6  5  5  4  4  3  5  5  5  3  4  4  4  2  5  2  4  1  3  3  4  3\n61622  2  3  3  4  5  4  4  5  3  2  2  2  5  4  5  2  3  4  4  3  3  3  4  3\n61623  6  6  5  6  5  6  6  6  1  3  2  1  6  5  6  3  5  2  2  3  4  3  5  6\n      O5 gender education age\n61617  3      1        NA  16\n61618  3      2        NA  18\n61620  2      2        NA  17\n61621  5      2        NA  17\n61622  3      1        NA  17\n61623  1      2         3  21\n\n\n\n\n\n\n\n\nLösung: Übung summarize()\n\n\n\n\n\n\ndf_beispiel |&gt; \n  summarize(min_satv = min(SATV, na.rm = TRUE),\n            max_satv = max(SATV, na.rm = TRUE),\n            mean_satv = mean(SATV, na.rm = TRUE),\n            sd_satv = sd(SATV, na.rm = TRUE))\n\n# A tibble: 1 × 4\n  min_satv max_satv mean_satv sd_satv\n     &lt;int&gt;    &lt;int&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1      200      800      612.    113.\n\nbfi |&gt; group_by(gender) |&gt; \n  summarize(C1_na = sd(C1, na.rm = TRUE),\n            C1_mean = mean(C1, na.rm = TRUE))\n\n# A tibble: 2 × 3\n  gender C1_na C1_mean\n   &lt;int&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1      1  1.24    4.48\n2      2  1.24    4.52",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Anhang: Data Wrangling</span>"
    ]
  },
  {
    "objectID": "00 Data Wrangling Basics.html#kontrolliere-deinen-lernfortschritt",
    "href": "00 Data Wrangling Basics.html#kontrolliere-deinen-lernfortschritt",
    "title": "6  Anhang: Data Wrangling",
    "section": "6.16 Kontrolliere deinen Lernfortschritt",
    "text": "6.16 Kontrolliere deinen Lernfortschritt\nWas ist der Unterschied zwischen mutate() und summarize()? Bekomme ich dasselbe Ergebnis, wenn ich die falsche Funktion verwende? Zum Beispiel: mutate(mean_age = mean(age, na.rm = TRUE)) vs.summarize(mean_age = mean(age, na.rm = TRUE)).",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Anhang: Data Wrangling</span>"
    ]
  },
  {
    "objectID": "00 Data Wrangling Basics.html#daten-auf-festplatte-schreiben",
    "href": "00 Data Wrangling Basics.html#daten-auf-festplatte-schreiben",
    "title": "6  Anhang: Data Wrangling",
    "section": "6.17 Daten auf Festplatte schreiben",
    "text": "6.17 Daten auf Festplatte schreiben\nAm Ende von Data Wrangling Prozessen ist es sinnvoll, die Ergebnisse festzuhalten, damit wir sie nicht verlieren, bzw. beim nächsten Mal nicht alles von vorne ausführen müssen.\n\ndf_beispiel_standardisiert &lt;- df_beispiel |&gt; mutate(across(c(\"SATV\", \"SATQ\", \"ACT\"),\n                                                           scale))\n\nsave(df_beispiel_standardisiert, file =  \"../data/df_beispiel_standardisiert.RData\")",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Anhang: Data Wrangling</span>"
    ]
  }
]