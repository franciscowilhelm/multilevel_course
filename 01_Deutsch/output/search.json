[
  {
    "objectID": "99_techsupport.html",
    "href": "99_techsupport.html",
    "title": "7  Anhang: Tech Support",
    "section": "",
    "text": "7.1 Häufige Probleme",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Anhang: Tech Support</span>"
    ]
  },
  {
    "objectID": "99_techsupport.html#probleme-beim-installieren-oder-laden-von-paketen",
    "href": "99_techsupport.html#probleme-beim-installieren-oder-laden-von-paketen",
    "title": "7  Anhang: Tech Support",
    "section": "7.2 Probleme beim Installieren oder Laden von Paketen",
    "text": "7.2 Probleme beim Installieren oder Laden von Paketen\n\nStellt sicher, dass eure RStudio-Version aktuell ist (Help –&gt; Check for Updates).\nStellt sicher, dass eure R-Version relativ aktuell ist. Welche R-Version ihr aktuell nutzt seht ihr beim Programmstart von RStudio in der Konsole, oder wenn ihr auf Tools –&gt; Global Options –&gt; General –&gt; R Sessions: R Version und dann auf Change… klickt. Dort könnt ihr eine der installierten R-Versionen auswählen. Manchmal benutzt RStudio automatisch eine alte Version, obwohl eine neuere bereits installiert wurde.\n\nVerwendet zum Installieren der Pakete den Code-Absatz aus der Einleitung. Die Pakete Laden Befehle aus den anderen Kapiteln sind nicht immer vollständig.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Anhang: Tech Support</span>"
    ]
  },
  {
    "objectID": "99_techsupport.html#probleme-beim-öffnen-des-r-projekts",
    "href": "99_techsupport.html#probleme-beim-öffnen-des-r-projekts",
    "title": "7  Anhang: Tech Support",
    "section": "7.3 Probleme beim Öffnen des R-Projekts",
    "text": "7.3 Probleme beim Öffnen des R-Projekts\nÖffnet sich das R-Projekt gar nicht, leer, oder meldet Fehler bezüglich der Schreibberechtigung, wurde möglicherweise die Übungs-.zip Datei nicht korrekt entpackt. Stellt sicher, dass ihr die .zip Datei erst entpackt und dann öffnet, anstatt das R-Projekt direkt aus der .zip Datei zu öffnen.\n\n7.3.1 Windows\n\nRechtsklick auf die .zip-Datei\nWähle “Alle extrahieren…”\nWähle den gewünschten Speicherort und klicke auf “Extrahieren”\n\nAlternative: Falls kein „Alle extrahieren…“ erscheint, kannst du die Datei mit Programmen wie 7-Zip entpacken.\n\n\n7.3.2 Mac (macOS)\n\nDoppelklick auf die .zip-Datei\n→ Der Ordner wird automatisch entpackt und erscheint im selben Verzeichnis.\n\nFalls der Doppelklick nicht funktioniert:\n\nRechtsklick → “Öffnen mit” → “Archivierungsprogramm”",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Anhang: Tech Support</span>"
    ]
  },
  {
    "objectID": "04 Hypotheses Tests_Erweiterungen.html",
    "href": "04 Hypotheses Tests_Erweiterungen.html",
    "title": "5  Kapitel 5: Hypothestentests 2 - Moderation und Mediation",
    "section": "",
    "text": "5.1 Cross-Level Interaktion / Moderation\nErwarten wir, dass der Effekt von täglichen Schwankungen in X auf Y abhängig von einer Variable ist, die auf Level-2 gemessen wird (z.B. relativ stabile Persönlichkeitsmerkmale), können wir dies mit einer Cross-Level Interaktion testen.\nhead(df_example1c)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nw\ny\nm\nx\ny_dm\nm_dm\nx_dm\ny_gm\nm_gm\nx_gm\n\n\n\n\n1\n3.847053\n4.064028\n8.492899\n4.136489\n-1.1414789\n1.4106789\n0.803986\n5.205507\n7.08222\n3.332503\n\n\n1\n3.847053\n3.599397\n9.073630\n3.728720\n-1.6061099\n1.9914099\n0.396217\n5.205507\n7.08222\n3.332503\n\n\n1\n3.847053\n7.704277\n4.082619\n2.638451\n2.4987701\n-2.9996011\n-0.694052\n5.205507\n7.08222\n3.332503\n\n\n1\n3.847053\n6.796018\n5.516980\n2.761167\n1.5905111\n-1.5652401\n-0.571336\n5.205507\n7.08222\n3.332503\n\n\n1\n3.847053\n4.723777\n6.875090\n3.152261\n-0.4817299\n-0.2071301\n-0.180242\n5.205507\n7.08222\n3.332503\n\n\n1\n3.847053\n3.592594\n9.817786\n4.168687\n-1.6129129\n2.7355659\n0.836184\n5.205507\n7.08222\n3.332503\nWir zentrieren den Moderator “w” auf dem Grand mean (Gesamtmittelwert) für eine einfachere Interpretation der Modellparameter.\ndf_example1c &lt;- df_example1c |&gt; center(w)\nhead(df_example1c)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nw\ny\nm\nx\ny_dm\nm_dm\nx_dm\ny_gm\nm_gm\nx_gm\nw_c\n\n\n\n\n1\n3.847053\n4.064028\n8.492899\n4.136489\n-1.1414789\n1.4106789\n0.803986\n5.205507\n7.08222\n3.332503\n0.81076\n\n\n1\n3.847053\n3.599397\n9.073630\n3.728720\n-1.6061099\n1.9914099\n0.396217\n5.205507\n7.08222\n3.332503\n0.81076\n\n\n1\n3.847053\n7.704277\n4.082619\n2.638451\n2.4987701\n-2.9996011\n-0.694052\n5.205507\n7.08222\n3.332503\n0.81076\n\n\n1\n3.847053\n6.796018\n5.516980\n2.761167\n1.5905111\n-1.5652401\n-0.571336\n5.205507\n7.08222\n3.332503\n0.81076\n\n\n1\n3.847053\n4.723777\n6.875090\n3.152261\n-0.4817299\n-0.2071301\n-0.180242\n5.205507\n7.08222\n3.332503\n0.81076\n\n\n1\n3.847053\n3.592594\n9.817786\n4.168687\n-1.6129129\n2.7355659\n0.836184\n5.205507\n7.08222\n3.332503\n0.81076\nDie zentrierte Variable heisst “w_c” und wurde am Ende des Datensatz angehängt.\nZunächst berechnen wir das Modell ohne Interaktion von X und W (X*W), aber mit dem Haupteffekt von X und W.\nLevel 1: \\(y_{ij} = \\beta_{0j} + \\beta_{1j}*(X_{ij}-\\bar{X_j}) + \\beta_{2j}*W_{j} + e_{ij}\\)\nLevel 2 (random intercept): \\(\\beta_{0j} = \\gamma_{00} + u_{0j}\\)\nLevel 2 (random slope for x): \\(\\beta_{1j} = \\gamma_{10} + u_{2j}\\)\nri.rs_w_modell &lt;- lmer(y ~ x_dm + w_c + (1 + x_dm | id), data = df_example1c)\nmodel_parameters(ri.rs_w_modell) |&gt; print_html()\n\n\n\n\n\n\n\nModel Summary\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(993)\np\n\n\n\n\nFixed Effects\n\n\n(Intercept)\n5.52\n0.10\n(5.33, 5.70)\n57.83\n&lt; .001\n\n\nx dm\n1.20\n0.11\n(0.98, 1.42)\n10.68\n&lt; .001\n\n\nw c\n0.44\n0.15\n(0.14, 0.74)\n2.91\n0.004\n\n\nRandom Effects\n\n\nSD (Intercept: id)\n0.93\n\n\n\n\n\n\nSD (x_dm: id)\n1.07\n\n\n\n\n\n\nCor (Intercept~x_dm: id)\n0.15\n\n\n\n\n\n\nSD (Residual)\n0.66\nDer Moderator W hat einen positiven Haupteffekt auf die abhängige Variable.\nAls nächstes fügen wir den Interaktionsterm hinzu.\nLevel 1: \\(y_{ij} = \\beta_{0j} + \\beta_{1j}\\cdot(X_{ij}-\\bar{X_j}) + \\beta_{2j}\\cdot W_{j} + e_{ij}\\)\nLevel 2 (random intercept): \\(\\beta_{0j} = \\gamma_{00} + u_{0j}\\)\nLevel 2 (random slope for x): \\(\\beta_{1j} = \\gamma_{10} + \\gamma_{11}*W_{j} + u_{2j}\\)\nri.rs_cli_modell &lt;- lmer(y ~ x_dm + w_c + w_c*x_dm + (1 + x_dm | id), data = df_example1c)\nmodel_parameters(ri.rs_cli_modell) |&gt; print_html()\n\n\n\n\n\n\n\nModel Summary\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(992)\np\n\n\n\n\nFixed Effects\n\n\n(Intercept)\n5.52\n0.10\n(5.33, 5.70)\n57.85\n&lt; .001\n\n\nx dm\n1.20\n0.11\n(0.98, 1.41)\n10.89\n&lt; .001\n\n\nw c\n0.49\n0.15\n(0.19, 0.79)\n3.19\n0.001\n\n\nx dm × w c\n0.39\n0.18\n(0.05, 0.74)\n2.23\n0.026\n\n\nRandom Effects\n\n\nSD (Intercept: id)\n0.93\n\n\n\n\n\n\nSD (x_dm: id)\n1.04\n\n\n\n\n\n\nCor (Intercept~x_dm: id)\n0.14\n\n\n\n\n\n\nSD (Residual)\n0.66\nBeachtet, dass mit der eingebauten Interaktion die Haupteffekte nicht mehr interpretiert werden.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Kapitel 5: Hypothestentests 2 - Moderation und Mediation</span>"
    ]
  },
  {
    "objectID": "04 Hypotheses Tests_Erweiterungen.html#cross-level-interaktion-moderation",
    "href": "04 Hypotheses Tests_Erweiterungen.html#cross-level-interaktion-moderation",
    "title": "5  Kapitel 5: Hypothestentests 2 - Moderation und Mediation",
    "section": "",
    "text": "5.1.1 Visualisierung\nVisualisierung des Interaktionseffekt mittels der plot_model() Funktion. Standardmässig werden die Simple Slopes an den Extremwerten (Minimum, Maximum) des Moderators geschätzt.\nDie Simple-Slope-Analyse in Mehrebenen-Modellen dient dazu, den Moderationseffekt einer Variablen zu untersuchen, indem die Beziehung zwischen Prädiktor (hier: “x”) und abhängiger Variable (hier: “y”) auf verschiedenen Ausprägungsniveaus der Moderatorvariablen (hier: “w_c”) betrachtet wird. Nach der Schätzung des Mehrebenen-Modells werden die Steigungen (Slopes) für unterschiedliche Werte des Moderators berechnet (z. B. ±1 Standardabweichung oder spezifische Werte), um zu analysieren, ob und wie sich der Effekt des Prädiktors je nach Moderator ändert. Diese Methode hilft zu verstehen, ob die Stärke oder Richtung eines Effekts in Abhängigkeit der Moderatorvariable variiert.\n\nplot_model(ri.rs_cli_modell,\n           type = \"int\", # typ interaktion\n           terms = c(\"x_dm\", \"w_c\")) # die terme (variablen) aus denen die Interaktion gebildet wird\n\n\n\n\n\n\n\n\nAlternativ kann man auch die Werte zum Mittelwerte und bei -1 SD und +1 SD des Moderators anzeigen lassen. Wir können den zuletzt erzeugten Plot mittels ggsave() abspeichern.\n\nplot_model(ri.rs_cli_modell, type = \"int\", mdrt.values = \"meansd\")\n\n\n\n\n\n\n\nggsave(\"Plots/CLI_Beispiel.png\")\n\nSaving 7 x 5 in image\n\n\nDer Plot zeigt, dass bei höheren Ausprägungen von w der Effekt von x_dm stärker ausfällt.\n\n\n5.1.2 Simple Slopes Analyse\nMit Hilfe der simple_slopes() Funktion aus dem reghelper Paket können wir uns die Regressionskoeffizienten einer Simple-Slope Analyse unterziehen. Die statistischen Kennwerte dienen als Zusatz zur Visualisierung der Simple Slopes. So können wir z.B. bestimmen, ob der Effekt von X auf Y auf verschiedenen Ausprägungen signifikant ist. Z.B. könnte der Effekt von X auf Y nur bei bestimmten Ausprägungen (hoch oder niedrig) signifikant sein.\nWir können die spezifischen Werte der Variable automatisch bestimmen (1. Variante) oder manuell setzen (2. Variante). Uns interessieren die Werte, wenn x_dm um eine Einheit steigt und der Moderator unterdurchschnittlich (-1 SD), durchschnittlich, oder überdurchschnittlich (+1 SD) ist. Entsprechend werden die Werte in Variante 2 manuell gesetzt. Die Werte können wir der Abbildung oben entnehmen.\n\nsimple_slopes(ri.rs_cli_modell)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx_dm\nw_c\nTest Estimate\nStd. Error\ndf\nt value\nPr(&gt;|t|)\n\n\n\n\n-0.663149\nsstest\n0.2286100\n0.1800277\n96.65133\n1.269861\n0.2071831\n\n\n0\nsstest\n0.4892460\n0.1535760\n97.99976\n3.185694\n0.0019372\n\n\n0.663149\nsstest\n0.7498820\n0.2048973\n97.16437\n3.659794\n0.0004104\n\n\nsstest\n-0.621309\n0.9540629\n0.1553862\n95.45208\n6.139946\n0.0000000\n\n\nsstest\n0\n1.1982546\n0.1099985\n95.83814\n10.893368\n0.0000000\n\n\nsstest\n0.621309\n1.4424463\n0.1547564\n94.09284\n9.320752\n0.0000000\n\n\n\n\n\nsimple_slopes(ri.rs_cli_modell,\n              levels = list(x_dm = c(1,'sstest') ),\n              w_c = c(-0.62,0, 0.62, \"sstest\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx_dm\nw_c\nTest Estimate\nStd. Error\ndf\nt value\nPr(&gt;|t|)\n\n\n\n\n1\nsstest\n0.8822738\n0.2485026\n96.49868\n3.550360\n0.0005966\n\n\nsstest\n-0.621309\n0.9540629\n0.1553862\n95.45208\n6.139946\n0.0000000\n\n\nsstest\n0\n1.1982546\n0.1099985\n95.83814\n10.893368\n0.0000000\n\n\nsstest\n0.621309\n1.4424463\n0.1547564\n94.09284\n9.320752\n0.0000000\n\n\n\n\n\n\nDie Simple Slope Analyse bestätigt die Visualiserung und zeigt, dass der Effekt von x_dm auf y schwächer ausfällt, aber immer noch signifikant positiv ist, wenn der Moderator w_c unterdurchschnittlich ist (Variante 1, Zeile 4; Variante 2, Zeile 2). Der Effekt fällt stärker aus, wenn der Moderator w_c überdurchschnittlich ist (Variante 1, Zeile 6; Variante 2, Zeile 4).\n\n\n5.1.3 Within-level Interaktion\nAnalog zur Cross-level Interaktion gibt es auch Within-level Interaktionen, bei der die Level-1 Anteile von Prädiktorvariablen miteinander interagieren.\nLevel 1: \\(y_{ij} = \\beta_{0j} + \\beta_{1j}\\cdot(X_{ij}-\\bar{X_j}) + \\beta_{2j}\\cdot(W_{ij}-\\bar{W_j}) + \\beta_{3j}\\cdot((W_{ij}-\\bar{W_j})\\cdot(X_{ij}-\\bar{X_j})) + e_{ij}\\)\nLevel 2 (random intercept): \\(\\beta_{0j} = \\gamma_{00} + u_{0j}\\)\nLevel 2 (random slope X): \\(\\beta_{1j} = \\gamma_{10} + u_{1j}\\)\nLevel 2 (random slope M): \\(\\beta_{2j} = \\gamma_{20} + u_{2j}\\)\n\nri.rs_wli_modell &lt;- lmer(y ~ x_dm + m_dm + x_dm*m_dm + (1 + x_dm + m_dm | id), data = df_example1c)\nmodel_parameters(ri.rs_wli_modell) |&gt; print_html()\n\n\n\n\n\n\n\nModel Summary\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(989)\np\n\n\n\n\nFixed Effects\n\n\n(Intercept)\n5.52\n0.10\n(5.32, 5.72)\n54.89\n&lt; .001\n\n\nx dm\n0.17\n0.08\n(9.53e-03, 0.33)\n2.08\n0.038\n\n\nm dm\n0.53\n0.06\n(0.41, 0.66)\n8.46\n&lt; .001\n\n\nx dm × m dm\n-5.19e-03\n0.02\n(-0.04, 0.02)\n-0.34\n0.735\n\n\nRandom Effects\n\n\nSD (Intercept: id)\n0.98\n\n\n\n\n\n\nSD (x_dm: id)\n0.47\n\n\n\n\n\n\nSD (m_dm: id)\n0.53\n\n\n\n\n\n\nCor (Intercept~x_dm: id)\n-0.08\n\n\n\n\n\n\nCor (Intercept~m_dm: id)\n0.04\n\n\n\n\n\n\nCor (x_dm~m_dm: id)\n-0.26\n\n\n\n\n\n\nSD (Residual)\n0.52\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplot_model(ri.rs_wli_modell, type = \"int\", mdrt.values = \"meansd\")\n\n\n\n\n\n\n\n\nDer Interaktionseffekt ist nicht signifikant. Dies bedeutet, wie der Plot zeigt, dass die Linien bei allen Ausprägungen des Moderators mehr oder wenig parallel sind.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Kapitel 5: Hypothestentests 2 - Moderation und Mediation</span>"
    ]
  },
  {
    "objectID": "04 Hypotheses Tests_Erweiterungen.html#übung",
    "href": "04 Hypotheses Tests_Erweiterungen.html#übung",
    "title": "5  Kapitel 5: Hypothestentests 2 - Moderation und Mediation",
    "section": "5.2 Übung",
    "text": "5.2 Übung\nWir arbeiten in der Übung mit dem Übungs-Datensatz aus Kapitel 4.\n\nload(\"../data/df_example_cli.RData\")\n\nhead(df_example_cli)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nilltask\nnegativ\nsupport\nilltask_dm\nnegativ_dm\nilltask_gm\nnegativ_gm\nnegativ_dm_l1\nday\n\n\n\n\n1\n1.188858\n1.825857\n3.454777\n-1.2994333\n-0.0153842\n2.488291\n1.841241\nNA\n1\n\n\n1\n1.719163\n1.633681\n3.454777\n-0.7691283\n-0.2075602\n2.488291\n1.841241\nNA\n4\n\n\n1\n3.149280\n1.250429\n3.454777\n0.6609887\n-0.5908122\n2.488291\n1.841241\nNA\n7\n\n\n1\n2.372508\n1.583838\n3.454777\n-0.1157833\n-0.2574032\n2.488291\n1.841241\n-0.5908122\n8\n\n\n1\n2.558448\n2.912401\n3.454777\n0.0701567\n1.0711598\n2.488291\n1.841241\n-0.2574032\n9\n\n\n2\n1.336438\n2.111289\n2.109855\n0.2807496\n-0.4911521\n1.055688\n2.602441\nNA\n1\n\n\n\n\n\nget_label(df_example_cli)\n\n                                         id \n                              \"Personen-ID\" \n                                    illtask \n                 \"Daily Illegitimate Tasks\" \n                                    negativ \n                    \"Daily Negative Affect\" \n                                    support \n                         \"Coworker support\" \n                                 illtask_dm \n\"Illegitimate Tasks (person-mean centered)\" \n                                 negativ_dm \n       \"Neg. Affect (person-mean centered)\" \n                                 illtask_gm \n      \"Illegitimate Tasks (person average)\" \n                                 negativ_gm \n             \"Neg. Affect (person average)\" \n                              negativ_dm_l1 \n                 \"Previous-day Neg. Affect\" \n                                        day \n                               \"Tag (1-10)\" \n\n# alternativ\nview_df(df_example_cli)\n\n\nData frame: df_example_cli\n\n\nID\nName\nLabel\nValues\nValue Labels\n\n\n1\nid\nPersonen-ID\nrange: 1-100\n\n\n2\nilltask\nDaily Illegitimate Tasks\nrange: -1.9-5.6\n\n\n3\nnegativ\nDaily Negative Affect\nrange: -0.2-7.7\n\n\n4\nsupport\nCoworker support\nrange: 1.4-4.5\n\n\n5\nilltask_dm\nIllegitimate Tasks (person-mean centered)\nrange: -2.1-2.3\n\n\n6\nnegativ_dm\nNeg. Affect (person-mean centered)\nrange: -2.0-2.7\n\n\n7\nilltask_gm\nIllegitimate Tasks (person average)\nrange: -0.7-4.7\n\n\n8\nnegativ_gm\nNeg. Affect (person average)\nrange: 0.8-5.0\n\n\n9\nnegativ_dm_l1\nPrevious-day Neg. Affect\nrange: -2.0-2.7\n\n\n10\nday\nTag (1-10)\nrange: 1-10\n\n\n\n\n\nBerechne Modelle mit denen du die folgenden Hypothesen testest:\nH1: Illegitime Aufgaben hängen positiv mit negativem Affekt zusammen. H2: Der positive Zusammenhang von illegitime Aufgaben mit negativem Affekt fällt schwächer aus, wenn Unterstützung von Kolleg:innen hoch ausgeprägt ist.\nGehe Schritt für Schritt vor und teste erst in einem Modell H1 (verwende dazu den Random Intercept, Random Slope Modell-Code aus dem letzten Kapitel), dann in einem anderen Modell H2. Urteile, ob die Hypothesen angenommen oder verworfen werden sollten.\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nri.rs_modell &lt;- lmer(negativ ~ illtask_dm  + support + (1 + illtask_dm | id), data = df_example_cli)\nparameters(ri.rs_modell)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\nCI\nCI_low\nCI_high\nt\ndf_error\np\nEffects\nGroup\n\n\n\n\n(Intercept)\n3.4515583\n0.3038234\n0.95\n2.8551451\n4.0479715\n11.360409\n776\n0.0000000\nfixed\n\n\n\nilltask_dm\n0.3256395\n0.0513930\n0.95\n0.2247537\n0.4265253\n6.336261\n776\n0.0000000\nfixed\n\n\n\nsupport\n-0.2468958\n0.1012860\n0.95\n-0.4457228\n-0.0480687\n-2.437610\n776\n0.0150083\nfixed\n\n\n\nSD (Intercept)\n0.6661075\nNA\n0.95\nNA\nNA\nNA\nNA\nNA\nrandom\nid\n\n\nSD (illtask_dm)\n0.3534636\nNA\n0.95\nNA\nNA\nNA\nNA\nNA\nrandom\nid\n\n\nCor (Intercept~illtask_dm)\n0.6940618\nNA\n0.95\nNA\nNA\nNA\nNA\nNA\nrandom\nid\n\n\nSD (Observations)\n0.6775572\nNA\n0.95\nNA\nNA\nNA\nNA\nNA\nrandom\nResidual\n\n\n\n\n\n\nDer Zusammenhang von täglichen illegitimen Aufgaben (illtask_dm) mit negativem Affekt (negativ) ist signifikant (b = 0.33, p &lt; .001), was Hypothese 1 unterstützt.\n\nri.rs_cli_modell &lt;- lmer(negativ ~ illtask_dm  + support*illtask_dm + (1 + illtask_dm | id), data = df_example_cli)\nparameters(ri.rs_cli_modell)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nCoefficient\nSE\nCI\nCI_low\nCI_high\nt\ndf_error\np\nEffects\nGroup\n\n\n\n\n(Intercept)\n3.4723696\n0.3361052\n0.95\n2.8125852\n4.1321541\n10.3311992\n775\n0.0000000\nfixed\n\n\n\nilltask_dm\n0.3598764\n0.2459646\n0.95\n-0.1229594\n0.8427122\n1.4631228\n775\n0.1438392\nfixed\n\n\n\nsupport\n-0.2540133\n0.1126112\n0.95\n-0.4750724\n-0.0329541\n-2.2556656\n775\n0.0243697\nfixed\n\n\n\nilltask_dm:support\n-0.0116576\n0.0823355\n0.95\n-0.1732847\n0.1499694\n-0.1415871\n775\n0.8874429\nfixed\n\n\n\nSD (Intercept)\n0.6668935\nNA\n0.95\nNA\nNA\nNA\nNA\nNA\nrandom\nid\n\n\nSD (illtask_dm)\n0.3567497\nNA\n0.95\nNA\nNA\nNA\nNA\nNA\nrandom\nid\n\n\nCor (Intercept~illtask_dm)\n0.6950819\nNA\n0.95\nNA\nNA\nNA\nNA\nNA\nrandom\nid\n\n\nSD (Observations)\n0.6776777\nNA\n0.95\nNA\nNA\nNA\nNA\nNA\nrandom\nResidual\n\n\n\n\n\n\nDer Interaktionseffekt von täglichen illegitimen Aufgaben mit sozialer Unterstützung durch Kolleg:innen auf negativen Affekt ist nicht signifikant (b = -0.01, p = .89). Hypothese 2 muss somit verworfen werden.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Kapitel 5: Hypothestentests 2 - Moderation und Mediation</span>"
    ]
  },
  {
    "objectID": "04 Hypotheses Tests_Erweiterungen.html#mediation",
    "href": "04 Hypotheses Tests_Erweiterungen.html#mediation",
    "title": "5  Kapitel 5: Hypothestentests 2 - Moderation und Mediation",
    "section": "5.3 1-1-1 Mediation",
    "text": "5.3 1-1-1 Mediation\nDie 1-1-1 Mediation ist die gängigste Variante, in der alle Variablen (X, M[ediator], und Y) auf Tagesebene gemessen werden.\n\n5.3.1 Daten einlesen\n\nload(\"../data/df_example1.RData\")\nhead(df_example1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\ny\nm\nx\ny_dm\nm_dm\nx_dm\ny_gm\nm_gm\nx_gm\n\n\n\n\n1\n4.003538\n4.769391\n2.365486\n-0.3020232\n0.8945291\n0.6845636\n4.305561\n3.874862\n1.680922\n\n\n1\n4.925174\n2.510943\n0.748855\n0.6196128\n-1.3639189\n-0.9320674\n4.305561\n3.874862\n1.680922\n\n\n1\n4.598564\n3.098112\n1.395041\n0.2930028\n-0.7767499\n-0.2858814\n4.305561\n3.874862\n1.680922\n\n\n1\n4.286179\n4.610746\n1.860026\n-0.0193822\n0.7358841\n0.1791036\n4.305561\n3.874862\n1.680922\n\n\n1\n4.183494\n4.549044\n2.288019\n-0.1220672\n0.6741821\n0.6070966\n4.305561\n3.874862\n1.680922\n\n\n1\n3.631716\n3.590049\n1.696510\n-0.6738452\n-0.2848129\n0.0155876\n4.305561\n3.874862\n1.680922\n\n\n\n\n\n\nZum Testen des Mediationsmodells verwenden wir zunächst die Funktion modmed.mlm(). Im Folgenden erstellen wir mit dieser Funktion ein Mediationsmodell und spezifizieren bei den Argumenten X, Y, und M die die unabhängige, abhängige, und mediierende Variable. Für die abhängige Variable Y wählen wir die Rohvariable, für unabhängige und mediierende Variablen die personen-zentrierten Variablen.\nAnders als bei den früheren Analysen steht uns das parameters Paket hier nicht zur Verfügung um die Ergebnisse zusammenzufassen. Stattdessen nehmen wir die summary() Funktion oder die tidy()-Funktion aus dem broom Paket.\n\nfit_mediation &lt;- modmed.mlm(\n  df_example1,\n  L2ID = \"id\",\n  X = \"x_dm\",\n  Y = \"y\",\n  M = \"m_dm\",\n  random.int.m = FALSE,\n  na.action = na.omit\n)\n\n#summary(fit_mediation$model)\nbroom::tidy(fit_mediation$model) |&gt;\n  mutate(across(where(is.numeric), round, 2)) # rundung der werte\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `across(where(is.numeric), round, 2)`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\neffect\ngroup\nterm\nestimate\nstd.error\ndf\nstatistic\np.value\n\n\n\n\nfixed\nNA\nSm\n0.00\n0.02\n1896\n0.00\n1\n\n\nfixed\nNA\nSy\n5.37\n0.09\n1896\n61.50\n0\n\n\nfixed\nNA\nSmX\n0.51\n0.03\n1896\n17.81\n0\n\n\nfixed\nNA\nSyX\n0.14\n0.04\n1896\n3.63\n0\n\n\nfixed\nNA\nSyM\n0.58\n0.04\n1896\n15.96\n0\n\n\nran_pars\nL2id\nsd_Sy\n0.84\nNA\nNA\nNA\nNA\n\n\nran_pars\nResidual\nsd_Observation\n0.70\nNA\nNA\nNA\nNA\n\n\nvar_model\nvarIdent(1 | Sm)\n0\n1.00\nNA\nNA\nNA\nNA\n\n\nvar_model\nvarIdent(1 | Sm)\n1\n0.87\nNA\nNA\nNA\nNA\n\n\n\n\n\n\nDie ausgegebenen Zeilen/Parameter sind etwas kryptisch beschrieben.\n\nSm - fixed Intercept von M\nSy - fixed Intercept von Y\nSmX - fixed Slope von X auf M (a-Pfad)\nSyX - fixed Slope von Y auf X (c’-Pfad)\nSyM - fixed Slope von Y auf M (b-Pfad)\n\n\n\n5.3.2 Bootstrapped Version\nDer indirekte Effekt von X auf Y via M (a-Pfad * b-Pfad) der uns in der Mediation von zentralem Interesse ist, ist in der Regel nicht normalverteilt, da ein Produkt zweier (oder mehrerer) Pfadkoeffizienten nicht wie die Pfadkoeffizienten selber approximativ normalverteilt ist. Aufgrund der fehlenden Normalverteilung verwenden wir die Bootstrap-Schätzung, um eine robustere Aussage über die Signifikanz des indirekten Effekts zu bekommen.\n\nboot.custom.results &lt;- boot.modmed.mlm.custom(\n  data = df_example1 |&gt; as.data.frame(),\n  L2ID = \"id\",\n  X = \"x_dm\",\n  Y = \"y\",\n  M = \"m_dm\",\n  random.int.m = FALSE,\n  control = list(opt = \"nlm\"),\n  na.action = na.omit,\n  return.type = \"all\",\n  nrep = 1000,\n  parallel.type = \"parallel\",\n  ncores = 4,\n  seed = 2299)\n\n\nbroom::tidy(boot.custom.results$model) |&gt;\n  mutate(across(where(is.numeric), round, 2)) # rundung der werte\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\neffect\ngroup\nterm\nestimate\nstd.error\ndf\nstatistic\np.value\n\n\n\n\nfixed\nNA\nSm\n0.00\n0.02\n1896\n0.00\n1\n\n\nfixed\nNA\nSy\n5.37\n0.09\n1896\n61.50\n0\n\n\nfixed\nNA\nSmX\n0.51\n0.03\n1896\n17.81\n0\n\n\nfixed\nNA\nSyX\n0.14\n0.04\n1896\n3.63\n0\n\n\nfixed\nNA\nSyM\n0.58\n0.04\n1896\n15.96\n0\n\n\nran_pars\nL2id\nsd_Sy\n0.84\nNA\nNA\nNA\nNA\n\n\nran_pars\nResidual\nsd_Observation\n0.70\nNA\nNA\nNA\nNA\n\n\nvar_model\nvarIdent(1 | Sm)\n0\n1.00\nNA\nNA\nNA\nNA\n\n\nvar_model\nvarIdent(1 | Sm)\n1\n0.87\nNA\nNA\nNA\nNA\n\n\n\n\n\n\nNach der Schätzung des Modells müssen wir das 95% Konfidenzintervall des indirekten Effekts aus den Modellergebnissen extrahieren. Dazu gibt es derzeit keine einfache Funktion, entsprechend fällt der folgende Code-Chunk komplexer aus.\n\n# Punktwert des indirekten Effekt\nindirect_punktschaetzung &lt;- extract.modmed.mlm(boot.custom.results, type=\"indirect\")\n\n# Bootstrapped 95% Konfidenzintervall um den Punktwert herum\nindirect_boot &lt;- tibble(SyM = boot.custom.results[[\"t\"]][,which(names(boot.custom.results[[\"t0\"]]) == \"SyM\")], \n                        SmX = boot.custom.results[[\"t\"]][,which(names(boot.custom.results[[\"t0\"]]) == \"SmX\")]) |&gt; \n  mutate(indirect = SyM * SmX)\nindirekt_ci &lt;- quantile(indirect_boot$indirect, c(0.025, 0.975), na.rm = TRUE)\n\n# zusammenfassen\nindirekt_zusammenfassung &lt;-\n  tibble(Koeffizient = indirect_punktschaetzung,\n         LLCI = indirekt_ci[1],\n         ULCI = indirekt_ci[2]) |&gt; \n  mutate(across(where(is.numeric), round, 3))\nindirekt_zusammenfassung\n\n\n\n\n\nKoeffizient\nLLCI\nULCI\n\n\n\n\n0.3\n0.198\n0.411\n\n\n\n\n\n\n\nLLCI = Lower Limit of Confidence Interval\nULCI = Upper Limit of Confidence Interval\n\nDer indirekte Effekt und sein 95% Konfidenzintervall müssen wir aus den Daten extrahieren. Wenn der 95% Konfidenzintervall die 0 ausschliesst (also sowohl unterer als auch oberes Limit entweder unter Null oder über Null liegen) können wir den indirekten Effekt als signifikant ansehen.\nIn diesem Beispiel finden wir also einen signifikanten indirekten Effekt mit Koeffizient = 0.30, 95% CI = [0.19, 0.41].",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Kapitel 5: Hypothestentests 2 - Moderation und Mediation</span>"
    ]
  },
  {
    "objectID": "04 Hypotheses Tests_Erweiterungen.html#übung-1",
    "href": "04 Hypotheses Tests_Erweiterungen.html#übung-1",
    "title": "5  Kapitel 5: Hypothestentests 2 - Moderation und Mediation",
    "section": "5.4 Übung",
    "text": "5.4 Übung\nWir arbeiten in der Übung mit einem neuen Datensatz.\nMache dich mit ihm vertraut. Wie in der Cross-Level Interaktionsübung benutzen wir einen Datensatz in dem die Variablen “labelled” sind, also Beschriftungen haben. Wir können die Labels mit get_label() abrufen.\n\nload(\"../data/df_111_uebung.RData\")\n\nhead(df_111_uebung)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nhelfen\nwertschaetz\nselbstwert\nwertschaetz_dm\nselbstwert_dm\nwertschaetz_gm\nselbstwert_gm\n\n\n\n\n1\n4.714438\n1.371902\n4.441296\n-0.0437649\n-0.7058638\n1.415667\n5.14716\n\n\n1\n3.622743\n0.574266\n5.981966\n-0.8414009\n0.8348062\n1.415667\n5.14716\n\n\n1\n5.337310\n1.472314\n5.407452\n0.0566471\n0.2602922\n1.415667\n5.14716\n\n\n1\n4.938451\n2.790352\n5.428928\n1.3746851\n0.2817682\n1.415667\n5.14716\n\n\n1\n3.742165\n1.204333\n5.369987\n-0.2113339\n0.2228272\n1.415667\n5.14716\n\n\n1\n4.607774\n1.744993\n4.644467\n0.3293261\n-0.5026928\n1.415667\n5.14716\n\n\n\n\n\nget_label(df_111_uebung)\n\n                                               id \n                                    \"Personen-ID\" \n                                           helfen \n                              \"Proaktives Helfen\" \n                                      wertschaetz \n                       \"erfahrene Wertschaetzung\" \n                                       selbstwert \n                                     \"Selbstwert\" \n                                   wertschaetz_dm \n\"erfahrene Wertschaetzung (person-mean centered)\" \n                                    selbstwert_dm \n              \"Selbstwert (person-mean centered)\" \n                                   wertschaetz_gm \n      \"erfahrene Wertschaetzung (person average)\" \n                                    selbstwert_gm \n                    \"Selbstwert (person average)\" \n\n# alternativ\nview_df(df_111_uebung)\n\n\nData frame: df_111_uebung\n\n\n\n\n\n\n\n\n\nID\nName\nLabel\nValues\nValue Labels\n\n\n1\nid\nPersonen-ID\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n&lt;... truncated&gt;\n\n\n2\nhelfen\nProaktives Helfen\nrange: 0.1-9.1\n\n\n3\nwertschaetz\nerfahrene Wertschaetzung\nrange: -2.4-5.5\n\n\n4\nselbstwert\nSelbstwert\nrange: 0.9-8.0\n\n\n5\nwertschaetz_dm\nerfahrene Wertschaetzung (person-mean centered)\nrange: -2.0-2.4\n\n\n6\nselbstwert_dm\nSelbstwert (person-mean centered)\nrange: -2.7-2.5\n\n\n7\nwertschaetz_gm\nerfahrene Wertschaetzung (person average)\nrange: -1.0-4.6\n\n\n8\nselbstwert_gm\nSelbstwert (person average)\nrange: 2.7-6.4\n\n\n\n\n\nBerechne Modelle mit denen du die folgenden Hypothesen testest:\nH1: Tägliche Wertschätzung durch Vorgesetzte und Kolleg:innen hängen positiv mit dem täglichen Selbstwert zusammen. H2: Täglicher Selbstwert hängt positiv mit täglichem proaktivem Helfen zusammen. H3: Es gibt einen positiven indirekten Zusammenhang zwischen täglicher Wertschätzung und täglichem proaktiven Helfen, vermittel durch den täglichen Selbstwert.\nTeste die Hypothesen in einem Modell mittels der boot.modmed.mlm.custom() Funktion. Urteile, ob die Hypothesen angenommen oder verworfen werden sollten.\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n# | cache: true\nboot.custom.results &lt;- boot.modmed.mlm.custom(\n  data = df_111_uebung |&gt; remove_all_labels(),\n  L2ID = \"id\",\n  X = \"wertschaetz_dm\",\n  Y = \"helfen\",\n  M = \"selbstwert_dm\",\n  random.int.m = FALSE,\n  control = list(opt = \"nlm\"),\n  na.action = na.omit,\n  return.type = \"all\",\n  nrep = 1000,\n  parallel.type = \"parallel\",\n  ncores = 4,\n  seed = 2299)\n\n\nbroom::tidy(boot.custom.results$model) |&gt;\n  mutate(across(where(is.numeric), round, 2)) # rundung der werte\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\neffect\ngroup\nterm\nestimate\nstd.error\ndf\nstatistic\np.value\n\n\n\n\nfixed\nNA\nSm\n0.00\n0.02\n1896\n0.00\n1\n\n\nfixed\nNA\nSy\n4.76\n0.10\n1896\n49.39\n0\n\n\nfixed\nNA\nSmX\n0.40\n0.03\n1896\n13.81\n0\n\n\nfixed\nNA\nSyX\n0.33\n0.04\n1896\n8.93\n0\n\n\nfixed\nNA\nSyM\n0.14\n0.04\n1896\n3.84\n0\n\n\nran_pars\nL2id\nsd_Sy\n0.94\nNA\nNA\nNA\nNA\n\n\nran_pars\nResidual\nsd_Observation\n0.74\nNA\nNA\nNA\nNA\n\n\nvar_model\nvarIdent(1 | Sm)\n0\n1.00\nNA\nNA\nNA\nNA\n\n\nvar_model\nvarIdent(1 | Sm)\n1\n0.85\nNA\nNA\nNA\nNA\n\n\n\n\n\n\n\n# Punktwert des indirekten Effekt\nindirect_punktschaetzung &lt;- extract.modmed.mlm(boot.custom.results, type=\"indirect\")\n\n# Bootstrapped 95% Konfidenzintervall um den Punktwert herum\nindirect_boot &lt;- tibble(SyM = boot.custom.results[[\"t\"]][,which(names(boot.custom.results[[\"t0\"]]) == \"SyM\")], \n                        SmX = boot.custom.results[[\"t\"]][,which(names(boot.custom.results[[\"t0\"]]) == \"SmX\")]) |&gt; \n  mutate(indirect = SyM * SmX)\nindirekt_ci &lt;- quantile(indirect_boot$indirect, c(0.025, 0.975), na.rm = TRUE)\n\n# zusammenfassen\nindirekt_zusammenfassung &lt;-\n  tibble(Koeffizient = indirect_punktschaetzung,\n         LLCI = indirekt_ci[1],\n         ULCI = indirekt_ci[2]) |&gt; \n  mutate(across(where(is.numeric), round, 3))\nindirekt_zusammenfassung\n\n\n\n\n\nKoeffizient\nLLCI\nULCI\n\n\n\n\n0.057\n-0.005\n0.138\n\n\n\n\n\n\nH1 wird unterstützt (SmX: b = 0.40, p &lt; .001). H2 wird verworfen (SyM: b = 0.14, p &lt; .40). H3: wird entsprechend auch verworfen (95% CI des indirekten Effekt schliesst die 0 ein). Es besteht aber ein direkter Zusammenhang zwischen X und Y (SyX: b = 0.33, p &lt; .001), der, anders als angenommen, nicht indirekt über Selbstwert vermittelt wird.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Kapitel 5: Hypothestentests 2 - Moderation und Mediation</span>"
    ]
  },
  {
    "objectID": "03 Hypotheses Tests.html",
    "href": "03 Hypotheses Tests.html",
    "title": "4  Kapitel 4: Hypothesentests - Teil 1",
    "section": "",
    "text": "4.1 Vorbereitung\nIn diesem Kapitel verwenden wir verschiedene Regressionsmodelle die zur Überprüfung von Hypothesen eingesetzt werden.\nInstall packages\nif (!require(\"pacman\")) install.packages(\"pacman\")\n\nLade nötiges Paket: pacman\n\npacman::p_load(lmerTest, haven, brms, psych,\n               sjmisc, sjPlot, sjlabelled, writexl, broom.mixed, qgraph,\n               tidyverse, multilevelTools, parameters)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Kapitel 4: Hypothesentests - Teil 1</span>"
    ]
  },
  {
    "objectID": "03 Hypotheses Tests.html#daten-einlesen",
    "href": "03 Hypotheses Tests.html#daten-einlesen",
    "title": "4  Kapitel 4: Hypothesentests - Teil 1",
    "section": "4.2 Daten einlesen",
    "text": "4.2 Daten einlesen\n\nload(\"../data/df_example1.RData\")\nload(\"../data/df_example1c.RData\")\n\nFür diese Einheit verwenden wir den folgenden Datensatz (data.frame/tibble):\n\ndf_example1: Alle Skalenscores im Long Format, mit personen-zentrierten Variablenvarianten (“_dm”) und Personen-Mittelwerten der täglich gemessenenen Variablen (“_gm”). Struktur des Datensatzes kann man sich ansehen mit head() oder print().\n\n\nhead(df_example1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\ny\nm\nx\ny_dm\nm_dm\nx_dm\ny_gm\nm_gm\nx_gm\n\n\n\n\n1\n4.003538\n4.769391\n2.365486\n-0.3020232\n0.8945291\n0.6845636\n4.305561\n3.874862\n1.680922\n\n\n1\n4.925174\n2.510943\n0.748855\n0.6196128\n-1.3639189\n-0.9320674\n4.305561\n3.874862\n1.680922\n\n\n1\n4.598564\n3.098112\n1.395041\n0.2930028\n-0.7767499\n-0.2858814\n4.305561\n3.874862\n1.680922\n\n\n1\n4.286179\n4.610746\n1.860026\n-0.0193822\n0.7358841\n0.1791036\n4.305561\n3.874862\n1.680922\n\n\n1\n4.183494\n4.549044\n2.288019\n-0.1220672\n0.6741821\n0.6070966\n4.305561\n3.874862\n1.680922\n\n\n1\n3.631716\n3.590049\n1.696510\n-0.6738452\n-0.2848129\n0.0155876\n4.305561\n3.874862\n1.680922\n\n\n\n\n\n\nIm Folgenden betrachten wir ein Modell in dem y durch x vorhergesagt wird.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Kapitel 4: Hypothesentests - Teil 1</span>"
    ]
  },
  {
    "objectID": "03 Hypotheses Tests.html#random-intercept-modell-null-model",
    "href": "03 Hypotheses Tests.html#random-intercept-modell-null-model",
    "title": "4  Kapitel 4: Hypothesentests - Teil 1",
    "section": "4.3 Random Intercept Modell / Null-Model",
    "text": "4.3 Random Intercept Modell / Null-Model\nDie Funktion lmer() benötigt zwei Argumente, (a) die Formel und (b) den Datensatz. Zum Aufbau und Details der Formeln s. Folien.\nLevel 1: \\(y_{ij} = \\beta_{0j} + e_{ij}\\)\nLevel 2 (random intercept): \\(\\beta_{0j} = \\gamma_{00} + u_{0j}\\)\n\nnullmodel &lt;- lmer(y ~ (1 | id), data = df_example1)\n\nZur Ansicht der Ergebnisse haben wir zwei Optionen: Den summary() Befehl - die Standardansicht, wie von den Paketautoren implementiert, den tidy() Befehl aus dem broom-Package, und den model_parameters() Befehl aus dem parameters Package. tidy() und model_parameters() Funktionsoutputs könnten nach Excel/Word exportiert werden mittels der write_xlsx() Funktion, oder indem das Notebook als .docx “gerendert” (ausgegeben) wird.\n\nsummary(nullmodel)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: y ~ (1 | id)\n   Data: df_example1\n\nREML criterion at convergence: 2742.9\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-6.1492 -0.5420 -0.0369  0.5543  4.6493 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 0.6902   0.8308  \n Residual             0.7164   0.8464  \nNumber of obs: 1000, groups:  id, 100\n\nFixed effects:\n            Estimate Std. Error       df t value Pr(&gt;|t|)    \n(Intercept)  5.36755    0.08728 99.00000    61.5   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\ntidy(nullmodel)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\neffect\ngroup\nterm\nestimate\nstd.error\nstatistic\ndf\np.value\n\n\n\n\nfixed\nNA\n(Intercept)\n5.3675530\n0.0872832\n61.49586\n99\n0\n\n\nran_pars\nid\nsd__(Intercept)\n0.8307776\nNA\nNA\nNA\nNA\n\n\nran_pars\nResidual\nsd__Observation\n0.8464254\nNA\nNA\nNA\nNA\n\n\n\n\n\n\n\nmodel_parameters(nullmodel) |&gt; print_html()\n\n\n\n\n\n\n\nModel Summary\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(997)\np\n\n\n\n\nFixed Effects\n\n\n(Intercept)\n5.37\n0.09\n(5.20, 5.54)\n61.50\n&lt; .001\n\n\nRandom Effects\n\n\nSD (Intercept: id)\n0.83\n\n\n\n\n\n\nSD (Residual)\n0.85\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIm Seminar verwenden wir den Output von model_parameters(), weil er eine recht gut formatierte Übersicht gibt.\n\n4.3.1 ICC\nAus dem Null-Model wird der ICC bestimmt. Dies haben wir in der vorhergehenden\nICC: \\(\\frac{\\tau_{00}}{\\tau_{00}+\\tau_{ij}}\\), \\(\\tau\\) gibt die Varianz des jewiligen Koeffizienten an.\nWir können dies aus dem Modelloutput nehmen und berechnen:\n\nmodelsummary &lt;- model_parameters(nullmodel)\ntau00 &lt;- modelsummary$Coefficient[modelsummary$Parameter == \"SD (Intercept)\"]^2\ntauij &lt;- modelsummary$Coefficient[modelsummary$Parameter == \"SD (Observations)\"]^2\ntau00 / (tau00+tauij)\n\n[1] 0.4906711\n\n# performance::icc(nullmodel) # Alternativfunktion\n\n\n\n4.3.2 Visualisierung\nWir können uns die Analysen visualisieren, hier zur reduzierten visuellen Komplexität nur auf Basis der ersten 20 Personen (ID 1-20.)\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nOder zwei Personen, um uns die einzelnen Punkte auch anschauen zu können:\n\nggplot(data = df_example1 |&gt; filter(id %in% c(1, 16)), aes(\n  x = x,\n  y = predicted_ri,\n  colour = id\n)) +\n  geom_smooth(method = \"lm\", fullrange = TRUE, se = F, size = 1) +\n  geom_jitter(aes(y = y), alpha = .5, size = 2.5) +\n  labs(x = xlabel, y = ylabel) +\n  ggtitle(\"Intercept-Only-Modell\") +\n  scale_colour_discrete() +\n  geom_abline(intercept = fixef(nullmodel), slope = 0, size = 1.5) +\n  ggthemes::theme_tufte()\n\n`geom_smooth()` using formula = 'y ~ x'",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Kapitel 4: Hypothesentests - Teil 1</span>"
    ]
  },
  {
    "objectID": "03 Hypotheses Tests.html#random-intercept-fixed-slope-modell",
    "href": "03 Hypotheses Tests.html#random-intercept-fixed-slope-modell",
    "title": "4  Kapitel 4: Hypothesentests - Teil 1",
    "section": "4.4 Random Intercept, fixed slope Modell",
    "text": "4.4 Random Intercept, fixed slope Modell\nAls nächstes bauen wir den Prädiktor x ein. Wir verwenden hier die zentrierte Variable “_dm” um Inner-Person Effekte zu berechnen.\nLevel 1: \\(y_{ij} = \\beta_{0j} + \\beta_{1j} \\cdot (X_{ij} - \\bar{X_j}) + e_{ij}\\)\nLevel 2 (random intercept): \\(\\beta_{0j} = \\gamma_{00} + u_{0j}\\)\nLevel 2 (fixed effect only): \\(\\beta'_{1j} = \\gamma'_{10}\\)\n\nri.fs_modell &lt;- lmer(y ~ x_dm + (1 | id), data = df_example1)\n\n\nmodel_parameters(ri.fs_modell) |&gt; print_html()\n\n\n\n\n\n\n\nModel Summary\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(996)\np\n\n\n\n\nFixed Effects\n\n\n(Intercept)\n5.37\n0.09\n(5.20, 5.54)\n61.50\n&lt; .001\n\n\nx dm\n0.44\n0.04\n(0.36, 0.51)\n11.63\n&lt; .001\n\n\nRandom Effects\n\n\nSD (Intercept: id)\n0.84\n\n\n\n\n\n\nSD (Residual)\n0.79\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.4.1 Visualisierung\n\n\n`geom_smooth()` using formula = 'y ~ x'",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Kapitel 4: Hypothesentests - Teil 1</span>"
    ]
  },
  {
    "objectID": "03 Hypotheses Tests.html#random-intercept-random-slope-modell",
    "href": "03 Hypotheses Tests.html#random-intercept-random-slope-modell",
    "title": "4  Kapitel 4: Hypothesentests - Teil 1",
    "section": "4.5 Random intercept, random slope Modell",
    "text": "4.5 Random intercept, random slope Modell\nAls nächstes fügen wir den random slope der Prädiktorvariable x_dm hinzu, in dem wir die random effect Struktur erweitern - “(1 + x_dm | id)”.\nLevel 1: \\(y_{ij} = \\beta_{0j} + \\beta_{1j} \\cdot (X_{ij}-\\bar{X_j}) + e_{ij}\\)\nLevel 2 (random intercept): \\(\\beta_{0j} = \\gamma_{00} + u_{0j}\\)\nLevel 2: \\(\\beta'_{1j} = \\gamma'_{10}\\)\n\nri.rs_modell &lt;- lmer(y ~ x_dm + (1 + x_dm | id), data = df_example1)\nmodel_parameters(ri.rs_modell) |&gt; print_html()\n\n\n\n\n\n\n\nModel Summary\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(994)\np\n\n\n\n\nFixed Effects\n\n\n(Intercept)\n5.37\n0.09\n(5.20, 5.54)\n61.50\n&lt; .001\n\n\nx dm\n0.42\n0.07\n(0.28, 0.56)\n5.88\n&lt; .001\n\n\nRandom Effects\n\n\nSD (Intercept: id)\n0.85\n\n\n\n\n\n\nSD (x_dm: id)\n0.63\n\n\n\n\n\n\nCor (Intercept~x_dm: id)\n0.20\n\n\n\n\n\n\nSD (Residual)\n0.65\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.5.1 Visualisierung\n\n\n`geom_smooth()` using formula = 'y ~ x'",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Kapitel 4: Hypothesentests - Teil 1</span>"
    ]
  },
  {
    "objectID": "03 Hypotheses Tests.html#level-2-prädiktoren",
    "href": "03 Hypotheses Tests.html#level-2-prädiktoren",
    "title": "4  Kapitel 4: Hypothesentests - Teil 1",
    "section": "4.6 Level-2 Prädiktoren",
    "text": "4.6 Level-2 Prädiktoren\nAls nächstes fügen wir einen Level-2 Prädiktor hinzu, der pro Person nur einmal gemessen wurde. Dabei handelt es sich für gewöhnlich um (1) Variablen, bei denen wir nicht an täglichen Schwankungen interessiert sind, wie soziodemografischen oder Persönlichkeitsvariablen, oder (2) den Mittelwert der Personen auf einer täglich gemessenen Variable. Im Beispiel verwenden wir (2), “x_gm”.\nLevel 1: \\(y_{ij} = \\beta_{0j} + \\beta_{1j} \\cdot (X_{ij}-\\bar{X_j}) + \\beta_{2j}\\cdot\\bar{X_j} + e_{ij}\\)\nLevel 2 (random intercept): \\(\\beta_{0j} = \\gamma_{00} + u_{0j}\\) Level 2 (random slope for x): \\(\\beta_{1j} = \\gamma_{10} + u_{2j}\\)\n\nri.rs_l2_modell &lt;- lmer(y ~ x_dm + x_gm + (1 + x_dm | id), data = df_example1)\nmodel_parameters(ri.rs_l2_modell) |&gt; print_html()\n\n\n\n\n\n\n\nModel Summary\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(993)\np\n\n\n\n\nFixed Effects\n\n\n(Intercept)\n4.47\n0.19\n(4.09, 4.84)\n23.30\n&lt; .001\n\n\nx dm\n0.42\n0.07\n(0.28, 0.56)\n5.85\n&lt; .001\n\n\nx gm\n0.43\n0.08\n(0.26, 0.59)\n5.13\n&lt; .001\n\n\nRandom Effects\n\n\nSD (Intercept: id)\n0.75\n\n\n\n\n\n\nSD (x_dm: id)\n0.63\n\n\n\n\n\n\nCor (Intercept~x_dm: id)\n0.17\n\n\n\n\n\n\nSD (Residual)\n0.65",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Kapitel 4: Hypothesentests - Teil 1</span>"
    ]
  },
  {
    "objectID": "03 Hypotheses Tests.html#übung",
    "href": "03 Hypotheses Tests.html#übung",
    "title": "4  Kapitel 4: Hypothesentests - Teil 1",
    "section": "4.7 Übung",
    "text": "4.7 Übung\nWir arbeiten in der Übung mit einem neuen Datensatz.\nMache dich mit ihm vertraut. Diesmal benutzen wir einen Datensatz in dem die Variablen “labelled” sind, also Beschriftungen haben. Wir können die Labels mit get_label() oder view_df() abrufen.\n\nload(\"../data/df_example_cli.RData\")\n\nhead(df_example_cli)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nilltask\nnegativ\nsupport\nilltask_dm\nnegativ_dm\nilltask_gm\nnegativ_gm\nnegativ_dm_l1\nday\n\n\n\n\n1\n1.188858\n1.825857\n3.454777\n-1.2994333\n-0.0153842\n2.488291\n1.841241\nNA\n1\n\n\n1\n1.719163\n1.633681\n3.454777\n-0.7691283\n-0.2075602\n2.488291\n1.841241\nNA\n4\n\n\n1\n3.149280\n1.250429\n3.454777\n0.6609887\n-0.5908122\n2.488291\n1.841241\nNA\n7\n\n\n1\n2.372508\n1.583838\n3.454777\n-0.1157833\n-0.2574032\n2.488291\n1.841241\n-0.5908122\n8\n\n\n1\n2.558448\n2.912401\n3.454777\n0.0701567\n1.0711598\n2.488291\n1.841241\n-0.2574032\n9\n\n\n2\n1.336438\n2.111289\n2.109855\n0.2807496\n-0.4911521\n1.055688\n2.602441\nNA\n1\n\n\n\n\n\nview_df(df_example_cli)\n\n\nData frame: df_example_cli\n\n\nID\nName\nLabel\nValues\nValue Labels\n\n\n1\nid\nPersonen-ID\nrange: 1-100\n\n\n2\nilltask\nDaily Illegitimate Tasks\nrange: -1.9-5.6\n\n\n3\nnegativ\nDaily Negative Affect\nrange: -0.2-7.7\n\n\n4\nsupport\nCoworker support\nrange: 1.4-4.5\n\n\n5\nilltask_dm\nIllegitimate Tasks (person-mean centered)\nrange: -2.1-2.3\n\n\n6\nnegativ_dm\nNeg. Affect (person-mean centered)\nrange: -2.0-2.7\n\n\n7\nilltask_gm\nIllegitimate Tasks (person average)\nrange: -0.7-4.7\n\n\n8\nnegativ_gm\nNeg. Affect (person average)\nrange: 0.8-5.0\n\n\n9\nnegativ_dm_l1\nPrevious-day Neg. Affect\nrange: -2.0-2.7\n\n\n10\nday\nTag (1-10)\nrange: 1-10\n\n\n\n\n# alternativ\n#get_label(df_example_cli)\n\nBerechne Modelle mit denen du die folgenden Hypothesen testest:\nHypothese 1: Tägliche illegitime Aufgaben hängen positiv mit täglichem negativem Affekt zusammen.\nTeste zunächst ein Random intercept, fixed slope Modell, und dann ein Random Intercept, Random Slope Modell. Urteile, ob die Hypothese angenommen oder verworfen werden sollten.\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nri.fs_modell &lt;- lmer(negativ ~ illtask_dm + (1 | id), data = df_example_cli)\nparameters(ri.fs_modell) |&gt; print_html()\n\nPackage 'merDeriv' needs to be installed to compute confidence intervals\n  for random effect parameters.\n\n\n\n\n\n\n\n\nModel Summary\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(779)\np\n\n\n\n\nFixed Effects\n\n\n(Intercept)\n2.73\n0.07\n(2.59, 2.87)\n37.43\n&lt; .001\n\n\nilltask dm\n0.30\n0.04\n(0.23, 0.38)\n8.07\n&lt; .001\n\n\nRandom Effects\n\n\nSD (Intercept: id)\n0.68\n\n\n\n\n\n\nSD (Residual)\n0.72\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nri.rs_modell &lt;- lmer(negativ ~ illtask_dm + (1 + illtask_dm | id), data = df_example_cli)\nparameters(ri.rs_modell) |&gt; print_html()\n\n\n\n\n\n\n\nModel Summary\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(777)\np\n\n\n\n\nFixed Effects\n\n\n(Intercept)\n2.73\n0.07\n(2.59, 2.87)\n37.65\n&lt; .001\n\n\nilltask dm\n0.32\n0.05\n(0.22, 0.43)\n6.37\n&lt; .001\n\n\nRandom Effects\n\n\nSD (Intercept: id)\n0.68\n\n\n\n\n\n\nSD (illtask_dm: id)\n0.35\n\n\n\n\n\n\nCor (Intercept~illtask_dm: id)\n0.70\n\n\n\n\n\n\nSD (Residual)\n0.68\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDie Hypothese 1 kann angenommen werden, da der Effekt von illegitimen Aufgaben (illtask_dm) signifikant positiv ist. Auch im strengeren random Slopes Modell ist der Effekt weiterhin signifikant.\nWir können auch sehen, dass im Random Slopes Modell die Konfidenzintervalle etwas breiter sind und der Standardfehler etwas grösser sind als im Fixed Slopes Modell. In Random Slopes Modellen können die Regressionskoeffizienten zwischen den Individuen variieren, was zusätzliche Varianz in die Schätzungen einbringt. Diese zusätzliche Unsicherheit führt dazu, dass sowohl die Standardfehler als auch die Konfidenzintervalle grösser ausfallen als in Fixed Slopes Modellen, bei denen die Steigung als konstant über alle Gruppen angenommen wird. Dadurch reflektieren die größeren Intervalle die höhere Unsicherheit in der Modellierung individueller Unterschiede in den Effekten.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Kapitel 4: Hypothesentests - Teil 1</span>"
    ]
  }
]