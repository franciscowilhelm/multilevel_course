[
  {
    "objectID": "01 Data Preparation Item Level.html",
    "href": "01 Data Preparation Item Level.html",
    "title": "2  Kapitel 1: Datenaufbereitung",
    "section": "",
    "text": "2.1 Pakete installieren und laden\nif (!require(\"pacman\")) install.packages(\"pacman\")\n\nLoading required package: pacman\n\npacman::p_load(haven, psych,\n               sjmisc, sjPlot, writexl,\n               tidyverse, multilevelTools)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Kapitel 1: Datenaufbereitung</span>"
    ]
  },
  {
    "objectID": "01 Data Preparation Item Level.html#daten-einlesen",
    "href": "01 Data Preparation Item Level.html#daten-einlesen",
    "title": "2  Kapitel 1: Datenaufbereitung",
    "section": "2.2 Daten einlesen",
    "text": "2.2 Daten einlesen\n\nload(\"../data/df_cfa_wide.RData\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Kapitel 1: Datenaufbereitung</span>"
    ]
  },
  {
    "objectID": "01 Data Preparation Item Level.html#daten-ansehen",
    "href": "01 Data Preparation Item Level.html#daten-ansehen",
    "title": "2  Kapitel 1: Datenaufbereitung",
    "section": "2.3 Daten ansehen",
    "text": "2.3 Daten ansehen\nDer Datensatz hat 131 (!) Spalten (ncol()) und 100 Zeilen (nrow()) (eine pro Person). Aufgrund des breiten Datenformats gibt es so viele Spalten, da jeder Tag (1-10 Tage) von jeder Variable seine eigene Spalte bekommt. Wie wir mit names() sehen, gibt es die Variablen id für die Personidentifikation (jede Person hat ihre eigene Nummer), a1-a5, b1-b5, und c1-c3. w,a,b und c bilden jeweils eine Skala mit 5 bzw. bei c 3 Indikatoren. Mit head() können wir einen Blick in die Daten werfen.\n\nncol(df_cfa_wide)\n\n[1] 131\n\nnrow(df_cfa_wide)\n\n[1] 100\n\nnames(df_cfa_wide)\n\n  [1] \"id\"     \"a1_t1\"  \"a1_t2\"  \"a1_t3\"  \"a1_t4\"  \"a1_t5\"  \"a1_t6\"  \"a1_t7\" \n  [9] \"a1_t8\"  \"a1_t9\"  \"a1_t10\" \"a2_t1\"  \"a2_t2\"  \"a2_t3\"  \"a2_t4\"  \"a2_t5\" \n [17] \"a2_t6\"  \"a2_t7\"  \"a2_t8\"  \"a2_t9\"  \"a2_t10\" \"a3_t1\"  \"a3_t2\"  \"a3_t3\" \n [25] \"a3_t4\"  \"a3_t5\"  \"a3_t6\"  \"a3_t7\"  \"a3_t8\"  \"a3_t9\"  \"a3_t10\" \"a4_t1\" \n [33] \"a4_t2\"  \"a4_t3\"  \"a4_t4\"  \"a4_t5\"  \"a4_t6\"  \"a4_t7\"  \"a4_t8\"  \"a4_t9\" \n [41] \"a4_t10\" \"a5_t1\"  \"a5_t2\"  \"a5_t3\"  \"a5_t4\"  \"a5_t5\"  \"a5_t6\"  \"a5_t7\" \n [49] \"a5_t8\"  \"a5_t9\"  \"a5_t10\" \"b1_t1\"  \"b1_t2\"  \"b1_t3\"  \"b1_t4\"  \"b1_t5\" \n [57] \"b1_t6\"  \"b1_t7\"  \"b1_t8\"  \"b1_t9\"  \"b1_t10\" \"b2_t1\"  \"b2_t2\"  \"b2_t3\" \n [65] \"b2_t4\"  \"b2_t5\"  \"b2_t6\"  \"b2_t7\"  \"b2_t8\"  \"b2_t9\"  \"b2_t10\" \"b3_t1\" \n [73] \"b3_t2\"  \"b3_t3\"  \"b3_t4\"  \"b3_t5\"  \"b3_t6\"  \"b3_t7\"  \"b3_t8\"  \"b3_t9\" \n [81] \"b3_t10\" \"b4_t1\"  \"b4_t2\"  \"b4_t3\"  \"b4_t4\"  \"b4_t5\"  \"b4_t6\"  \"b4_t7\" \n [89] \"b4_t8\"  \"b4_t9\"  \"b4_t10\" \"b5_t1\"  \"b5_t2\"  \"b5_t3\"  \"b5_t4\"  \"b5_t5\" \n [97] \"b5_t6\"  \"b5_t7\"  \"b5_t8\"  \"b5_t9\"  \"b5_t10\" \"c1_t1\"  \"c1_t2\"  \"c1_t3\" \n[105] \"c1_t4\"  \"c1_t5\"  \"c1_t6\"  \"c1_t7\"  \"c1_t8\"  \"c1_t9\"  \"c1_t10\" \"c2_t1\" \n[113] \"c2_t2\"  \"c2_t3\"  \"c2_t4\"  \"c2_t5\"  \"c2_t6\"  \"c2_t7\"  \"c2_t8\"  \"c2_t9\" \n[121] \"c2_t10\" \"c3_t1\"  \"c3_t2\"  \"c3_t3\"  \"c3_t4\"  \"c3_t5\"  \"c3_t6\"  \"c3_t7\" \n[129] \"c3_t8\"  \"c3_t9\"  \"c3_t10\"\n\nhead(df_cfa_wide)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\na1_t1\na1_t2\na1_t3\na1_t4\na1_t5\na1_t6\na1_t7\na1_t8\na1_t9\na1_t10\na2_t1\na2_t2\na2_t3\na2_t4\na2_t5\na2_t6\na2_t7\na2_t8\na2_t9\na2_t10\na3_t1\na3_t2\na3_t3\na3_t4\na3_t5\na3_t6\na3_t7\na3_t8\na3_t9\na3_t10\na4_t1\na4_t2\na4_t3\na4_t4\na4_t5\na4_t6\na4_t7\na4_t8\na4_t9\na4_t10\na5_t1\na5_t2\na5_t3\na5_t4\na5_t5\na5_t6\na5_t7\na5_t8\na5_t9\na5_t10\nb1_t1\nb1_t2\nb1_t3\nb1_t4\nb1_t5\nb1_t6\nb1_t7\nb1_t8\nb1_t9\nb1_t10\nb2_t1\nb2_t2\nb2_t3\nb2_t4\nb2_t5\nb2_t6\nb2_t7\nb2_t8\nb2_t9\nb2_t10\nb3_t1\nb3_t2\nb3_t3\nb3_t4\nb3_t5\nb3_t6\nb3_t7\nb3_t8\nb3_t9\nb3_t10\nb4_t1\nb4_t2\nb4_t3\nb4_t4\nb4_t5\nb4_t6\nb4_t7\nb4_t8\nb4_t9\nb4_t10\nb5_t1\nb5_t2\nb5_t3\nb5_t4\nb5_t5\nb5_t6\nb5_t7\nb5_t8\nb5_t9\nb5_t10\nc1_t1\nc1_t2\nc1_t3\nc1_t4\nc1_t5\nc1_t6\nc1_t7\nc1_t8\nc1_t9\nc1_t10\nc2_t1\nc2_t2\nc2_t3\nc2_t4\nc2_t5\nc2_t6\nc2_t7\nc2_t8\nc2_t9\nc2_t10\nc3_t1\nc3_t2\nc3_t3\nc3_t4\nc3_t5\nc3_t6\nc3_t7\nc3_t8\nc3_t9\nc3_t10\n\n\n\n\n1\n3.336252\n2.149828\n1.613518\n3.351085\n3.320900\n4.173775\n3.653771\n1.926106\n5.621661\n4.948758\n3.380463\n5.110309\n3.004133\n3.852294\n3.694431\n5.658948\n4.973751\n4.999227\n5.123906\n6.090460\n3.223528\n5.678413\n2.503233\n4.972103\n4.703663\n3.273027\n3.187604\n3.664482\n5.464105\n3.765162\n4.399347\n2.765556\n1.898476\n2.612551\n3.476859\n4.192700\n2.856953\n4.112356\n4.579488\n3.134414\n3.542602\n2.387270\n2.807670\n3.233779\n4.210036\n3.565438\n3.293944\n3.909548\n5.635526\n4.620410\n3.370896\n2.486919\n0.991958\n2.248097\n1.953658\n1.544111\n2.103968\n1.763424\n3.087552\n1.618470\n1.697640\n0.952220\n-0.685685\n0.004118\n0.675750\n-0.373186\n1.938302\n0.447036\n3.860272\n1.211009\n0.584167\n2.101517\n0.003147\n0.711264\n0.921623\n1.303905\n1.201749\n0.899882\n1.797242\n0.734580\n1.576649\n0.331000\n-0.517730\n2.185949\n0.284884\n1.687402\n1.388842\n0.160632\n2.144261\n1.205662\n2.847195\n2.552073\n1.955846\n2.028044\n2.361978\n2.539967\n2.125510\n1.206909\n4.844395\n4.320178\n4.325797\n3.364003\n2.582169\n2.918614\n2.829237\n4.141474\n2.711044\n4.787052\n4.594232\n2.511473\n1.030847\n5.711729\n2.659834\n3.163276\n3.910432\n5.234767\n5.515933\n5.206142\n4.431722\n4.953160\n3.822098\n3.613752\n2.155132\n2.463234\n2.739723\n3.409232\n3.488225\n1.453246\n4.117747\n3.745528\n\n\n2\n3.707018\n2.377418\n1.854018\n4.632683\n2.479164\n2.234632\n4.485121\n4.011457\n2.427658\n2.600831\n3.996684\n3.074568\n3.716554\n3.796472\n3.108752\n2.922636\n4.654462\n4.431057\n3.497468\n4.130753\n0.810690\n2.874266\n3.669414\n2.478778\n2.406462\n2.515853\n3.129976\n3.718570\n2.542158\n2.606330\n3.515638\n4.128262\n3.577047\n4.258751\n4.238509\n3.267878\n4.119021\n2.712250\n2.601381\n5.293957\n2.907960\n2.834590\n3.827659\n5.278379\n3.967381\n4.134327\n5.923659\n4.251589\n3.292468\n3.639972\n2.323243\n2.042416\n2.601619\n0.235322\n1.990456\n3.388960\n0.995331\n3.325457\n2.207927\n0.221311\n2.990608\n1.476811\n2.349784\n3.097647\n2.047705\n2.722032\n3.112804\n1.368452\n2.251611\n1.587188\n1.013232\n2.926646\n2.095343\n2.858416\n3.019904\n1.726097\n3.515165\n1.348090\n1.890474\n2.311975\n1.190393\n2.184150\n1.549624\n0.452129\n1.513757\n1.432716\n1.950500\n2.007023\n0.249291\n-0.504312\n2.010378\n4.018477\n3.410691\n3.063017\n3.897992\n2.469268\n2.906900\n2.914951\n0.608605\n2.239330\n2.576924\n1.208644\n2.606353\n3.886131\n3.856964\n3.332155\n0.597512\n2.731819\n2.110466\n2.687502\n-1.710033\n-0.670529\n-0.330814\n-0.601643\n-0.251286\n0.439045\n0.734464\n0.066167\n-0.849054\n-0.757472\n0.351828\n0.095795\n0.897598\n2.615174\n0.455632\n2.211615\n-0.235576\n0.389909\n-0.160126\n1.833746\n\n\n3\n5.177071\n-0.128053\n2.797632\n0.303081\n4.314881\n2.337009\n3.575595\n1.818855\n-0.306364\n1.614770\n2.958702\n2.735971\n2.978813\n4.107814\n4.661105\n3.033462\n2.912859\n3.754350\n1.986925\n2.453018\n5.346752\n4.501127\n4.825683\n4.908117\n5.724673\n5.153263\n4.766531\n5.198076\n1.471673\n3.829653\n4.772178\n2.755005\n4.204091\n2.631057\n4.744125\n3.983818\n2.875329\n3.684137\n1.252706\n1.649124\n5.782683\n4.648184\n3.675335\n5.918703\n5.729757\n5.027148\n4.950459\n5.555384\n2.874046\n2.074345\n3.034341\n5.163917\n1.010752\n1.666880\n1.295466\n1.477020\n1.009490\n1.175458\n1.284057\n3.434230\n4.263902\n3.116927\n2.598624\n2.281766\n4.053404\n2.417430\n1.154442\n2.357182\n-0.103946\n2.599341\n3.981286\n1.433954\n2.329805\n3.582351\n2.509821\n-0.341738\n1.558373\n2.687843\n1.337345\n3.732375\n3.988386\n2.509786\n2.058585\n3.740040\n3.256067\n3.500106\n0.782067\n3.601466\n0.922850\n4.635307\n3.024556\n1.150083\n3.052157\n3.163149\n2.655710\n0.093386\n-0.073910\n2.227515\n1.712568\n2.898763\n2.820979\n1.664689\n2.688626\n2.657114\n1.381627\n2.417342\n1.443182\n2.776111\n2.248535\n2.684371\n1.748407\n2.869058\n1.052509\n3.174517\n0.118054\n0.789280\n2.679447\n0.740977\n1.135104\n0.980832\n1.537544\n2.950929\n1.429920\n2.534687\n3.792833\n1.161559\n0.105494\n2.915895\n1.714465\n2.815621\n\n\n4\n4.705740\n3.597286\n2.948942\n2.098839\n2.783596\n4.420878\n1.358347\n3.848268\n3.714631\n2.284839\n4.038396\n4.916627\n2.739167\n3.144930\n2.224095\n2.968036\n2.365223\n3.665594\n2.585768\n3.208773\n5.110747\n4.059650\n3.327694\n4.411642\n3.937307\n5.154507\n3.126869\n4.554551\n3.766840\n4.039097\n5.965881\n5.027371\n4.130869\n5.175652\n4.037358\n5.245027\n3.205133\n3.004498\n6.786242\n4.499281\n3.958800\n3.838211\n3.211688\n2.475119\n2.191741\n2.052676\n2.687921\n2.079803\n3.929772\n1.621818\n3.621642\n3.197431\n2.838179\n1.280215\n1.746913\n2.267367\n1.597599\n2.441468\n1.211542\n4.138991\n1.342898\n1.821522\n1.688056\n2.463308\n2.030884\n0.815056\n0.953910\n1.729489\n1.332197\n3.093290\n2.400477\n2.873127\n1.997939\n1.791812\n-0.960833\n0.893946\n0.647417\n1.110916\n1.748169\n2.121472\n1.952886\n2.904973\n0.878772\n1.269630\n0.835469\n-1.070358\n-0.541286\n1.063053\n1.485312\n3.607293\n4.027168\n3.804839\n2.787383\n2.807136\n2.706166\n2.527843\n1.675010\n2.839636\n3.124758\n4.327591\n-0.571315\n2.285224\n1.057377\n1.803651\n0.992669\n1.980404\n3.310448\n1.662047\n2.537811\n1.245361\n1.490392\n0.456182\n1.328019\n1.697168\n0.693560\n0.252673\n2.728439\n1.103803\n1.332902\n0.163830\n0.043749\n0.744745\n0.204956\n-0.370906\n-1.022587\n-0.403501\n1.095947\n0.274934\n1.170815\n-1.658070\n\n\n5\n3.949976\n3.330208\n5.413867\n3.719810\n5.798861\n3.088709\n4.012137\n5.875070\n3.181456\n4.931577\n3.317796\n5.810359\n5.343310\n3.928448\n3.798973\n3.932334\n2.986737\n6.926680\n4.932457\n6.716081\n3.673230\n3.927261\n4.515421\n3.791699\n4.846026\n3.398835\n2.273474\n4.371252\n1.762524\n3.275910\n5.841838\n8.072948\n6.721671\n6.987111\n5.944237\n4.489158\n4.921571\n7.603350\n6.165390\n6.983403\n3.389670\n5.893949\n3.749111\n4.411794\n2.873486\n2.611568\n1.286889\n4.646997\n3.107310\n4.433750\n1.701253\n0.278520\n3.249563\n2.181162\n3.107517\n0.092424\n1.985821\n1.740418\n3.187945\n2.244310\n3.361174\n3.497546\n3.372372\n2.430237\n5.397523\n3.270945\n3.053623\n1.919141\n3.688502\n2.961518\n4.337413\n3.496237\n5.441549\n3.444545\n4.486709\n4.455020\n2.470650\n5.844872\n4.583409\n6.108861\n4.302733\n2.764837\n3.876676\n3.527337\n5.128605\n2.163503\n1.886539\n1.734753\n3.437857\n3.740089\n4.179862\n3.775715\n5.299768\n2.953386\n3.807893\n2.537854\n2.901724\n4.785203\n5.926126\n4.928503\n3.053878\n1.885364\n4.448834\n3.900540\n4.728735\n2.129385\n3.805631\n2.089345\n3.743529\n2.992289\n1.790360\n1.515488\n3.618075\n3.781413\n4.205560\n1.303834\n3.673459\n3.327604\n3.160806\n3.722098\n1.817841\n2.362278\n2.812572\n4.554119\n3.287976\n3.279677\n1.435943\n3.242930\n0.500366\n5.079764\n\n\n6\n2.274255\n2.290222\n1.376191\n2.173916\n2.099371\n3.312339\n2.172030\n2.595873\n2.289308\n1.580778\n2.787734\n2.067549\n2.180852\n3.302369\n1.863362\n3.760236\n2.294264\n2.135892\n1.550506\n2.432511\n3.703579\n2.047107\n3.065654\n1.978181\n2.963593\n2.955959\n3.468359\n4.343268\n3.525407\n3.837417\n4.151001\n0.835873\n1.884775\n2.608722\n3.012065\n2.776904\n2.578840\n3.399579\n3.577152\n3.039595\n1.512579\n0.621510\n1.092427\n1.911605\n1.368582\n2.511084\n0.839038\n3.272104\n1.121144\n1.740897\n2.996994\n-1.267884\n2.586945\n2.184757\n-0.124601\n2.601747\n1.747253\n2.520691\n4.051763\n2.738223\n1.022146\n-1.129770\n1.219736\n-0.032099\n2.843606\n-1.122089\n0.739502\n2.138073\n0.272516\n0.625661\n2.134281\n0.231331\n2.861858\n1.303966\n1.199804\n1.300905\n1.312581\n2.266003\n3.106999\n2.869239\n2.308207\n1.068449\n2.414964\n1.894137\n2.681821\n0.512435\n2.125864\n2.787195\n2.595406\n2.191860\n2.267998\n0.203488\n2.181351\n1.670791\n0.222494\n0.947280\n2.464313\n2.733245\n2.599860\n1.042442\n1.648781\n0.598068\n0.225724\n0.521410\n1.669001\n1.384766\n2.299040\n2.014711\n2.088084\n0.651604\n2.356883\n0.718648\n1.309239\n2.011107\n1.617811\n3.844703\n1.838274\n2.215482\n2.364317\n1.437971\n2.745956\n3.067538\n3.096565\n2.927631\n4.206480\n3.969140\n5.377585\n2.509150\n2.817378\n1.073844",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Kapitel 1: Datenaufbereitung</span>"
    ]
  },
  {
    "objectID": "01 Data Preparation Item Level.html#daten-transformieren-langformat",
    "href": "01 Data Preparation Item Level.html#daten-transformieren-langformat",
    "title": "2  Kapitel 1: Datenaufbereitung",
    "section": "2.4 Daten transformieren: Langformat",
    "text": "2.4 Daten transformieren: Langformat\nAls erstes transformieren wir die Daten vom Breit- ins Langformat, so dass jede Messung (Tag 1-Tag 10) eine eigene Zeile bekommt. Diese Variable nennen wir “time”. Im ersten Schritt machen wir mit pivot_longer() den Datensatz seehr lang, es bekommt nämlich jede Messung von jeder Variable ihre eigenen Zeile. Wir machen den Datensatz dann im zweiten Schritt mit pivot_wider() wieder etwas breiter mit dem Ziel, eine Zeile pro Person und Tag zu bekommen, und jeweils eine Spalte pro Item.\nDie Funktionsweise von pivot_longer() und pivot_wider() ist in der Einführung zu R beschrieben.\n\ndf_cfa_superlong &lt;- df_cfa_wide |&gt; \n  pivot_longer(\n    cols = -id, # All columns except id\n    names_to = c(\"variable\", \"time\"),\n    names_sep = \"_t\"\n  ) \n\ndf_cfa_long &lt;- df_cfa_superlong |&gt; \n  pivot_wider(names_from = variable,\n              values_from = value) |&gt; \n  mutate(time = as.numeric(time)) # time ist eine Zahl von 1-10, wurde aber zuvor als Character-Vector abgespeichert",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Kapitel 1: Datenaufbereitung</span>"
    ]
  },
  {
    "objectID": "01 Data Preparation Item Level.html#daten-transformieren-skalenscores-erstellen",
    "href": "01 Data Preparation Item Level.html#daten-transformieren-skalenscores-erstellen",
    "title": "2  Kapitel 1: Datenaufbereitung",
    "section": "2.5 Daten transformieren: Skalenscores erstellen",
    "text": "2.5 Daten transformieren: Skalenscores erstellen\nAls nächstes können wir die Skalenscores erstellen.\n\ndf_cfa_long_scores &lt;- df_cfa_long |&gt; group_by(id, time) |&gt; \n  summarise(\n    a = rowMeans(across(starts_with(\"a\")), na.rm = TRUE),\n    b = rowMeans(across(starts_with(\"b\")), na.rm = TRUE),\n    c = rowMeans(across(starts_with(\"c\")), na.rm = TRUE),\n    .groups = \"drop\" # group_by() wieder aufheben für den finalen Datensatz\n  )\n\nWir verwenden eine simple Form der Skalenerstellung bei dem der Mittelwert aller vorhandenen Items einer Skala verwendet wird. (Best-practice ist es bei fehlenden Daten genau hinzuschauen und nur dann einen Skalenwert zu erstellen, wenn die Personen zu einen gewissen Prozentsatz aller Items eine Antwort geben (etwa 2/3). Eine solche Funktion könnten wir programmieren, lassen es aber für das Beispiel weg.)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Kapitel 1: Datenaufbereitung</span>"
    ]
  },
  {
    "objectID": "01 Data Preparation Item Level.html#daten-transformieren-zentrierung",
    "href": "01 Data Preparation Item Level.html#daten-transformieren-zentrierung",
    "title": "2  Kapitel 1: Datenaufbereitung",
    "section": "2.6 Daten transformieren: Zentrierung",
    "text": "2.6 Daten transformieren: Zentrierung\nFür die spätere Verwendung zerlegen wir die Rohvariablen mittels person-mean Zentrierung. Wir zentrieren wir die Skalenvariablen, die täglich gemessen werden (aber nicht Baseline-Variablen), mittels de_mean(). de_mean() nimmt als Argumente (a) mit Komma getrennte Namen der Variablen, die wir zentrieren wollen (mehrere auf einmal ist möglich), (b) mittels grp = Argument die identifizierende Variable für die Gruppenzugehörigkeit in Anführungszeichen (\"id\".\n\ndf_cfa_long_scores &lt;- df_cfa_long_scores |&gt; \n  de_mean(a,b, c, grp = \"id\")\nhead(df_cfa_long_scores)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\ntime\na\nb\nc\na_dm\nb_dm\nc_dm\na_gm\nb_gm\nc_gm\n\n\n\n\n1\n1\n3.576438\n2.0153094\n3.059581\n-0.2566380\n0.4476044\n-0.5267811\n3.833076\n1.567705\n3.586362\n\n\n1\n2\n3.618275\n1.6847458\n4.229828\n-0.2148012\n0.1170408\n0.6434662\n3.833076\n1.567705\n3.586362\n\n\n1\n3\n2.365406\n0.3495072\n2.465712\n-1.4676704\n-1.2181978\n-1.1206501\n3.833076\n1.567705\n3.586362\n\n\n1\n4\n3.604362\n1.4354944\n2.848375\n-0.2287140\n-0.1322106\n-0.7379871\n3.833076\n1.567705\n3.586362\n\n\n1\n5\n3.881178\n1.2395786\n3.159797\n0.0481014\n-0.3281264\n-0.4265645\n3.833076\n1.567705\n3.586362\n\n\n1\n6\n4.172778\n1.3404398\n4.261824\n0.3397012\n-0.2272652\n0.6754625\n3.833076\n1.567705\n3.586362\n\n\n\n\n\n\nAls Ergebnis erhalten wir die zusätzlichen Variablen a, b, c jeweils mit “_dm” und “_gm”. Was verbirgt sich dahinter? Wir haben einen Datensatz mit den unzentrierten / Rohvariablen der Skalen (ohne Suffix), den zentrierten Variablen (Suffix _dm) und den Mittelwerten der Personen (Suffix _gm), den wir zur weiteren Verwendung auch abspeichern.\nDamit ist die Transformation der Daten abgeschlossen! Wir können die Datensätze - “df_cfa_long” für die Items und “df_cfa_long_scores” für die Skalen nun abspeichern.\n\nsave(df_cfa_long, df_cfa_long_scores, file = \"../data/df_cfa_long.RData\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Kapitel 1: Datenaufbereitung</span>"
    ]
  },
  {
    "objectID": "01 Data Preparation Item Level.html#überprüfe-dein-verständnis",
    "href": "01 Data Preparation Item Level.html#überprüfe-dein-verständnis",
    "title": "2  Kapitel 1: Datenaufbereitung",
    "section": "2.7 Überprüfe dein Verständnis",
    "text": "2.7 Überprüfe dein Verständnis\n\nbeispiel_zentrierung &lt;- df_cfa_long_scores |&gt; \n  filter(id == 1) |&gt; \n  select(id, time, a, a_dm, a_gm)\n\nbeispiel_zentrierung\n\n\n\n\n\nid\ntime\na\na_dm\na_gm\n\n\n\n\n1\n1\n3.576438\n-0.2566380\n3.833076\n\n\n1\n2\n3.618275\n-0.2148012\n3.833076\n\n\n1\n3\n2.365406\n-1.4676704\n3.833076\n\n\n1\n4\n3.604362\n-0.2287140\n3.833076\n\n\n1\n5\n3.881178\n0.0481014\n3.833076\n\n\n1\n6\n4.172778\n0.3397012\n3.833076\n\n\n1\n7\n3.593205\n-0.2398718\n3.833076\n\n\n1\n8\n3.722344\n-0.1107326\n3.833076\n\n\n1\n9\n5.284937\n1.4518608\n3.833076\n\n\n1\n10\n4.511841\n0.6787644\n3.833076\n\n\n\n\n\n\nWarum ist der Wert, den Person 1 in “a_gm” hat, in jeder Zeile gleich, nicht aber bei “a_dm” und “a”? Wie müsste man a transformieren, damit man auf a_dm kommt? Denke an die mathematischen Operationen die du in mutate() eingeben müsstest, wie +, -, /, mean().\n\n\n\n\n\n\nLösung\n\n\n\n\n\nDie Variable a ist die Rohvariable, die den gemessenen Wert auf der Skala an jedem Tag angibt. Variablen mit “_gm” und “_dm” werden von sjmisc::de_mean() erstellt und stehen für den Mittelwert der Person über alle Tage hinweg. Variablen mit “_dm” stehen für die täglichen Abweichungen vom Mittelwert der Person. “a_dm” ergibt sich aus: \\(a = a - a\\_gm\\). Wir können dies auch in R replizieren mit:\n\nbeispiel_zentrierung |&gt; \n  mutate(a_dm_manuell = a - mean(a))\n\n\n\n\n\nid\ntime\na\na_dm\na_gm\na_dm_manuell\n\n\n\n\n1\n1\n3.576438\n-0.2566380\n3.833076\n-0.2566380\n\n\n1\n2\n3.618275\n-0.2148012\n3.833076\n-0.2148012\n\n\n1\n3\n2.365406\n-1.4676704\n3.833076\n-1.4676704\n\n\n1\n4\n3.604362\n-0.2287140\n3.833076\n-0.2287140\n\n\n1\n5\n3.881178\n0.0481014\n3.833076\n0.0481014\n\n\n1\n6\n4.172778\n0.3397012\n3.833076\n0.3397012\n\n\n1\n7\n3.593205\n-0.2398718\n3.833076\n-0.2398718\n\n\n1\n8\n3.722344\n-0.1107326\n3.833076\n-0.1107326\n\n\n1\n9\n5.284937\n1.4518608\n3.833076\n1.4518608\n\n\n1\n10\n4.511841\n0.6787644\n3.833076\n0.6787644",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Kapitel 1: Datenaufbereitung</span>"
    ]
  },
  {
    "objectID": "01 Data Preparation Item Level.html#übung-datenaufbereitung",
    "href": "01 Data Preparation Item Level.html#übung-datenaufbereitung",
    "title": "2  Kapitel 1: Datenaufbereitung",
    "section": "2.8 Übung Datenaufbereitung",
    "text": "2.8 Übung Datenaufbereitung\nSchau dir den Datensatz df_cfa_exercise an und repliziere die Schritte oben:\n\nDaten in Langformat transformieren und als df_uebung_lang &lt;- zuweisen.\nSkalenscores für x und y erstellen und als df_uebung_lang_scores &lt;- zuweisen.\nSkalenscores für x und y zentrieren (weiterhin in df_uebung_lang_scores).\n\nDu kannst dazu den Code von oben wiederverwenden und auf den hier verwendeten Datensatz und seine Variablen anpassen.\n\nload(\"../data/df_cfa_exercise.RData\")\nhead(df_cfa_exercise)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nx1_t1\nx1_t2\nx1_t3\nx1_t4\nx1_t5\nx1_t6\nx1_t7\nx1_t8\nx1_t9\nx1_t10\nx2_t1\nx2_t2\nx2_t3\nx2_t4\nx2_t5\nx2_t6\nx2_t7\nx2_t8\nx2_t9\nx2_t10\nx3_t1\nx3_t2\nx3_t3\nx3_t4\nx3_t5\nx3_t6\nx3_t7\nx3_t8\nx3_t9\nx3_t10\nx4_t1\nx4_t2\nx4_t3\nx4_t4\nx4_t5\nx4_t6\nx4_t7\nx4_t8\nx4_t9\nx4_t10\nx5_t1\nx5_t2\nx5_t3\nx5_t4\nx5_t5\nx5_t6\nx5_t7\nx5_t8\nx5_t9\nx5_t10\ny1_t1\ny1_t2\ny1_t3\ny1_t4\ny1_t5\ny1_t6\ny1_t7\ny1_t8\ny1_t9\ny1_t10\ny2_t1\ny2_t2\ny2_t3\ny2_t4\ny2_t5\ny2_t6\ny2_t7\ny2_t8\ny2_t9\ny2_t10\ny3_t1\ny3_t2\ny3_t3\ny3_t4\ny3_t5\ny3_t6\ny3_t7\ny3_t8\ny3_t9\ny3_t10\ny4_t1\ny4_t2\ny4_t3\ny4_t4\ny4_t5\ny4_t6\ny4_t7\ny4_t8\ny4_t9\ny4_t10\ny5_t1\ny5_t2\ny5_t3\ny5_t4\ny5_t5\ny5_t6\ny5_t7\ny5_t8\ny5_t9\ny5_t10\n\n\n\n\n1\n4.927017\n3.484359\n5.209319\n3.777327\n2.822955\n2.874990\n4.399279\n3.999338\n2.829229\n4.534257\n3.569244\n3.716360\n4.025572\n2.601702\n4.917407\n4.417907\n5.836183\n2.584864\n2.416726\n3.428733\n3.123268\n2.200183\n2.416466\n2.600930\n2.179303\n3.370835\n5.833981\n3.574207\n2.399534\n1.756436\n5.759150\n4.865658\n5.106690\n4.142291\n4.984553\n4.902819\n7.088255\n6.024145\n4.119966\n4.134776\n4.700258\n3.579269\n5.881804\n4.111085\n4.600078\n4.055922\n4.496880\n4.373719\n4.322336\n3.912015\n4.329297\n3.597471\n3.552542\n3.052100\n2.592308\n3.082656\n4.184377\n4.064089\n3.642032\n2.777390\n4.477198\n4.454955\n4.760682\n3.288172\n5.678996\n4.679951\n4.928690\n5.166207\n3.485148\n3.454632\n2.848577\n5.551165\n3.769263\n3.649328\n2.271035\n5.264214\n3.832915\n3.875455\n2.525079\n1.163129\n4.678402\n4.682683\n3.607138\n4.363976\n3.401883\n5.139966\n5.210060\n4.713772\n3.424733\n2.631818\n3.480544\n3.221823\n3.853132\n3.120772\n3.842651\n2.815425\n3.273848\n3.126467\n3.647887\n3.895862\n\n\n2\n5.024072\n2.470240\n2.259750\n3.383971\n3.405628\n2.925394\n3.722530\n3.104064\n4.068848\n2.923166\n3.661601\n3.732475\n2.084769\n3.978517\n2.855392\n3.381118\n3.865699\n3.911571\n3.102266\n2.858461\n5.186708\n1.540100\n3.453976\n1.671304\n4.397883\n4.996236\n3.609226\n2.266511\n5.332266\n5.041631\n2.577130\n1.182058\n2.648178\n2.580964\n4.378121\n2.015839\n2.477425\n2.718602\n2.512741\n3.104794\n2.425656\n2.302399\n1.261294\n2.294336\n0.776553\n3.169805\n2.850572\n2.683466\n2.756426\n3.199966\n3.488302\n3.348598\n1.567981\n2.689270\n2.093631\n0.946151\n2.760766\n1.974521\n0.788326\n1.546632\n3.613495\n3.002835\n2.618250\n3.474268\n4.107470\n3.950412\n3.461374\n3.162900\n2.504398\n3.957139\n3.269670\n2.924702\n2.951385\n1.403080\n1.747677\n3.671060\n2.755273\n2.860291\n3.582403\n2.855433\n4.296437\n4.459933\n3.877955\n3.542746\n4.623289\n5.768592\n2.820453\n4.347125\n5.008321\n5.628651\n3.446137\n3.354074\n0.216899\n1.984132\n2.551348\n1.010641\n3.200017\n1.600360\n1.541323\n3.561905\n\n\n3\n3.661946\n4.515898\n2.627455\n2.097116\n3.295632\n4.674215\n3.854248\n3.430167\n3.423922\n4.346313\n3.369146\n2.583655\n2.805899\n2.629365\n2.759572\n2.753171\n1.063016\n2.180655\n3.397097\n3.797167\n3.784757\n3.774945\n1.163201\n2.880376\n2.329117\n5.686030\n3.881392\n3.907517\n3.697921\n3.270770\n2.040071\n4.645036\n2.312931\n2.106188\n3.517961\n3.099783\n3.312862\n4.134669\n3.522531\n2.951239\n3.113105\n2.513375\n2.887626\n4.867711\n4.787919\n2.084980\n4.140326\n3.036390\n4.304286\n3.375258\n1.956426\n2.710257\n2.345528\n2.025919\n1.763310\n1.487463\n1.435715\n3.255219\n3.430917\n2.560493\n2.972647\n3.841999\n2.321647\n5.547948\n2.755463\n3.135102\n1.252126\n1.455243\n0.126571\n0.754453\n3.451330\n2.634979\n2.051891\n3.677636\n4.382111\n0.630656\n2.520796\n2.908761\n-0.251480\n1.706827\n4.334217\n3.310795\n3.634877\n3.788040\n3.997747\n3.418240\n1.451858\n5.332129\n3.107325\n2.796257\n3.441736\n1.732713\n4.678564\n3.527282\n4.910696\n3.960887\n2.782757\n3.427556\n4.629581\n4.084214\n\n\n4\n1.933604\n1.835414\n4.246882\n3.229524\n2.456309\n2.818070\n2.602155\n3.215303\n4.200392\n2.272876\n0.706912\n-0.801259\n1.640656\n1.587674\n1.470820\n2.430678\n1.819882\n1.695119\n1.338284\n0.605444\n0.133074\n0.158037\n1.792941\n1.790514\n1.269408\n3.353523\n2.179509\n1.409529\n0.888444\n1.224938\n0.326793\n0.174798\n2.335327\n1.525558\n-0.955707\n3.610542\n1.960530\n-0.865120\n1.385375\n1.430312\n0.685265\n-0.230309\n0.633548\n1.199429\n0.310757\n2.375445\n1.869323\n0.641068\n1.674369\n1.870899\n3.087726\n0.985564\n0.784520\n2.725897\n0.850097\n0.685824\n1.168844\n-0.239602\n2.799497\n2.131838\n1.596182\n1.458913\n3.630159\n2.387079\n0.462230\n0.650202\n2.356301\n0.755215\n2.026497\n2.441231\n2.790539\n2.575200\n3.509842\n3.116568\n3.452843\n3.093494\n1.836035\n2.222184\n2.761235\n4.237117\n3.075454\n1.881486\n2.553940\n1.045851\n3.202694\n4.161503\n2.702880\n0.817310\n2.733675\n1.369864\n0.687845\n2.150121\n1.293763\n0.737558\n0.793559\n1.293628\n1.312178\n-1.925199\n0.168729\n1.409099\n\n\n5\n2.274807\n2.908011\n3.179267\n2.941155\n3.710268\n2.717757\n3.510822\n1.550497\n2.728217\n4.947419\n4.312907\n1.624997\n3.450676\n3.296389\n4.639991\n4.428850\n4.773291\n2.273139\n2.820446\n3.868664\n4.675249\n2.412898\n3.691474\n4.295843\n4.288994\n3.679321\n3.664403\n3.449730\n4.627416\n5.374093\n3.114936\n0.937293\n3.231832\n2.031238\n2.033217\n0.704127\n1.766480\n1.422281\n1.951835\n3.429262\n2.336261\n3.616157\n3.631813\n3.258421\n5.976209\n4.089613\n2.896231\n4.596477\n4.129096\n7.093438\n3.593002\n3.190479\n2.211968\n2.500292\n3.999353\n2.826291\n2.768957\n2.979500\n3.155079\n3.074007\n2.688911\n2.680939\n4.108605\n2.347372\n3.353903\n3.417996\n3.602248\n3.722665\n1.867266\n4.398309\n2.672452\n3.234202\n4.512234\n1.011391\n2.736290\n2.495329\n2.283781\n0.979636\n2.101990\n3.646597\n4.168885\n6.011056\n5.576807\n4.452524\n5.109755\n3.539751\n5.203918\n6.884093\n6.758122\n4.835822\n1.016782\n1.853578\n2.498811\n3.096292\n2.572159\n2.496271\n1.515257\n1.183772\n3.329594\n2.744476\n\n\n6\n3.184660\n4.046734\n3.540150\n4.059281\n2.374465\n2.067087\n3.390182\n3.492470\n3.661657\n1.892471\n2.910669\n2.351059\n0.726541\n1.928325\n-0.062322\n1.306896\n0.272615\n1.463914\n2.076900\n2.569456\n5.019716\n2.328710\n2.837884\n4.043339\n1.947459\n2.449519\n3.065598\n4.321089\n2.036927\n1.389769\n3.537501\n4.318936\n1.631771\n3.685972\n3.609319\n1.645394\n2.917829\n2.317283\n2.267146\n3.963144\n3.536972\n3.295575\n3.075710\n3.460675\n3.224478\n1.660497\n3.093049\n2.421162\n2.188736\n3.557481\n0.309582\n1.857645\n1.819382\n1.085073\n2.427644\n1.988539\n2.246552\n2.295530\n1.075097\n1.388195\n1.656496\n1.752528\n2.418624\n1.340024\n0.824050\n0.698072\n1.970136\n2.064690\n1.795599\n4.439921\n1.967216\n0.477582\n1.303589\n0.223835\n1.302689\n1.254710\n2.383013\n0.978524\n2.745955\n1.923409\n1.194165\n1.793615\n0.785669\n0.374648\n1.989626\n3.421168\n2.360255\n0.441367\n2.033105\n3.299585\n1.283497\n1.845475\n1.331906\n1.425406\n2.937331\n0.823984\n2.306800\n2.113772\n2.127941\n1.507769\n\n\n\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nload(\"../data/df_cfa_exercise.RData\")\nhead(df_cfa_exercise)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nx1_t1\nx1_t2\nx1_t3\nx1_t4\nx1_t5\nx1_t6\nx1_t7\nx1_t8\nx1_t9\nx1_t10\nx2_t1\nx2_t2\nx2_t3\nx2_t4\nx2_t5\nx2_t6\nx2_t7\nx2_t8\nx2_t9\nx2_t10\nx3_t1\nx3_t2\nx3_t3\nx3_t4\nx3_t5\nx3_t6\nx3_t7\nx3_t8\nx3_t9\nx3_t10\nx4_t1\nx4_t2\nx4_t3\nx4_t4\nx4_t5\nx4_t6\nx4_t7\nx4_t8\nx4_t9\nx4_t10\nx5_t1\nx5_t2\nx5_t3\nx5_t4\nx5_t5\nx5_t6\nx5_t7\nx5_t8\nx5_t9\nx5_t10\ny1_t1\ny1_t2\ny1_t3\ny1_t4\ny1_t5\ny1_t6\ny1_t7\ny1_t8\ny1_t9\ny1_t10\ny2_t1\ny2_t2\ny2_t3\ny2_t4\ny2_t5\ny2_t6\ny2_t7\ny2_t8\ny2_t9\ny2_t10\ny3_t1\ny3_t2\ny3_t3\ny3_t4\ny3_t5\ny3_t6\ny3_t7\ny3_t8\ny3_t9\ny3_t10\ny4_t1\ny4_t2\ny4_t3\ny4_t4\ny4_t5\ny4_t6\ny4_t7\ny4_t8\ny4_t9\ny4_t10\ny5_t1\ny5_t2\ny5_t3\ny5_t4\ny5_t5\ny5_t6\ny5_t7\ny5_t8\ny5_t9\ny5_t10\n\n\n\n\n1\n4.927017\n3.484359\n5.209319\n3.777327\n2.822955\n2.874990\n4.399279\n3.999338\n2.829229\n4.534257\n3.569244\n3.716360\n4.025572\n2.601702\n4.917407\n4.417907\n5.836183\n2.584864\n2.416726\n3.428733\n3.123268\n2.200183\n2.416466\n2.600930\n2.179303\n3.370835\n5.833981\n3.574207\n2.399534\n1.756436\n5.759150\n4.865658\n5.106690\n4.142291\n4.984553\n4.902819\n7.088255\n6.024145\n4.119966\n4.134776\n4.700258\n3.579269\n5.881804\n4.111085\n4.600078\n4.055922\n4.496880\n4.373719\n4.322336\n3.912015\n4.329297\n3.597471\n3.552542\n3.052100\n2.592308\n3.082656\n4.184377\n4.064089\n3.642032\n2.777390\n4.477198\n4.454955\n4.760682\n3.288172\n5.678996\n4.679951\n4.928690\n5.166207\n3.485148\n3.454632\n2.848577\n5.551165\n3.769263\n3.649328\n2.271035\n5.264214\n3.832915\n3.875455\n2.525079\n1.163129\n4.678402\n4.682683\n3.607138\n4.363976\n3.401883\n5.139966\n5.210060\n4.713772\n3.424733\n2.631818\n3.480544\n3.221823\n3.853132\n3.120772\n3.842651\n2.815425\n3.273848\n3.126467\n3.647887\n3.895862\n\n\n2\n5.024072\n2.470240\n2.259750\n3.383971\n3.405628\n2.925394\n3.722530\n3.104064\n4.068848\n2.923166\n3.661601\n3.732475\n2.084769\n3.978517\n2.855392\n3.381118\n3.865699\n3.911571\n3.102266\n2.858461\n5.186708\n1.540100\n3.453976\n1.671304\n4.397883\n4.996236\n3.609226\n2.266511\n5.332266\n5.041631\n2.577130\n1.182058\n2.648178\n2.580964\n4.378121\n2.015839\n2.477425\n2.718602\n2.512741\n3.104794\n2.425656\n2.302399\n1.261294\n2.294336\n0.776553\n3.169805\n2.850572\n2.683466\n2.756426\n3.199966\n3.488302\n3.348598\n1.567981\n2.689270\n2.093631\n0.946151\n2.760766\n1.974521\n0.788326\n1.546632\n3.613495\n3.002835\n2.618250\n3.474268\n4.107470\n3.950412\n3.461374\n3.162900\n2.504398\n3.957139\n3.269670\n2.924702\n2.951385\n1.403080\n1.747677\n3.671060\n2.755273\n2.860291\n3.582403\n2.855433\n4.296437\n4.459933\n3.877955\n3.542746\n4.623289\n5.768592\n2.820453\n4.347125\n5.008321\n5.628651\n3.446137\n3.354074\n0.216899\n1.984132\n2.551348\n1.010641\n3.200017\n1.600360\n1.541323\n3.561905\n\n\n3\n3.661946\n4.515898\n2.627455\n2.097116\n3.295632\n4.674215\n3.854248\n3.430167\n3.423922\n4.346313\n3.369146\n2.583655\n2.805899\n2.629365\n2.759572\n2.753171\n1.063016\n2.180655\n3.397097\n3.797167\n3.784757\n3.774945\n1.163201\n2.880376\n2.329117\n5.686030\n3.881392\n3.907517\n3.697921\n3.270770\n2.040071\n4.645036\n2.312931\n2.106188\n3.517961\n3.099783\n3.312862\n4.134669\n3.522531\n2.951239\n3.113105\n2.513375\n2.887626\n4.867711\n4.787919\n2.084980\n4.140326\n3.036390\n4.304286\n3.375258\n1.956426\n2.710257\n2.345528\n2.025919\n1.763310\n1.487463\n1.435715\n3.255219\n3.430917\n2.560493\n2.972647\n3.841999\n2.321647\n5.547948\n2.755463\n3.135102\n1.252126\n1.455243\n0.126571\n0.754453\n3.451330\n2.634979\n2.051891\n3.677636\n4.382111\n0.630656\n2.520796\n2.908761\n-0.251480\n1.706827\n4.334217\n3.310795\n3.634877\n3.788040\n3.997747\n3.418240\n1.451858\n5.332129\n3.107325\n2.796257\n3.441736\n1.732713\n4.678564\n3.527282\n4.910696\n3.960887\n2.782757\n3.427556\n4.629581\n4.084214\n\n\n4\n1.933604\n1.835414\n4.246882\n3.229524\n2.456309\n2.818070\n2.602155\n3.215303\n4.200392\n2.272876\n0.706912\n-0.801259\n1.640656\n1.587674\n1.470820\n2.430678\n1.819882\n1.695119\n1.338284\n0.605444\n0.133074\n0.158037\n1.792941\n1.790514\n1.269408\n3.353523\n2.179509\n1.409529\n0.888444\n1.224938\n0.326793\n0.174798\n2.335327\n1.525558\n-0.955707\n3.610542\n1.960530\n-0.865120\n1.385375\n1.430312\n0.685265\n-0.230309\n0.633548\n1.199429\n0.310757\n2.375445\n1.869323\n0.641068\n1.674369\n1.870899\n3.087726\n0.985564\n0.784520\n2.725897\n0.850097\n0.685824\n1.168844\n-0.239602\n2.799497\n2.131838\n1.596182\n1.458913\n3.630159\n2.387079\n0.462230\n0.650202\n2.356301\n0.755215\n2.026497\n2.441231\n2.790539\n2.575200\n3.509842\n3.116568\n3.452843\n3.093494\n1.836035\n2.222184\n2.761235\n4.237117\n3.075454\n1.881486\n2.553940\n1.045851\n3.202694\n4.161503\n2.702880\n0.817310\n2.733675\n1.369864\n0.687845\n2.150121\n1.293763\n0.737558\n0.793559\n1.293628\n1.312178\n-1.925199\n0.168729\n1.409099\n\n\n5\n2.274807\n2.908011\n3.179267\n2.941155\n3.710268\n2.717757\n3.510822\n1.550497\n2.728217\n4.947419\n4.312907\n1.624997\n3.450676\n3.296389\n4.639991\n4.428850\n4.773291\n2.273139\n2.820446\n3.868664\n4.675249\n2.412898\n3.691474\n4.295843\n4.288994\n3.679321\n3.664403\n3.449730\n4.627416\n5.374093\n3.114936\n0.937293\n3.231832\n2.031238\n2.033217\n0.704127\n1.766480\n1.422281\n1.951835\n3.429262\n2.336261\n3.616157\n3.631813\n3.258421\n5.976209\n4.089613\n2.896231\n4.596477\n4.129096\n7.093438\n3.593002\n3.190479\n2.211968\n2.500292\n3.999353\n2.826291\n2.768957\n2.979500\n3.155079\n3.074007\n2.688911\n2.680939\n4.108605\n2.347372\n3.353903\n3.417996\n3.602248\n3.722665\n1.867266\n4.398309\n2.672452\n3.234202\n4.512234\n1.011391\n2.736290\n2.495329\n2.283781\n0.979636\n2.101990\n3.646597\n4.168885\n6.011056\n5.576807\n4.452524\n5.109755\n3.539751\n5.203918\n6.884093\n6.758122\n4.835822\n1.016782\n1.853578\n2.498811\n3.096292\n2.572159\n2.496271\n1.515257\n1.183772\n3.329594\n2.744476\n\n\n6\n3.184660\n4.046734\n3.540150\n4.059281\n2.374465\n2.067087\n3.390182\n3.492470\n3.661657\n1.892471\n2.910669\n2.351059\n0.726541\n1.928325\n-0.062322\n1.306896\n0.272615\n1.463914\n2.076900\n2.569456\n5.019716\n2.328710\n2.837884\n4.043339\n1.947459\n2.449519\n3.065598\n4.321089\n2.036927\n1.389769\n3.537501\n4.318936\n1.631771\n3.685972\n3.609319\n1.645394\n2.917829\n2.317283\n2.267146\n3.963144\n3.536972\n3.295575\n3.075710\n3.460675\n3.224478\n1.660497\n3.093049\n2.421162\n2.188736\n3.557481\n0.309582\n1.857645\n1.819382\n1.085073\n2.427644\n1.988539\n2.246552\n2.295530\n1.075097\n1.388195\n1.656496\n1.752528\n2.418624\n1.340024\n0.824050\n0.698072\n1.970136\n2.064690\n1.795599\n4.439921\n1.967216\n0.477582\n1.303589\n0.223835\n1.302689\n1.254710\n2.383013\n0.978524\n2.745955\n1.923409\n1.194165\n1.793615\n0.785669\n0.374648\n1.989626\n3.421168\n2.360255\n0.441367\n2.033105\n3.299585\n1.283497\n1.845475\n1.331906\n1.425406\n2.937331\n0.823984\n2.306800\n2.113772\n2.127941\n1.507769\n\n\n\n\n\n# 1. Daten in Langformat transformieren - funktionen: pivot_longer(), pivot_wider()\ndf_uebung_superlang &lt;- df_cfa_exercise |&gt; \n  pivot_longer(\n    cols = -id, # All columns except id\n    names_to = c(\"variable\", \"time\"),\n    names_sep = \"_t\"\n  ) \ndf_uebung_lang &lt;- df_uebung_superlang |&gt; \n  pivot_wider(names_from = variable,\n              values_from = value) |&gt; \n  mutate(time = as.numeric(time)) \n\n# 2. Skalenscores für X und Y erstellen - funktionen: group_by(), summarise()\ndf_uebung_lang_scores &lt;- df_uebung_lang |&gt; group_by(id, time) |&gt; \n  summarise(\n    x = rowMeans(across(starts_with(\"x\")), na.rm = TRUE),\n    y = rowMeans(across(starts_with(\"y\")), na.rm = TRUE),\n    .groups = \"drop\" # group_by() wieder aufheben für den finalen Datensatz\n  )\n\n# 3. Skalenscores für X und Y zentrieren - Funktionen: de_mean()\ndf_uebung_lang_scores &lt;- df_uebung_lang_scores |&gt; \n  de_mean(x, y, grp = \"id\")\n\n\nhead(df_uebung_lang_scores)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\ntime\nx\ny\nx_dm\ny_dm\nx_gm\ny_gm\n\n\n\n\n1\n1\n4.415787\n3.962804\n0.3959958\n0.1601657\n4.019792\n3.802638\n\n\n1\n2\n3.569166\n4.301619\n-0.4506258\n0.4989815\n4.019792\n3.802638\n\n\n1\n3\n4.527970\n3.908551\n0.5081786\n0.1059135\n4.019792\n3.802638\n\n\n1\n4\n3.446667\n3.494870\n-0.5731246\n-0.3077683\n4.019792\n3.802638\n\n\n1\n5\n3.900859\n3.557375\n-0.1189324\n-0.2452633\n4.019792\n3.802638\n\n\n1\n6\n3.924495\n4.196442\n-0.0952970\n0.3938045\n4.019792\n3.802638",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Kapitel 1: Datenaufbereitung</span>"
    ]
  },
  {
    "objectID": "01 Data Preparation Item Level.html#abspeichern-der-gebildeten-skalen",
    "href": "01 Data Preparation Item Level.html#abspeichern-der-gebildeten-skalen",
    "title": "2  Kapitel 1: Datenaufbereitung",
    "section": "2.9 Abspeichern der gebildeten Skalen",
    "text": "2.9 Abspeichern der gebildeten Skalen\nZum Schluss speichern wir die Ergebnisse (sowohl die Items als auch die Skalen in Langformat) der Übung ab.\n\nsave(df_uebung_lang, df_uebung_lang_scores, file = \"../data/df_uebung.RData\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Kapitel 1: Datenaufbereitung</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Tagebuchstudien und Mehrebenenmodelle",
    "section": "",
    "text": "1 Einleitung\nDieses Dokument enthält Anleitungen und Übungen zur Analyse von Daten aus Tagebuchstudien mittels Mehrebenenmodellen. Es ist im Rahmen des Seminars zu Tagebuchstudien in Psychologie an der Uni Bern entstanden.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Einleitung</span>"
    ]
  },
  {
    "objectID": "index.html#voraussetzungen",
    "href": "index.html#voraussetzungen",
    "title": "Tagebuchstudien und Mehrebenenmodelle",
    "section": "1.1 Voraussetzungen",
    "text": "1.1 Voraussetzungen\nMaterialien:\n\nRStudio (erstellt RStudio 2024.12.0, Build 467)\nR (erstellt mit R 4.4.2)\nInstallation von Paketen mit dem Code unten.\n\nKenntnisse:\n\nData Wrangling in R, Umgang mit R-Notebooks, s. Anhang: Data Wrangling, sowie https://methodenlehre.github.io/einfuehrung-in-R/\nStatistisches Wissen zu linearen Modellen (Regressionen) und Testkonstruktion (Likert-Skalen, Reliabilitätsanalyse)\n\n\n1.1.1 Installation von R-Paketen, die im Kurs verwendet werden\nDer Code unten installiert, falls noch nicht vorhanden, den “pacman” Paketmanager und danach alle R-Pakete, die für den Kurs benötigt werden.\n\nif (!require(\"pacman\")) install.packages(\"pacman\")\n\npacman::p_load(devtools)\ndevtools::install_github(\"falkcarl/multilevelmediation\")\n\npacman::p_load(lmerTest, haven, brms, psych,\n               sjmisc, sjlabelled, sjPlot, writexl, broom.mixed, qgraph,\n               tidyverse, multilevelTools, parameters, devtools,\n               multilevelmediation)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Einleitung</span>"
    ]
  },
  {
    "objectID": "02 Descriptive Statistics.html",
    "href": "02 Descriptive Statistics.html",
    "title": "3  Kapitel 2: Deskriptive Analysen und Überprüfung von Voraussetzungen",
    "section": "",
    "text": "3.1 Pakete laden\nif (!require(\"pacman\")) install.packages(\"pacman\")\n\nLoading required package: pacman\n\nif (!require(\"franzpak\")) devtools::install_github(\"franciscowilhelm/franzpak\")\n\nLoading required package: franzpak\n\npacman::p_load(haven, psych,\n               sjmisc, sjPlot, writexl, lavaan,\n               tidyverse, multilevelTools, franzpak)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Kapitel 2: Deskriptive Analysen und Überprüfung von Voraussetzungen</span>"
    ]
  },
  {
    "objectID": "02 Descriptive Statistics.html#daten-laden",
    "href": "02 Descriptive Statistics.html#daten-laden",
    "title": "3  Kapitel 2: Deskriptive Analysen und Überprüfung von Voraussetzungen",
    "section": "3.2 Daten laden",
    "text": "3.2 Daten laden\n\nload(\"../data/df_cfa_long.RData\")\n\nhead(df_cfa_long_scores)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\ntime\na\nb\nc\na_dm\nb_dm\nc_dm\na_gm\nb_gm\nc_gm\n\n\n\n\n1\n1\n3.576438\n2.0153094\n3.059581\n-0.2566380\n0.4476044\n-0.5267811\n3.833076\n1.567705\n3.586362\n\n\n1\n2\n3.618275\n1.6847458\n4.229828\n-0.2148012\n0.1170408\n0.6434662\n3.833076\n1.567705\n3.586362\n\n\n1\n3\n2.365406\n0.3495072\n2.465712\n-1.4676704\n-1.2181978\n-1.1206501\n3.833076\n1.567705\n3.586362\n\n\n1\n4\n3.604362\n1.4354944\n2.848375\n-0.2287140\n-0.1322106\n-0.7379871\n3.833076\n1.567705\n3.586362\n\n\n1\n5\n3.881178\n1.2395786\n3.159797\n0.0481014\n-0.3281264\n-0.4265645\n3.833076\n1.567705\n3.586362\n\n\n1\n6\n4.172778\n1.3404398\n4.261824\n0.3397012\n-0.2272652\n0.6754625\n3.833076\n1.567705\n3.586362\n\n\n\n\n\n\nSchauen wir uns nochmal die Datenstruktur unseres aufbereiteten Datensatzes an. Wir haben die Variablen:\n\nid: Gruppierungsvariable / Personen-ID, von 1 - 100\ntime: Zeitpunkt / Tag der Messung, von 1-10\na, b, c: Rohvariablen\na_dm - c_dm: Personen-zentrierte Variablen\na_gm - c_gm : Personen-Mittelwerte",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Kapitel 2: Deskriptive Analysen und Überprüfung von Voraussetzungen</span>"
    ]
  },
  {
    "objectID": "02 Descriptive Statistics.html#icc-und-within-person-variance",
    "href": "02 Descriptive Statistics.html#icc-und-within-person-variance",
    "title": "3  Kapitel 2: Deskriptive Analysen und Überprüfung von Voraussetzungen",
    "section": "3.3 ICC und Within-Person Variance",
    "text": "3.3 ICC und Within-Person Variance\nUns interessiert wie gross der Anteil der Varianz ist, der jeweils auf die zwei Ebenen der Daten entfallen (Inner-Person, Zwischen-Person-Ebene). Dies kann uns der ICC angeben. Mittels der Funktion statsBy() bekommen wir einige Analysen zu unseren Mehrebenen-Daten geliefert. Die Funktion benötigt zwei Argumente: den Datensatz und und die Gruppierungsvariable. Wir wählen entsprechend in select() die Variablen, die uns interessieren. Dies sind die Gruppierungsvariable “id” und die Rohvarianten der Variablen aus, da nur diese die Informationen über beide Ebenen enthalten (personen-zentrierte Variablen beinhalten nur Varianz auf Inner-Person-Ebene, Personen-Mittelwerte nur Varianz auf Zwischen-Person-Ebene). Die zerlegten Variablen mit den Kürzeln _dm und _gm brauchen wir erst später.\n\nmehrebenen_stats &lt;- df_cfa_long_scores |&gt; \n  select(id, a, b, c) |&gt; \n    statsBy(group = \"id\")\n\nWir bekommen hier manchmal Warnungen, wenn wir auch reine Level-2 Variablen eingeschlossen haben. Dies können wir jedoch ignorieren. Mit print() bekommen wir eine Übersicht über die Ergebnisse der Resultate der statsBy() Funktion.\n\nprint(mehrebenen_stats)\n\nStatistics within and between groups  \nCall: statsBy(data = select(df_cfa_long_scores, id, a, b, c), group = \"id\")\nIntraclass Correlation 1 (Percentage of variance due to groups) \n  id    a    b    c \n1.00 0.49 0.55 0.47 \nIntraclass Correlation 2 (Reliability of group differences) \n  id    a    b    c \n1.00 0.91 0.92 0.90 \neta^2 between groups  \na.bg b.bg c.bg \n0.54 0.59 0.52 \n\nTo see the correlations between and within groups, use the short=FALSE option in your print statement.\nMany results are not shown directly. To see specific objects select from the following list:\n mean sd n F ICC1 ICC2 ci1 ci2 raw rbg ci.bg pbg rwg nw ci.wg pwg etabg etawg nwg nG Call\n\n\nUns interessiert nur die Intraclass Correlation 1. Intraclass Correlation (2) und Eta-Quadrat interessieren uns nicht.\nDen ICC können wir uns auch direkt angeben lassen, indem wir aus dem Listenobjekt mehrebenen_stats mit dem Dollarzeichen $ die Untervariable ICC1 anwählen.\n\nicc &lt;- mehrebenen_stats$ICC1 |&gt; \n  round(2) # runden\nicc\n\n  id    a    b    c \n1.00 0.49 0.55 0.47 \n\n\nAlle Skalen im Beispiel haben ICCs in einem angemessenen Bereich (&lt;.80). Dies heisst, dass genug tägliche Varianz vorhanden ist, um Mehrebenen-Analysen durchzuführen.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Kapitel 2: Deskriptive Analysen und Überprüfung von Voraussetzungen</span>"
    ]
  },
  {
    "objectID": "02 Descriptive Statistics.html#reliabilitätsanalyse",
    "href": "02 Descriptive Statistics.html#reliabilitätsanalyse",
    "title": "3  Kapitel 2: Deskriptive Analysen und Überprüfung von Voraussetzungen",
    "section": "3.4 Reliabilitätsanalyse",
    "text": "3.4 Reliabilitätsanalyse\nDie Reliabilitätsanalyse basiert auf den Items, nicht auf den Skalenwerten. Diese haben wir im df_cfa_long Dataframe abgespeichert.\n\nhead(df_cfa_long)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\ntime\na1\na2\na3\na4\na5\nb1\nb2\nb3\nb4\nb5\nc1\nc2\nc3\n\n\n\n\n1\n1\n3.336252\n3.380463\n3.223528\n4.399347\n3.542602\n3.370896\n1.697640\n0.584167\n1.576649\n2.847195\n4.325797\n1.030847\n3.822098\n\n\n1\n2\n2.149828\n5.110309\n5.678413\n2.765556\n2.387270\n2.486919\n0.952220\n2.101517\n0.331000\n2.552073\n3.364003\n5.711729\n3.613752\n\n\n1\n3\n1.613518\n3.004133\n2.503233\n1.898476\n2.807670\n0.991958\n-0.685685\n0.003147\n-0.517730\n1.955846\n2.582169\n2.659834\n2.155132\n\n\n1\n4\n3.351085\n3.852294\n4.972103\n2.612551\n3.233779\n2.248097\n0.004118\n0.711264\n2.185949\n2.028044\n2.918614\n3.163276\n2.463234\n\n\n1\n5\n3.320900\n3.694431\n4.703663\n3.476859\n4.210036\n1.953658\n0.675750\n0.921623\n0.284884\n2.361978\n2.829237\n3.910432\n2.739723\n\n\n1\n6\n4.173775\n5.658948\n3.273027\n4.192700\n3.565438\n1.544111\n-0.373186\n1.303905\n1.687402\n2.539967\n4.141474\n5.234767\n3.409232\n\n\n\n\n\n\nBei täglich erhobenen Skalen nehmen wir die omegaSEM() Funktion. Als erstes Argument geben wir die Items in einem Character-Vector mittels c(), die Items werden mit Anführungszeichen angegeben. Falls ihr die Itemnamen nicht wisst, könnt ihr sie mit names(df_cfa_long) nachsehen.\n\nscalea_reliab &lt;- omegaSEM(\n  items = c(\"a1\", \"a2\", \"a3\", \"a4\", \"a5\"),\n  id = \"id\",\n  data = df_cfa_long)\nscalea_reliab$Results\n\n\n\n\n\n\nlabel\nest\nci.lower\nci.upper\n\n\n\n\n42\nomega_within\n0.7390195\n0.7120809\n0.7659581\n\n\n50\nomega_between\n0.8480644\n0.7955281\n0.9006008\n\n\n\n\n\n\nHier erscheint teils eine Warnung, weil nicht alle Personen (cluster) Varianz auf den Items haben. Dies können wir ignorieren. In den simulierten Daten, die wir verwenden, ist dies jedoch nicht der Fall. Dann können wir den Output ansehen. Omega_within gibt die Reliabilität für Unterschiede innerhalb der Person an, und Omega_between gibt die Reliabilität für Unterschiede zwischen Personen an. Die Reliabilitäten sollten über .70 liegen für eine gute Reliabilität auf beiden Leveln.\n\nscaleb_reliab &lt;- omegaSEM(\n  items = c(\"b1\", \"b2\", \"b3\", \"b4\", \"b5\"),\n  id = \"id\",\n  data = df_cfa_long)\n\nscaleb_reliab$Results\n\n\n\n\n\n\nlabel\nest\nci.lower\nci.upper\n\n\n\n\n42\nomega_within\n0.7439948\n0.7175652\n0.7704245\n\n\n50\nomega_between\n0.8884161\n0.8502350\n0.9265972\n\n\n\n\n\n\n\nscalec_reliab &lt;- omegaSEM(\n  items = c(\"c1\", \"c2\", \"c3\"),\n  id = \"id\",\n  data = df_cfa_long)\n\nscalec_reliab$Results\n\n\n\n\n\n\nlabel\nest\nci.lower\nci.upper\n\n\n\n\n28\nomega_within\n0.6276604\n0.5854945\n0.6698263\n\n\n34\nomega_between\n0.7638922\n0.6728196\n0.8549647",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Kapitel 2: Deskriptive Analysen und Überprüfung von Voraussetzungen</span>"
    ]
  },
  {
    "objectID": "02 Descriptive Statistics.html#korrelationstabelle",
    "href": "02 Descriptive Statistics.html#korrelationstabelle",
    "title": "3  Kapitel 2: Deskriptive Analysen und Überprüfung von Voraussetzungen",
    "section": "3.5 Korrelationstabelle",
    "text": "3.5 Korrelationstabelle\nIn quantitativ-empirischen psychologischen Artikeln ist (fast) immer die Korrelationstabelle die erste Tabelle des Artikels. Unser nächstes Ziel ist es, eine Korrelationstabelle anzufertigen, in der wir auch die Mittelwerte und Standardabweichungen integrieren.\n\n3.5.1 Mittelwerte\nMittelwerte wurden bereits - pro Person - durch die statsBy() Funktion gebildet. Den allgemeinen Mittelwert bekommen wir mit der Funktion summarise(). Diese erlaubt uns, zusammenfassende Werte zu bilden. Da wir dies gleich für mehrere Variablen machen, benutzen wir zudem across(), um die Summary gleich für mehrere Variablen zu bilden. Die Funktion benötigt als Argumente (a) die Namen der Variablen mit c() als einen Vektor zusammengefasst, (b) die Funktionen, wie sie gebildet werden (hier: ~mean(.x, na.rm = TRUE) für das arithmetische Mittel unter Ausschluss aller nicht vorhandenen Werte) und (c) optional die Namen der ausgegebenen Variablen mittels “.names”. Wir verwenden “m_{.col}”. Abschliessend runden wir die Werte.\nErsetzt im folgenden Code in der Klammer von c() die Variablennamen mit denen, die euch interessieren, hier sowohl die täglichen als auch Baselinevariablen.\n\nmittelwerte &lt;- mehrebenen_stats$mean |&gt; \n  as_tibble() |&gt; \n  summarise(across(c(a,b,c), ~mean(.x, na.rm = TRUE)))\n\nmittelwerte\n\n\n\n\n\na\nb\nc\n\n\n\n\n3.034273\n1.949319\n1.990651\n\n\n\n\n\n\nWir sehen, dass a einen höheren Mittelwert (M = 3.03) als b und c (M = 1.94, M = 1.99) aufweist. Für die Verteilung der Variablen sehen wir uns idealerweise auch Histogramme an.\n\nhist(mehrebenen_stats$mean[,\"a\"])\n\n\n\n\n\n\n\nhist(mehrebenen_stats$mean[,\"b\"])\n\n\n\n\n\n\n\nhist(mehrebenen_stats$mean[,\"c\"])\n\n\n\n\n\n\n\n\nAlle Variablen scheinen vom Histogram her hinreichend normalverteilt.\n\n\n3.5.2 Standardabweichungen\nGanz ähnlich wie mit Mittelwerten verfahren wir für die Standardabweichung, nur dass wir hier als Funktion ~sd(.x, na.rm = TRUE) verwenden. Ersetzt auch hier im folgenden Code in der Klammer von c() die Variablennamen mit denen, die euch interessieren, hier sowohl die täglichen als auch Baselinevariablen. Die Baselinevariable “w” zeigt hier keine SD mit dieser Berechnung und muss separat berechnet werden.\n\nstandardabweichung &lt;- mehrebenen_stats$sd |&gt; \n  as_tibble() |&gt; \n  summarise(across(c(a, b, c), ~mean(.x, na.rm = TRUE)))\nstandardabweichung\n\n\n\n\n\na\nb\nc\n\n\n\n\n0.6875217\n0.6956185\n0.7549543\n\n\n\n\n\n\n\n\n3.5.3 Korrelationen\nWir wollen eine Korrelationstabelle, in der wir auf einen Blick sowohl die Zwischen-Person-Korrelationen als auch die Inner-Person-Korrelationen sehen. Die statsBy() Funktion, die wir bereits aufgerufen haben, gibt uns beides separat aus. und\n\nmehrebenen_stats$rbg |&gt; round(2) # Zwischen Person Kor.\n\n     a.bg b.bg c.bg\na.bg 1.00 0.32 0.39\nb.bg 0.32 1.00 0.29\nc.bg 0.39 0.29 1.00\n\nmehrebenen_stats$rwg |&gt; round(2) # Inner Person Kor.\n\n     a.wg b.wg c.wg\na.wg 1.00 0.22 0.25\nb.wg 0.22 1.00 0.29\nc.wg 0.25 0.29 1.00\n\n\nWir erhalten im unteren Dreieck die Inner-Person-Korrelationen, und im oberen Dreieck die Zwischen-Person-Korrelationen.\n\n\n3.5.4 Integration in Tabelle\nJetzt gilt es, die Mittelwerte, Standardabweichungen, ICCs, und Korrelationen Zwischen und Innerhalb von Personen in einer Tabelle zu integrieren. Mit der tibble() Funktion bauen wir einen neue Datensatz-Tabelle, in der wir alle Variablen integrieren.\nDie vorhergehenden Analysen zeigen wie man die einzelnen Komponenten der Tabelle erstellt. Die Funktion cortable_multilevel() führt die einzelnen Funktionen direkt zusammen.\n\ncortable_integriert &lt;- cortable_multilevel(df_cfa_long_scores, c(\"a\", \"b\", \"c\"), grp = \"id\")\ncortable_integriert\n\n\n\n\n\nVariable\nM\nSD\nICC\n1.\n2.\n3.\n\n\n\n\n1.a\n3.03\n0.99\n.49\n-\n.32**\n.39***\n\n\n2.b\n1.95\n1.07\n.55\n.22***\n-\n.29**\n\n\n3.c\n1.99\n1.06\n.47\n.25***\n.29***\n-\n\n\n\n\n\n\n\n\n3.5.5 Export von Tabellen zu Excel\nWir exportieren die Korrelationstabelle nach Excel mittels write_xlsx().\n\n# eval: false\nwrite_xlsx(cortable_integriert, path = \"korrelationstabelle.xlsx\")\n\nDie Excel-Tabelle lässt sich dann in Word kopieren und weiter verarbeitet werden, z.B. mit den richtigen Variablennamen versehen werden etc. Damit haben wir nun die Datenaufbereitung und deskriptive Datenanalyse abgeschlossen.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Kapitel 2: Deskriptive Analysen und Überprüfung von Voraussetzungen</span>"
    ]
  },
  {
    "objectID": "02 Descriptive Statistics.html#blick-hinter-die-kulissen-berechnung-von-omega-mittels-einer-mehrebenen-konfirmatorischen-faktorenanalysen",
    "href": "02 Descriptive Statistics.html#blick-hinter-die-kulissen-berechnung-von-omega-mittels-einer-mehrebenen-konfirmatorischen-faktorenanalysen",
    "title": "3  Kapitel 2: Deskriptive Analysen und Überprüfung von Voraussetzungen",
    "section": "4.2 Blick hinter die Kulissen: Berechnung von Omega mittels einer Mehrebenen konfirmatorischen Faktorenanalysen",
    "text": "4.2 Blick hinter die Kulissen: Berechnung von Omega mittels einer Mehrebenen konfirmatorischen Faktorenanalysen\nFür eine genauere Auswertung können wir omegaSEM() mit dem Parameter savemodel = TRUE laufen lassen und uns mittels summary() die konfirmatorische Faktoranalyse (CFA) genauer ansehen.\nWie CFAs funktionieren, kann hier repetiert werden: Statistik IV - Methodenlehre\nZudem können wir uns mit lavInspect() die Modellparameter ansehen, um zu verstehen wie die Reliabilitätskoeffizient gebildet wird.\n\nscalec_reliab &lt;- omegaSEM(c(\"c1\", \"c2\", \"c3\"), \"id\", df_cfa_long, savemodel = TRUE)\nscalec_reliab$Fit |&gt; summary(fit = TRUE, stand = TRUE)\n\nlavaan 0.6-18 ended normally after 32 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        15\n  Number of inequality constraints                   6\n\n  Number of observations                          1000\n  Number of clusters [id]                          100\n\nModel Test User Model:\n                                                      \n  Test statistic                                 0.000\n  Degrees of freedom                                 0\n\nModel Test Baseline Model:\n\n  Test statistic                               383.809\n  Degrees of freedom                                 6\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    1.000\n  Tucker-Lewis Index (TLI)                       1.000\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -4446.130\n  Loglikelihood unrestricted model (H1)      -4446.130\n                                                      \n  Akaike (AIC)                                8922.260\n  Bayesian (BIC)                              8995.876\n  Sample-size adjusted Bayesian (SABIC)       8948.235\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.000\n  90 Percent confidence interval - lower         0.000\n  90 Percent confidence interval - upper         0.000\n  P-value H_0: RMSEA &lt;= 0.050                       NA\n  P-value H_0: RMSEA &gt;= 0.080                       NA\n\nStandardized Root Mean Square Residual (corr metric):\n\n  SRMR (within covariance matrix)                0.000\n  SRMR (between covariance matrix)               0.000\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Observed\n  Observed information based on                Hessian\n\n\nLevel 1 [within]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  f_within =~                                                           \n    c1       (wl1)    0.596    0.043   13.816    0.000    0.596    0.595\n    c2       (wl2)    0.653    0.046   14.176    0.000    0.653    0.622\n    c3       (wl3)    0.587    0.043   13.605    0.000    0.587    0.580\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n    f_within          1.000                               1.000    1.000\n   .c1       (wr1)    0.648    0.048   13.565    0.000    0.648    0.645\n   .c2       (wr2)    0.675    0.054   12.435    0.000    0.675    0.613\n   .c3       (wr3)    0.677    0.048   14.183    0.000    0.677    0.663\n\n\nLevel 2 [id]:\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  f_between =~                                                          \n    c1       (bl1)    0.529    0.095    5.570    0.000    0.529    0.660\n    c2       (bl2)    0.704    0.106    6.614    0.000    0.704    0.803\n    c3       (bl3)    0.680    0.115    5.905    0.000    0.680    0.694\n\nIntercepts:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .c1                2.003    0.086   23.252    0.000    2.003    2.500\n   .c2                1.948    0.094   20.798    0.000    1.948    2.224\n   .c3                2.021    0.103   19.615    0.000    2.021    2.063\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n    f_betwen          1.000                               1.000    1.000\n   .c1       (br1)    0.362    0.081    4.446    0.000    0.362    0.564\n   .c2       (br2)    0.272    0.107    2.536    0.011    0.272    0.355\n   .c3       (br3)    0.497    0.120    4.132    0.000    0.497    0.518\n\nDefined Parameters:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n    num_within        3.371    0.262   12.875    0.000    3.371    3.233\n    denom_within      5.370    0.253   21.213    0.000    5.370    5.155\n    omega_within      0.628    0.022   29.175    0.000    0.628    0.627\n    num_between       3.659    0.764    4.787    0.000    3.659    4.657\n    denom_between     4.789    0.754    6.354    0.000    4.789    6.094\n    omega_between     0.764    0.046   16.440    0.000    0.764    0.764\n\nConstraints:\n                                               |Slack|\n    wr1 - 0                                      0.648\n    wr2 - 0                                      0.675\n    wr3 - 0                                      0.677\n    br1 - 0                                      0.362\n    br2 - 0                                      0.272\n    br3 - 0                                      0.497\n\nlavInspect(scalec_reliab$Fit, \"list\") |&gt; \n  select(lhs, op, rhs, free, level, free, label, est, se) |&gt; \n  mutate(across(where(is.numeric), round, 2)) # alternatively, parTable()\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `across(where(is.numeric), round, 2)`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlhs\nop\nrhs\nfree\nlevel\nlabel\nest\nse\n\n\n\n\nf_within\n=~\nc1\n1\n1\nwl1\n0.60\n0.04\n\n\nf_within\n=~\nc2\n2\n1\nwl2\n0.65\n0.05\n\n\nf_within\n=~\nc3\n3\n1\nwl3\n0.59\n0.04\n\n\nf_within\n~~\nf_within\n0\n1\n\n1.00\n0.00\n\n\nc1\n~~\nc1\n4\n1\nwr1\n0.65\n0.05\n\n\nc2\n~~\nc2\n5\n1\nwr2\n0.68\n0.05\n\n\nc3\n~~\nc3\n6\n1\nwr3\n0.68\n0.05\n\n\nc1\n~1\n\n0\n1\n\n0.00\n0.00\n\n\nc2\n~1\n\n0\n1\n\n0.00\n0.00\n\n\nc3\n~1\n\n0\n1\n\n0.00\n0.00\n\n\nf_within\n~1\n\n0\n1\n\n0.00\n0.00\n\n\nf_between\n=~\nc1\n7\n2\nbl1\n0.53\n0.10\n\n\nf_between\n=~\nc2\n8\n2\nbl2\n0.70\n0.11\n\n\nf_between\n=~\nc3\n9\n2\nbl3\n0.68\n0.12\n\n\nf_between\n~~\nf_between\n0\n2\n\n1.00\n0.00\n\n\nc1\n~~\nc1\n10\n2\nbr1\n0.36\n0.08\n\n\nc2\n~~\nc2\n11\n2\nbr2\n0.27\n0.11\n\n\nc3\n~~\nc3\n12\n2\nbr3\n0.50\n0.12\n\n\nc1\n~1\n\n13\n2\n\n2.00\n0.09\n\n\nc2\n~1\n\n14\n2\n\n1.95\n0.09\n\n\nc3\n~1\n\n15\n2\n\n2.02\n0.10\n\n\nf_between\n~1\n\n0\n2\n\n0.00\n0.00\n\n\nwr1\n&gt;\n0\n0\n0\n\n0.65\n0.00\n\n\nwr2\n&gt;\n0\n0\n0\n\n0.68\n0.00\n\n\nwr3\n&gt;\n0\n0\n0\n\n0.68\n0.00\n\n\nnum_within\n:=\n(wl1+wl2+wl3)^2\n0\n0\nnum_within\n3.37\n0.26\n\n\ndenom_within\n:=\n(wl1+wl2+wl3)^2+(wr1+wr2+wr3)\n0\n0\ndenom_within\n5.37\n0.25\n\n\nomega_within\n:=\nnum_within/denom_within\n0\n0\nomega_within\n0.63\n0.02\n\n\nbr1\n&gt;\n0\n0\n0\n\n0.36\n0.00\n\n\nbr2\n&gt;\n0\n0\n0\n\n0.27\n0.00\n\n\nbr3\n&gt;\n0\n0\n0\n\n0.50\n0.00\n\n\nnum_between\n:=\n(bl1+bl2+bl3)^2\n0\n0\nnum_between\n3.66\n0.76\n\n\ndenom_between\n:=\n(bl1+bl2+bl3)^2+(br1+br2+br3)\n0\n0\ndenom_between\n4.79\n0.75\n\n\nomega_between\n:=\nnum_between/denom_between\n0\n0\nomega_between\n0.76\n0.05\n\n\n\n\n\n\nWie der Output zeigt, ergibt sich die Omega-Reliabilität aus dem Anteil der durch den Faktor (f_within für den Faktor auf Level-1 bzw. f_between für den Faktor auf Level-2) erklärten Varianz der Items (Summe aller Item-Ladungen, quadriert für Varianz) geteilt durch die Gesamtvarianz der Items (durch Faktor erklärte Varianz der Items + Residualvarianz, d.h. übrigbleibende Varianz der Items). Diese Formel wird pro Varianzebene (Level-1, also tägliche Schwankungen innerhalb der Person) und Level-2 (Unterschiede zwischen Personen) getrennt berechnet.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Kapitel 2: Deskriptive Analysen und Überprüfung von Voraussetzungen</span>"
    ]
  },
  {
    "objectID": "02 Descriptive Statistics.html#zusatz",
    "href": "02 Descriptive Statistics.html#zusatz",
    "title": "3  Kapitel 2: Deskriptive Analysen und Überprüfung von Voraussetzungen",
    "section": "4.1 Zusatz",
    "text": "4.1 Zusatz\nDie folgenden Analysen sind optional, geben aber ein tieferes Verständnis des Materials.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Kapitel 2: Deskriptive Analysen und Überprüfung von Voraussetzungen</span>"
    ]
  },
  {
    "objectID": "03 Hypotheses Tests.html",
    "href": "03 Hypotheses Tests.html",
    "title": "4  Kapitel 3: Hypothesentests - Teil 1",
    "section": "",
    "text": "4.1 Vorbereitung\nIn diesem Kapitel verwenden wir verschiedene Regressionsmodelle die zur Überprüfung von Hypothesen eingesetzt werden.\nInstall packages\nif (!require(\"pacman\")) install.packages(\"pacman\")\n\nLoading required package: pacman\n\npacman::p_load(lmerTest, haven, brms, psych,\n               sjmisc, sjPlot, writexl, broom.mixed, qgraph,\n               tidyverse, multilevelTools, parameters)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Kapitel 3: Hypothesentests - Teil 1</span>"
    ]
  },
  {
    "objectID": "03 Hypotheses Tests.html#daten-einlesen",
    "href": "03 Hypotheses Tests.html#daten-einlesen",
    "title": "4  Kapitel 3: Hypothesentests - Teil 1",
    "section": "4.2 Daten einlesen",
    "text": "4.2 Daten einlesen\n\nload(\"../data/df_example1.RData\")\nload(\"../data/df_example1c.RData\")\n\nFür diese Einheit verwenden wir den folgenden Datensatz (data.frame/tibble):\n\ndf_example1: Alle Skalenscores im Long Format, mit personen-zentrierten Variablenvarianten (“_dm”) und Personen-Mittelwerten der täglich gemessenenen Variablen (“_gm”). Struktur des Datensatzes kann man sich ansehen mit head() oder print().\n\n\nhead(df_example1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\ny\nm\nx\ny_dm\nm_dm\nx_dm\ny_gm\nm_gm\nx_gm\n\n\n\n\n1\n4.003538\n4.769391\n2.365486\n-0.3020232\n0.8945291\n0.6845636\n4.305561\n3.874862\n1.680922\n\n\n1\n4.925174\n2.510943\n0.748855\n0.6196128\n-1.3639189\n-0.9320674\n4.305561\n3.874862\n1.680922\n\n\n1\n4.598564\n3.098112\n1.395041\n0.2930028\n-0.7767499\n-0.2858814\n4.305561\n3.874862\n1.680922\n\n\n1\n4.286179\n4.610746\n1.860026\n-0.0193822\n0.7358841\n0.1791036\n4.305561\n3.874862\n1.680922\n\n\n1\n4.183494\n4.549044\n2.288019\n-0.1220672\n0.6741821\n0.6070966\n4.305561\n3.874862\n1.680922\n\n\n1\n3.631716\n3.590049\n1.696510\n-0.6738452\n-0.2848129\n0.0155876\n4.305561\n3.874862\n1.680922\n\n\n\n\n\n\nIm Folgenden betrachten wir ein Modell in dem y durch x vorhergesagt wird.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Kapitel 3: Hypothesentests - Teil 1</span>"
    ]
  },
  {
    "objectID": "03 Hypotheses Tests.html#random-intercept-modell-null-model",
    "href": "03 Hypotheses Tests.html#random-intercept-modell-null-model",
    "title": "4  Kapitel 3: Hypothesentests - Teil 1",
    "section": "4.3 Random Intercept Modell / Null-Model",
    "text": "4.3 Random Intercept Modell / Null-Model\nDie Funktion lmer() benötigt zwei Argumente, (a) die Formel und (b) den Datensatz. Zum Aufbau und Details der Formeln s. Folien.\nLevel 1: \\(y_{ij} = \\beta_{0j} + e_{ij}\\)\nLevel 2 (random intercept): \\(\\beta_{0j} = \\gamma_{00} + u_{0j}\\)\n\nnullmodel &lt;- lmer(y ~ (1 | id), data = df_example1)\n\nZur Ansicht der Ergebnisse haben wir zwei Optionen: Den summary() Befehl - die Standardansicht, wie von den Paketautoren implementiert, den tidy() Befehl aus dem broom-Package, und den model_parameters() Befehl aus dem parameters Package. tidy() und model_parameters() Funktionsoutputs könnten nach Excel/Word exportiert werden mittels der write_xlsx() Funktion, oder indem das Notebook als .docx “gerendert” (ausgegeben) wird.\n\nsummary(nullmodel)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: y ~ (1 | id)\n   Data: df_example1\n\nREML criterion at convergence: 2742.9\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-6.1492 -0.5420 -0.0369  0.5543  4.6493 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n id       (Intercept) 0.6902   0.8308  \n Residual             0.7164   0.8464  \nNumber of obs: 1000, groups:  id, 100\n\nFixed effects:\n            Estimate Std. Error       df t value Pr(&gt;|t|)    \n(Intercept)  5.36755    0.08728 99.00000    61.5   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\ntidy(nullmodel)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\neffect\ngroup\nterm\nestimate\nstd.error\nstatistic\ndf\np.value\n\n\n\n\nfixed\nNA\n(Intercept)\n5.3675530\n0.0872832\n61.49586\n99\n0\n\n\nran_pars\nid\nsd__(Intercept)\n0.8307776\nNA\nNA\nNA\nNA\n\n\nran_pars\nResidual\nsd__Observation\n0.8464254\nNA\nNA\nNA\nNA\n\n\n\n\n\n\n\nmodel_parameters(nullmodel) |&gt; print_html()\n\n\n\n\n\n\n\nModel Summary\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(997)\np\n\n\n\n\nFixed Effects\n\n\n(Intercept)\n5.37\n0.09\n(5.20, 5.54)\n61.50\n&lt; .001\n\n\nRandom Effects\n\n\nSD (Intercept: id)\n0.83\n\n\n\n\n\n\nSD (Residual)\n0.85\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIch bevorzuge persönlich den Output von model_parameters(), aber das ist Geschmackssache.\n\n4.3.1 ICC\nAus dem Null-Model wird der ICC bestimmt. Dies haben wir in der vorhergehenden\nICC: \\(\\frac{\\tau_{00}}{\\tau_{00}+\\tau_{ij}}\\), \\(\\tau\\) gibt die Varianz des jewiligen Koeffizienten an.\nWir können dies aus dem Modelloutput nehmen und berechnen:\n\nmodelsummary &lt;- model_parameters(nullmodel)\ntau00 &lt;- modelsummary$Coefficient[modelsummary$Parameter == \"SD (Intercept)\"]^2\ntauij &lt;- modelsummary$Coefficient[modelsummary$Parameter == \"SD (Observations)\"]^2\ntau00 / (tau00+tauij)\n\n[1] 0.4906711\n\n# performance::icc(nullmodel) # Alternativfunktion\n\n\n\n4.3.2 Visualisierung\nWir können uns die Analysen visualisieren, hier zur reduzierten visuellen Komplexität nur auf Basis der ersten 20 Personen (ID 1-20.)\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nOder zwei Personen, um uns die einzelnen Punkte auch anschauen zu können\n\nggplot(data = df_example1 |&gt; filter(id %in% c(1, 16)), aes(\n  x = x,\n  y = predicted_ri,\n  colour = id\n)) +\n  geom_smooth(method = \"lm\", fullrange = TRUE, se = F, size = 1) +\n  geom_jitter(aes(y = y), alpha = .5, size = 2.5) +\n  labs(x = xlabel, y = ylabel) +\n  ggtitle(\"Intercept-Only-Modell\") +\n  scale_colour_discrete() +\n  geom_abline(intercept = fixef(nullmodel), slope = 0, size = 1.5) +\n  ggthemes::theme_tufte()\n\n`geom_smooth()` using formula = 'y ~ x'",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Kapitel 3: Hypothesentests - Teil 1</span>"
    ]
  },
  {
    "objectID": "03 Hypotheses Tests.html#random-intercept-fixed-slope-modell",
    "href": "03 Hypotheses Tests.html#random-intercept-fixed-slope-modell",
    "title": "4  Kapitel 3: Hypothesentests - Teil 1",
    "section": "4.4 Random Intercept, fixed slope Modell",
    "text": "4.4 Random Intercept, fixed slope Modell\nAls nächstes bauen wir den Prädiktor x ein. Wir verwenden hier die zentrierte Variable “_dm” um Inner-Person Effekte zu berechnen.\nLevel 1: \\(y_{ij} = \\beta_{0j} + \\beta_{1j}*X_{ij} + e_{ij}\\)\nLevel 2 (random intercept): \\(\\beta_{0j} = \\gamma_{00} + u_{0j}\\)\nLevel 2 (fixed effect only): \\(\\beta'_{1j} = \\gamma'_{10}\\)\n\nri.fs_modell &lt;- lmer(y ~ x_dm + (1 | id), data = df_example1)\n\n\nmodel_parameters(ri.fs_modell) |&gt; print_html()\n\n\n\n\n\n\n\nModel Summary\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(996)\np\n\n\n\n\nFixed Effects\n\n\n(Intercept)\n5.37\n0.09\n(5.20, 5.54)\n61.50\n&lt; .001\n\n\nx dm\n0.44\n0.04\n(0.36, 0.51)\n11.63\n&lt; .001\n\n\nRandom Effects\n\n\nSD (Intercept: id)\n0.84\n\n\n\n\n\n\nSD (Residual)\n0.79\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.4.1 Visualisierung\n\n\n`geom_smooth()` using formula = 'y ~ x'",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Kapitel 3: Hypothesentests - Teil 1</span>"
    ]
  },
  {
    "objectID": "03 Hypotheses Tests.html#level-2-prädiktoren",
    "href": "03 Hypotheses Tests.html#level-2-prädiktoren",
    "title": "4  Kapitel 3: Hypothesentests - Teil 1",
    "section": "4.6 Level-2 Prädiktoren",
    "text": "4.6 Level-2 Prädiktoren\nAls nächstes fügen wir einen Level-2 Prädiktor hinzu, der pro Person nur einmal gemessen wurde. Dabei handelt es sich für gewöhnlich um (1) Variablen, bei denen wir nicht an täglichen Schwankungen interessiert sind, wie soziodemografischen oder Persönlichkeitsvariablen, oder (2) den Mittelwert der Personen auf einer täglich gemessenen Variable. Im Beispiel verwenden wir (2), “x_gm”.\nLevel 1: \\(y_{ij} = \\beta_{0j} + \\beta_{1j}*(X_{ij}-\\overline{X_j}) + \\beta_{2j}*\\overline{X_j} + e_{ij}\\)\nLevel 2 (random intercept): \\(\\beta_{0j} = \\gamma_{00} + u_{0j}\\) Level 2 (random slope for x): \\(\\beta_{1j} = \\gamma_{10} + u_{2j}\\)\n\nri.rs_l2_modell &lt;- lmer(y ~ x_dm + x_gm + (1 + x_dm | id), data = df_example1)\nmodel_parameters(ri.rs_l2_modell) |&gt; print_html()\n\n\n\n\n\n\n\nModel Summary\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(993)\np\n\n\n\n\nFixed Effects\n\n\n(Intercept)\n4.47\n0.19\n(4.09, 4.84)\n23.30\n&lt; .001\n\n\nx dm\n0.42\n0.07\n(0.28, 0.56)\n5.85\n&lt; .001\n\n\nx gm\n0.43\n0.08\n(0.26, 0.59)\n5.13\n&lt; .001\n\n\nRandom Effects\n\n\nSD (Intercept: id)\n0.75\n\n\n\n\n\n\nSD (x_dm: id)\n0.63\n\n\n\n\n\n\nCor (Intercept~x_dm: id)\n0.17\n\n\n\n\n\n\nSD (Residual)\n0.65",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Kapitel 3: Hypothesentests - Teil 1</span>"
    ]
  },
  {
    "objectID": "03 Hypotheses Tests.html#random-intercept-random-slope-modell",
    "href": "03 Hypotheses Tests.html#random-intercept-random-slope-modell",
    "title": "4  Kapitel 3: Hypothesentests - Teil 1",
    "section": "4.5 Random intercept, random slope Modell",
    "text": "4.5 Random intercept, random slope Modell\nAls nächstes fügen wir den random slope der Prädiktorvariable x_dm hinzu, in dem wir die random effect Struktur erweitern - “(1 + x_dm | id)”.\nLevel 1: \\(y_{ij} = \\beta_{0j} + \\beta_{1j}*(X_{ij}-\\overline{X_j}) + e_{ij}\\)\nLevel 2 (random intercept): \\(\\beta_{0j} = \\gamma_{00} + u_{0j}\\)\nLevel 2: \\(\\beta'_{1j} = \\gamma'_{10}\\)\n\nri.rs_modell &lt;- lmer(y ~ x_dm + (1 + x_dm | id), data = df_example1)\nmodel_parameters(ri.rs_modell) |&gt; print_html()\n\n\n\n\n\n\n\nModel Summary\n\n\nParameter\nCoefficient\nSE\n95% CI\nt(994)\np\n\n\n\n\nFixed Effects\n\n\n(Intercept)\n5.37\n0.09\n(5.20, 5.54)\n61.50\n&lt; .001\n\n\nx dm\n0.42\n0.07\n(0.28, 0.56)\n5.88\n&lt; .001\n\n\nRandom Effects\n\n\nSD (Intercept: id)\n0.85\n\n\n\n\n\n\nSD (x_dm: id)\n0.63\n\n\n\n\n\n\nCor (Intercept~x_dm: id)\n0.20\n\n\n\n\n\n\nSD (Residual)\n0.65\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.5.1 Visualisierung\n\n\n`geom_smooth()` using formula = 'y ~ x'",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Kapitel 3: Hypothesentests - Teil 1</span>"
    ]
  },
  {
    "objectID": "00 Data Wrangling Basics.html",
    "href": "00 Data Wrangling Basics.html",
    "title": "5  Anhang: Data Wrangling",
    "section": "",
    "text": "6 Pakete laden\nbasierend auf Kurs von Ian Hussey - https://github.com/ianhussey/data-wrangling-workshop/ S. auch https://methodenlehre.github.io/einfuehrung-in-R/\nIn diesem Kurs arbeiten wir mit R-Notebooks. Diese enthalten sowohl normalen Text als auch “Chunks” von R-Code. Chunks sind Abschnitte von R-Code. Diese Chunks lassen sich mit einem Klick auf Code –&gt; Insert Chunk (oder der Tastenkombination Alt + Ctrl / Cmd + I) einfügen. Diese lassen sich mit einem Klcik auf den grünen Play-Button ganz rechts ausführen. Der Pfeil nach unten Button (zweiter von Rechts) führt alle Chunks, die vor dem Chunk gelagert sind, aus.\nZunächst laden wir die Pakete die wir für die Sitzung brauchen.\nif (!require(\"pacman\")) install.packages(\"pacman\")\n\nLoading required package: pacman\n\npacman::p_load(psych, tidyverse)\ndata(sat.act)\ndf_beispiel &lt;-as_tibble(sat.act)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Anhang: Data Wrangling</span>"
    ]
  },
  {
    "objectID": "00 Data Wrangling Basics.html#warum-lohnt-es-sich-die-pipe-zu-nutzen",
    "href": "00 Data Wrangling Basics.html#warum-lohnt-es-sich-die-pipe-zu-nutzen",
    "title": "5  Anhang: Data Wrangling",
    "section": "11.1 Warum lohnt es sich, die Pipe zu nutzen?",
    "text": "11.1 Warum lohnt es sich, die Pipe zu nutzen?\nDer Pipe-Operator ermöglicht es uns, Code zu schreiben, der von oben nach unten gelesen wird und einer Abfolge von Schritten folgt – so, wie Menschen Schritte organisieren und beschreiben. Ohne den Pipe-Operator wird der Code von innen nach aussen geschrieben, auf eine Weise, die der Computer versteht, aber für Menschen weniger intuitiv ist. Die Unterscheide in der Lesbarkeit zeigen sich vor allem bei komplexeren, verketteten Funktionen.\nWir verwenden im Folgenden einen Datenframe, wählen mit select() Spalten aus, und erstellen ihre Mittelwerte mit colMeans(). Ohne Pipe lesen wir von innen nach aussen: select(…), dann colMeans(…); mit Pipe lesen und schreiben wir: Objekt - select() - colMeans(), was einfacher nachzuvollziehen ist. Jede Funktion macht etwas, die Pipe gibt jeweils den transformierten Inhalt weiter an die nächste Funktion.\n\n# use a function without the pipe\nexample_without_pipe &lt;- colMeans(select(df_beispiel, SATV, SATQ), na.rm = TRUE)\n\nexample_without_pipe\n\n    SATV     SATQ \n612.2343 610.2169 \n\n# use a function with the pipe. \nexample_with_pipe &lt;- df_beispiel |&gt; \n  select(SATV, SATQ) |&gt; \n  colMeans(na.rm = TRUE)\n\n# check they produce identical results\nidentical(example_without_pipe, example_with_pipe)\n\n[1] TRUE",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Anhang: Data Wrangling</span>"
    ]
  },
  {
    "objectID": "00 Data Wrangling Basics.html#group_by",
    "href": "00 Data Wrangling Basics.html#group_by",
    "title": "5  Anhang: Data Wrangling",
    "section": "18.1 group_by()",
    "text": "18.1 group_by()\nOft wollen wir einen Datensatz jedoch nicht auf eine einzelne Zeile reduzieren bzw. den gesamten Datensatz zusammenfassen, sondern eine Zusammenfassung für jede (Unter-)Gruppe erstellen. Dies ist hilfreich, insbesondere da wir im Seminar mit Tagen verschachtelt in Personen arbeiten werden.\n\n# illustrate use of group_by() and summarize()\ndf_beispiel |&gt; \n  group_by(education) |&gt; \n  summarize(ACT_c = mean(ACT_z, na.rm = TRUE))\n\n# A tibble: 6 × 2\n  education   ACT_c\n      &lt;int&gt;   &lt;dbl&gt;\n1         0 -0.223 \n2         1 -0.219 \n3         2 -0.325 \n4         3 -0.0524\n5         4  0.148 \n6         5  0.219",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Anhang: Data Wrangling</span>"
    ]
  },
  {
    "objectID": "00 Data Wrangling Basics.html#komplexere-zusammenfassungen",
    "href": "00 Data Wrangling Basics.html#komplexere-zusammenfassungen",
    "title": "5  Anhang: Data Wrangling",
    "section": "18.2 Komplexere Zusammenfassungen",
    "text": "18.2 Komplexere Zusammenfassungen\nÄhnlich wie bei mutate() kann auch die Operation für summarize() komplexer sein, z. B. das Finden des Mittelwerts einer logischen Operation (d.h., logische Operatoren nutzend, wie &, &lt;, &gt;, | etc.) , um einen Anteil zu berechnen. Im Folgenden berechnen wir den Anteil von niedrigen SAT Verbal Scores (hier definiert als -1 Standardabweichungen oder niedriger) gruppiert nach Bildung.\n\ndf_beispiel |&gt; \n  mutate(SATV_z = scale(SATV)) |&gt; \n  group_by(education) |&gt;\n  summarize(SATV_unterdurchschnitt = mean(SATV_z &lt; -1, na.rm = TRUE))\n\n# A tibble: 6 × 2\n  education SATV_unterdurchschnitt\n      &lt;int&gt;                  &lt;dbl&gt;\n1         0                 0.193 \n2         1                 0.2   \n3         2                 0.25  \n4         3                 0.135 \n5         4                 0.0942\n6         5                 0.0851\n\n\nMit across() kannst du Zusammenfassungen (oder auch Änderungen mit mutate()) über mehrere Spalten hinweg auf dieselbe Weise durchführen. Wir werden hier nicht alle Möglichkeiten oder Details zu across() behandeln, aber es ist wichtig zu wissen, dass es möglich ist. Zum Beispiel:\n\ndf_beispiel |&gt; \n  # ... calculate the mean of every numeric column in the dataset ...\n  summarise(across(where(is.numeric), mean, na.rm = TRUE)) |&gt; \n  # ... and then round every column to one decimal place\n  mutate(across(everything(), round, digits = 2))\n\nWarning: There was 1 warning in `summarise()`.\nℹ In argument: `across(where(is.numeric), mean, na.rm = TRUE)`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))\n\n\n# A tibble: 1 × 8\n  gender education   age   ACT  SATV  SATQ ACT_c ACT_z\n   &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1   1.65      3.16  25.6  28.6  612.  610.     0     0",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Anhang: Data Wrangling</span>"
    ]
  },
  {
    "objectID": "00 Data Wrangling Basics.html#lösung-übung-data-wrangling",
    "href": "00 Data Wrangling Basics.html#lösung-übung-data-wrangling",
    "title": "5  Anhang: Data Wrangling",
    "section": "21.1 Lösung: Übung Data Wrangling",
    "text": "21.1 Lösung: Übung Data Wrangling\n\n# auswählen\ndf_auswahl &lt;- df_beispiel |&gt; select(education, SATQ)\n# neue variable erstellen\ndf_neuevariable &lt;- df_auswahl |&gt; mutate(\n  education = as.factor(education),\n  SATQ_c = scale(SATQ, center = TRUE, scale = FALSE))\n# filtern\ndf_filter &lt;- df_neuevariable |&gt; filter(education == 1)\n\n# jetzt alles zusammen\ndf_kombiniert &lt;- df_beispiel |&gt; \n  select(education, SATQ) |&gt; \n  mutate(\n  education = as.factor(education),\n  SATQ_c = scale(SATQ, center = TRUE, scale = FALSE)) |&gt; \n  filter(education == 1)\n\n# identical(df_filter, df_kombiniert) # check",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Anhang: Data Wrangling</span>"
    ]
  },
  {
    "objectID": "00 Data Wrangling Basics.html#lösung-übung-summarize",
    "href": "00 Data Wrangling Basics.html#lösung-übung-summarize",
    "title": "5  Anhang: Data Wrangling",
    "section": "21.2 Lösung: Übung summarize()",
    "text": "21.2 Lösung: Übung summarize()\n\ndf_beispiel |&gt; \n  summarize(min_satv = min(SATV, na.rm = TRUE),\n            max_satv = max(SATV, na.rm = TRUE),\n            mean_satv = mean(SATV, na.rm = TRUE),\n            sd_satv = sd(SATV, na.rm = TRUE))\n\n# A tibble: 1 × 4\n  min_satv max_satv mean_satv sd_satv\n     &lt;int&gt;    &lt;int&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1      200      800      612.    113.\n\nbfi |&gt; group_by(gender) |&gt; \n  summarize(C1_na = sd(C1, na.rm = TRUE),\n            C1_mean = mean(C1, na.rm = TRUE))\n\n# A tibble: 2 × 3\n  gender C1_na C1_mean\n   &lt;int&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1      1  1.24    4.48\n2      2  1.24    4.52",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Anhang: Data Wrangling</span>"
    ]
  }
]