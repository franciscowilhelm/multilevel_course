---
title: "Datenaufbereitung"
format: html
---


## Reading example data

-   Zunächst sind alle Variablen auszuwählen, die ihr für eure Analysen benötigt.

-   Schlagt im Codebook nach, wie die Variablen/Skalen heissen, die ihr in eurem zu testenden Modell heranzieht.

-   Die "id_num" Variable ist ebenfalls wichtig und sollte mit ausgewählt werden.

In diesem Beispiel befassen wir uns mit Boredom (bore), bored behavior (borb), meaningfulness (mea) und als Moderator wählen wir work values - intellectual stimulation (vint).
Für die Analysen arbeiten wir meist mit den Skalenscores aus dem df_scores_long.
Für die Reliabilitätsanalyse greifen wir auf die Items zurück in df_items_long für die täglichen und df_baseline_items für die Baseline.


Ihr könnt die Variablen mit denen, die euch interessieren, ersetzen.
Für die scores ist das in der Klammer der Funktion `select()`.
Für die Items können wir uns die Mühe sparen jedes Item einzeln zu nennen und in dem `starts_with()` Selektionshelfer in einem Vektor `c()` die Namen der Skalen eintragen. Hier müssen die Variablennamen explizit als Character angegeben werden mittels der Anführungszeichen "".

```{r}
df_example1 <- read.table(file = "data_simulation/example1rep2.dat", header = FALSE, 
        na.strings = "*", strip.white = TRUE) |> as_tibble()
names(df_example1) <- c("w", "y", "x", "m", "id")
df_example1 <- df_example1 |> select(id, everything())
```





## Item-level dataset 


### Reliabilitätsanalyse

Die Reliabilitätsanalyse basiert auf den Items, nicht auf den Skalenwerten. Entsprechend arbeiten wir mit den Dataframes `df_items_long` und `df_baseline`.

Bei Skalen aus der Daily Erhebung nehmen wir die `omegaSEM()` Funktion. Als erstes Argument geben wir die Items in einem Character-Vector mittels `c()`, die Items werden mit Anführungszeichen angegeben. Falls ihr die Itemnamen nicht wisst, könnt ihr sie mit `names(df_items)` nachsehen.

```{r}
names(df_items)
borb_reliab <- multilevelTools::omegaSEM(c("borb_1", "borb_2", "borb_3"), "id_num", df_items)
borb_reliab$Results
bore_reliab <- multilevelTools::omegaSEM(c("bore_1", "bore_2"), "id_num", df_items)
bore_reliab$Results
mea_reliab <- multilevelTools::omegaSEM(c("mea_1", "mea_2", "mea_3"), "id_num", df_items)
mea_reliab$Results
```
Hier erscheint meist eine Warnung, weil nicht alle Personen (cluster) Varianz auf den Items haben. Dies koennen wir ignorieren.
Dann koennen wir den Output ansehen. Omega_within und Omega_between sollten über .70 liegen für eine gute Reliabilität auf beiden Leveln.

Für die Baseline-Variablen verwenden wir die Funktion `alpha()` aus dem `psych` Paket. Als Argument nimmt die Funktion hier (a) den Datensatz und (b) die Variablennamen der Items der Skala in einem Vektor `c()`. Revers kodierte Items werden mit einem "-" als Präfix eingetragen (z.B. "-reversitem_1").

```{r}
vint_reliab <- psych::alpha(df_baseline, c("vint_1", "vint_2", "vint_3"))
print(vint_reliab)
```
Wir erhalten umfangreiche Angaben zur Reliabilität. Wichtig ist der Alpha-Wert der Gesamtskala (std.alpha). Dieser ist im Beispiel > .70. Im Datensatz sind ein paar Skalen, bei denen die Reliabilität darunter liegt. Meist sind dies Skalen die ein revers kodiertes Item enthalten, diese Items wurden von vielen Teilnehmenden scheinbar nicht verstanden.

## Scale-level dataset

### Zentrierung

Als nächstes zentrieren wir die Skalenvariablen, die täglich gemessen werden (aber nicht Baseline-Variablen), mittels `de_mean()`. de_mean() nimmt als Argumente (a) mit Komma getrennte Namen der Variablen, die wir zentrieren wollen (mehrere auf einmal ist möglich), (b) mittels grp Argument die identifizierende Variable für die Gruppenzugehörigkeit.
Setzt entsprechend die interessierende täglichen Variablen ein.

```{r}
df_example1 <- df_example1 |> 
  de_mean(y, m, x, grp = "id")
head(df_example1)

save(df_example1, file = "data/df_example1.RData")
```

Jetzt haben wir einen Datensatz mit den unzentrierten / Rohvariablen der Skalen (ohne Suffix), den zentrierten Variablen (Suffix `_dm`) und den Mittelwerten der Personen (Suffix `_gm`).

Uns interessiert wie gross der Anteil der Varianz ist, der auf die zwei Ebenen der Daten entfallen (Inner-Person, Zwischen-Person-Ebene). Dies kann uns der ICC angeben. Mittels der Funktion `statsBy()` bekommen wir einige Analysen zu unseren Mehrebenen-Daten geliefert. Die Funktion benötigt zwei Argumente: den Datensatz und und die Gruppierungsvariable. Wir wählen mittels `select()` die Rohvariante der Variablen aus, da nur diese die Informationen über beide Ebenen enthalten. 
Ersetzt entsprechend im `select()` die Variablen mit denen, die euch interessieren, hier sowohl die täglichen als auch Baselinevariablen.

```{r}
mehrebenen_stats <- df_example1 |>
  select(id, y, m, x, w) |> 
  statsBy(group = "id")
```
Wir bekommen hier Warnungen, weil wir auch eine reine Level-2 Variablen eingeschlossen haben (vint). Dies können wir jedoch ignorieren.
Den ICC können wir uns angeben lassen, indem wir aus dem Listenobjekt `mehrebenen_stats` mit dem Dollarzeichen `$` die Untervariable `ICC1` anwählen.

```{r}
icc <- mehrebenen_stats$ICC1 |> 
  round(2) # runden
icc
```
Alle Skalen im Beispiel haben ICCs in einem angemessenen Bereich (<.80). Dies heisst, dass genug tägliche Varianz vorhanden ist, um Mehrebenen-Analysen durchzuführen.

### Korrelationstabelle

In psychologischen Artikeln ist (fast) immer die Korrelationstabelle die erste Tabelle des Artikels. Unser nächstes Ziel ist es, die Korrelationstabelle anzufertigen in der wir auch die Mittelwerte und Standardabweichungen integrieren. 

Mittelwerte bekommen wir mit der Funktion `summarise()`. Diese erlaubt uns, zusammenfassende Werte zu bilden. Da wir dies gleich für mehrere Variablen machen, benutzen wir zudem `across()` um die Summary gleich für mehrere Variablen zu bilden. Die Funktion benötigt als Argumente (a) die Namen der Variablen mit `c()` als einen Vektor zusammengefasst, (b) die Funktionen, wie sie gebildet werden (hier: `~mean(.x, na.rm = TRUE)` für das arithmetische Mittel unter Ausschluss aller nicht vorhandenen Werte) und (c) optional die Namen der ausgegebenen Variablen mittels ".names". Wir verwenden "m_{.col}". Abschliessend runden wir die Werte.

Ersetzt im folgenden Code in der Klammer von `c()` die Variablennamen  mit denen, die euch interessieren, hier sowohl die täglichen als auch Baselinevariablen.

```{r}
mittelwerte <- df |> summarise(across(c(bore, borb, mea, vint),
                                           ~mean(.x, na.rm = TRUE),
                                           .names = "m_{.col}")) |>
  round(2) # runden

mittelwerte
```
Wir sehen, dass Boredom und bored behavior eher selten sind. Für die Verteilung der Variablen sehen wir uns idealerweise auch Histogramme an (hier nicht aufgezeigt).

#### Standardabweichungen

Ganz ähnlich verfahren wir für die Standardabweichung, nur dass wir hier als Funktion `~sd(.x, na.rm = TRUE)` verwenden.
Ersetzt auch hier im folgenden Code in der Klammer von `c()` die Variablennamen  mit denen, die euch interessieren, hier sowohl die täglichen als auch Baselinevariablen.

```{r}
standardabweichung <- df |>  summarise(across(c(bore, borb, mea, vint),
                                                   ~sd(.x, na.rm = TRUE),
                                                   .names = "sd_{.col}")) |> 
  round(2) # runden

standardabweichung
```

#### Korrelationen

Wir wollen eine Korrelationstabelle, in der wir auf einen Blick sowohl die Zwischen-Person-Korrelationen als auch die Inner-Person-Korrelationen sehen. Die `statsBy()` Funktion, die wir bereits aufgerufen haben, gibt uns beides separat aus, und wir müssen sie über mehrere Schritte zusammenführen und gemösse APA mit Signifikanzsternchen ergänzen.
Die Details der Vorgehensweise geht über den Rahmen dieses Arbeitsbuchs hinaus. Wir verwenden die `mehrebenen_stats` Liste, die wir weiter oben erstellt haben. 

(Die folgende Syntax muss nicht angepasst werden.)

```{r}
cortable_between <- mehrebenen_stats$rbg |> round(2) # Zwischen Person Kor.
cortable_within <- mehrebenen_stats$rwg |> round(2) # Inner Person Kor.

# Signifikanzsternchen
star_assign <- function(x) {
  if(!is.na(x)) {
    if(x < 0.001) "***"
    else if (x < 0.01) "**"
    else if (x < 0.05) "*"
    else ""
  }
  else ""
}
vstar_assign <- Vectorize(star_assign)

for(i in 1:length(cortable_between)) {
  cortable_between[i] <- str_c(cortable_between[i], vstar_assign(mehrebenen_stats$pbg[i]))
  }

for(i in 1:length(cortable_within)) {
  cortable_within[i] <- str_c(cortable_within[i], vstar_assign(mehrebenen_stats$pwg[i]))
  }

cortable <- cortable_between
cortable[lower.tri(cortable)] <- cortable_within[lower.tri(cortable_within)] # Inner-Person Korrelationen im unteren Dreieck einfügen.
cortable <- cortable |>   as_tibble(rownames = "var") # als data frame formatieren (später wichtig)

cortable
```

Wir erhalten im unteren Dreieck die Inner-Person-Korrelationen, und im oberen Dreieck die Zwischen-Person-Korrelationen.


#### Integration in Tabelle

Jetzt gilt es, die Mittelwerte, Standardabweichungen, ICCs, und Korrelationen in einer Tabelle zu integrieren. Mit der `tibble()` Funktion bauen wir einen neue Datensatz-Tabelle, in der wir alle Variablen integrieren.

(Die folgende Syntax muss nicht angepasst werden.)

```{r}
cortable_integriert <- tibble(cortable["var"],
                              m = t(mittelwerte), # t() transponiert die Dimensionen der Variable, damit wir es als spalte (3x1) haben statt als zeile (1x3)
                              sd = t(standardabweichung),
                              icc = icc[2:length(icc)], # 1 überspringen da wir den ICC von "id" nicht brauchen
                              cortable[,2:ncol(cortable)])

cortable_integriert
```

### Export von Tabellen zu Excel

Wir exportieren die Korrelationstabelle nach Excel mittels `write_xlsx()`.

(Die folgende Syntax muss nicht angepasst werden.)
```{r}
write_xlsx(cortable_integriert, path = "korrelationstabelle.xlsx")
```

Excel-Tabelle lässt sich dann in Word kopieren und kann aufgehübscht, z.B. mit den richtigen Variablennamen versehen werden etc. Damit haben wir nun die Datenaufbereitung und deskriptive Datenanalyse abgeschlossen (ausgenommen Reliabilitätsanalyse).
